# Tyler's References and Reading List

Bib information and reading notes for papers I've read.

Reading list is a yaml file generated using my personal [bibmgr tool](https://github.com/thchang/bib-manager).

List of topics (may be some overlap between topics):

 * [AI](#AI)
 * [SciML](#SciML)
 * [optimization](#optimization)
 * [HPC](#HPC)
 * [software](#software)
 * [computational geometry](#computational-geometry)
 * [design of experiments](#design-of-experiments)
 * [quantum computing](#quantum-computing)

## AI

 * [Ba et al., 2016. Layer Normalization](https://arxiv.org/abs/1607.06450v1)
 * [Bengio et al., 2013. Representation Learning: A Review and New Perspectives](http://ieeexplore.ieee.org/document/6472238/)
 * [Boyd et al., 2004. Convex optimization](https://stanford.edu/~boyd/cvxbook/)
 * [Bradbury et al., 2018. JAX: composable transformations of Python+NumPy programs](http://github.com/google/jax)
 * [Brockman et al., 2016. OpenAI Gym](https://github.com/openai/gym)
 * [Bronstein et al., 2021. Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges](https://doi.com/10.48550/arXiv.2104.13478)
 * [Brown et al., 2020. Language Models are Few-Shot Learners](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)
 * [Chen et al., 2016. XGBoost: A Scalable Tree Boosting System](https://dl.acm.org/doi/10.1145/2939672.2939785)
 * [Chen et al., 2021. Evaluating large language models trained on code](https://doi.com/10.48550/arXiv.2107.03374)
 * [Chiang et al., 2024. Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference](https://openreview.net/forum?id=3MW8GKNyzI)
 * [Chollet et al., 2015. Keras](https://keras.io)
 * [Dash et al., 2024. Optimizing Distributed Training on Frontier for Large Language Models](https://ieeexplore.ieee.org/document/10528939/)
 * [Dauphin et al., 2014. Identifying and attacking the saddle point problem in high-dimensional non-convex optimization](https://proceedings.neurips.cc/paper_files/paper/2014/file/04192426585542c54b96ba14445be996-Paper.pdf)
 * [Deng et al., 2009. ImageNet: A large-scale hierarchical image database](https://ieeexplore.ieee.org/document/5206848/)
 * [Devlin et al., 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://aclanthology.org/N19-1423/)
 * [Dhariwal et al., 2017. OpenAI Baselines](https://github.com/openai/baselines)
 * [Dubois et al., 2024. Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators](https://doi.com/10.48550/arXiv.2404.04475)
 * [Duchi et al., 2011. Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](http://jmlr.org/papers/v12/duchi11a.html)
 * [Fawzi et al., 2022. Discovering faster matrix multiplication algorithms with reinforcement learning](https://www.nature.com/articles/s41586-022-05172-4)
 * [Fukushima, 1975. Cognitron: A self-organizing multilayered neural network](http://link.springer.com/10.1007/BF00342633)
 * [Gao et al., 2023. Scaling Laws for Reward Model Overoptimization](https://proceedings.mlr.press/v202/gao23h.html)
 * [Geman et al., 1992. Neural networks and the bias/variance dilemma](https://direct.mit.edu/neco/article/4/1/1-58/5624)
 * [Goh, 2017. Why Momentum Really Works](http://distill.pub/2017/momentum)
 * [Gorban et al., 2017. Stochastic separation theorems](https://linkinghub.elsevier.com/retrieve/pii/S0893608017301776)
 * [Grattafiori et al., 2024. The LLaMA 3 herd of models](https://arxiv.org/abs/2407.21783)
 * [Graves, 2014. Generating Sequences With Recurrent Neural Networks](https://arxiv.org/abs/1308.0850)
 * [Guo et al., 2025. DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning](https://doi.com/10.48550/arXiv.2501.12948)
 * [He et al., 2016. Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385)
 * [Hinton et al., 1983. Optimal perceptual inference](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b89e9f0cef5ace08946a7c07bf7284854c418445)
 * [Hochreiter et al., 1997. Long Short-Term Memory](https://direct.mit.edu/neco/article/9/8/1735-1780/6109)
 * [Hof, 2015. Google Tries to Make Machine Learning a Little More Human](https://www.technologyreview.com/2015/11/05/165175/google-tries-to-make-machine-learning-a-little-more-human)
 * [Ilyas et al., 2019. Adversarial Examples Are Not Bugs, They Are Features](https://proceedings.neurips.cc/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf)
 * [Jain et al., 2022. tiktoken](https://github.com/openai/tiktoken)
 * [Jain et al., 2024. LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code](https://doi.com/10.48550/arXiv.2403.07974)
 * [Jordan, 1986. Serial order: a parallel distributed processing approach](https://www.osti.gov/biblio/6910294)
 * [Kingma et al., 2014. Auto-encoding variational Bayes](https://arxiv.org/abs/1312.6114)
 * [Kingma et al., 2015. Adam: A method for stochastic optimization](https://arxiv.org/abs/1412.6980)
 * [Krizhevsky, 2009. Learning multiple layers of features from tiny images](https://www.cs.utoronto.ca/~kriz/learning-features-2009-TR.pdf)
 * [Krizhevsky et al., 2012. ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
 * [Lai, 2003. Stochastic approximation](https://projecteuclid.org/journals/annals-of-statistics/volume-31/issue-2/Stochastic-approximation-invited-paper/10.1214/aos/1051027873.full)
 * [LeCun et al., 1989. Backpropagation Applied to Handwritten Zip Code Recognition](https://direct.mit.edu/neco/article/1/4/541-551/5515)
 * [LeCun et al., 1995. Convolutional networks for images, speech, and time series](https://www.cs.utoronto.ca/~bonner/courses/2016s/csc321/readings/Convolutional%20networks%20for%20images,%20speech,%20and%20time%20series.pdf)
 * [LeCun et al., 1998. Gradient-based learning applied to document recognition](http://ieeexplore.ieee.org/document/726791/)
 * [Liu et al., 2024. DeepSeek-V3 technical report](https://doi.com/10.48550/arXiv.2412.19437)
 * [Lux et al., 2020. Analytic test functions for generalizable evaluation of convex optimization techniques](https://ieeexplore.ieee.org/document/9368254/)
 * [Mikolov et al., 2013. Efficient estimation of word representations in vector space](https://openreview.net/forum?id=idpCdOWtqXd60&noteld=C8Vn84fq)
 * [Mikolov et al., 2013. Linguistic regularities in continuous space word representations](https://aclanthology.org/N13-1090.pdf)
 * [Nair et al., 2010. Rectified linear units improve restricted Boltzmann machines](https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf)
 * [Nesterov, 1983. A method for solving the convex programming problem with convergence rate $O(1/k^2)$](https://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=dan&paperid=46009&option_lang=eng)
 * [Ng, 2004. Feature selection, L1 vs. L2 regularization, and rotational invariance](https://doi.org/10.1145/1015330.1015435)
 * [Park et al., 1991. Universal approximation using radial-basis-function networks](https://direct.mit.edu/neco/article/3/2/246-257/5580)
 * [Paszke et al., 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf)
 * [Pedregosa et al., 2011. Scikit-learn: Machine learning in Python](https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf)
 * [Radford et al., 2018. Improving language understanding by generative pre-training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
 * [Radford et al., 2019. Language models are unsupervised multitask learners](https://storage.prod.researchhub.com/uploads/papers/2020/06/01/language-models.pdf)
 * [Recht et al., 2019. Do ImageNet Classifiers Generalize to ImageNet?](https://proceedings.mlr.press/v97/recht19a.html)
 * [Rosenblatt, 1958. The perceptron: a probabilistic model for information storage and organization in the brain.](https://doi.apa.org/doi/10.1037/h0042519)
 * [Rumelhart et al., 1985. Learning internal representations by error propagation](https://www.cs.toronto.edu/~hinton/absps/pdp8.pdf)
 * [Rumelhart et al., 1986. Learning representations by back-propagating errors](https://www.nature.com/articles/323533a0)
 * [Schulman et al., 2017. Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)
 * [Sennrich et al., 2016. Neural Machine Translation of Rare Words with Subword Units](https://aclanthology.org/P16-1162/)
 * [Shao et al., 2024. DeepSeekMath: Pushing the limits of mathematical reasoning in open language models](https://doi.com/10.48550/arXiv.2402.03300)
 * [Shwartz-Ziv et al., 2022. Tabular data: Deep learning is not all you need](https://linkinghub.elsevier.com/retrieve/pii/S1566253521002360)
 * [Silver et al., 2016. Mastering the game of Go with deep neural networks and tree search](https://www.nature.com/articles/nature16961)
 * [Sohl-Dickstein et al., 2015. Deep Unsupervised Learning using Nonequilibrium Thermodynamics](https://proceedings.mlr.press/v37/sohl-dickstein15.html)
 * [Srivastava et al., 2014. Dropout: a simple way to prevent neural networks from overfitting](https://jmlr.org/papers/v15/srivastava14a.html)
 * [Team et al., 2023. Gemini: a family of highly capable multimodal models](https://doi.com/10.48550/arXiv.2312.11805)
 * [Touvron et al., 2023. LLaMA: Open and efficient foundation language models](https://doi.com/10.48550/arXiv.2302.13971)
 * [Touvron et al., 2023. LLaMA~2: Open foundation and fine-tuned chat models](https://arxiv.org/abs/2307.09288)
 * [Vaswani et al., 2017. Attention is all you need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
 * [Vinyals et al., 2019. Grandmaster level in StarCraft II using multi-agent reinforcement learning](https://doi.org/10.1038/s41586-019-1724-z)
 * [Wang et al., 2024. Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://aclanthology.org/2024.acl-long.510)
 * [Wang et al., 2024. MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark](https://proceedings.neurips.cc/paper_files/paper/2024/file/ad236edc564f3e3156e1b2feafb99a24-Paper-Datasets_and_Benchmarks_Track.pdf)
 * [Wei et al., 2022. Chain-of-thought prompting elicits reasoning in large language models](https://openreview.net/forum?id=_VjQlMeSB_J)
 * [Weinan, 2020. Machine learning and computational mathematics](https://global-sci.com/article/79736/machine-learning-and-computational-mathematics)
 * [Yann, 1998. The MNIST database of handwritten digits](yann.lecun.com/exdb/mnist)
 * [Zhang et al., 2017. Understanding deep learning requires rethinking generalization](https://openreview.net/forum?id=Sy8gdB9xx)
 * [Zhou et al., 2023. Instruction-Following Evaluation for Large Language Models](https://arxiv.org/abs/2311.07911)
 * [Ziegler et al., 2019. Fine-Tuning Language Models from Human Preferences](https://arxiv.org/abs/1909.08593)

## SciML

 * [Agrawal et al., 2019. Differentiable Convex Optimization Layers](https://proceedings.neurips.cc/paper_files/paper/2019/file/9ce3c52fc54362e22053399d3181c638-Paper.pdf)
 * [Akiba et al., 2019. Optuna: A next-generation hyperparameter optimization framework](https://dl.acm.org/doi/10.1145/3292500.3330701)
 * [Amos et al., 2017. OptNet: Differentiable Optimization as a Layer in Neural Networks](https://proceedings.mlr.press/v70/amos17a.html)
 * [Amos, 2023. Tutorial on Amortized Optimization](https://doi.org/10.1561/2200000102)
 * [Applegate et al., 2021. Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient](https://proceedings.neurips.cc/paper_files/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf)
 * [Balandat et al., 2020. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization](https://proceedings.neurips.cc/paper/2020/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf)
 * [Balaprakash et al., 2018. DeepHyper: Asynchronous hyperparameter search for deep neural networks](https://ieeexplore.ieee.org/document/8638041)
 * [Ball et al., 1992. On the sensitivity of radial basis interpolation to minimal data separation distance](http://link.springer.com/10.1007/BF01203461)
 * [Bambade et al., 2022. PROX-QP: Yet another Quadratic Programming Solver for Robotics and beyond](https://hal.inria.fr/hal-03683733)
 * [Belkin et al., 2018. Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate](https://proceedings.neurips.cc/paper/2018/hash/e22312179bf43e61576081a2f250f845-Abstract.html)
 * [Belkin, 2021. Fit without fear: remarkable mathematical phenomena of deep learning through the prism of interpolation](https://www.cambridge.org/core/product/identifier/S0962492921000039/type/journal_article)
 * [Bengio et al., 2013. Representation Learning: A Review and New Perspectives](http://ieeexplore.ieee.org/document/6472238/)
 * [Bollapragada et al., 2020. Optimization and supervised machine learning methods for fitting numerical physics models without derivatives](https://iopscience.iop.org/article/10.1088/1361-6471/abd009)
 * [Boyd et al., 2004. Convex optimization](https://stanford.edu/~boyd/cvxbook/)
 * [Bradbury et al., 2018. JAX: composable transformations of Python+NumPy programs](http://github.com/google/jax)
 * [Brockman et al., 2016. OpenAI Gym](https://github.com/openai/gym)
 * [Bronstein et al., 2021. Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges](https://doi.com/10.48550/arXiv.2104.13478)
 * [Buhmann, 2000. Radial basis functions](https://www.cambridge.org/core/product/identifier/S0962492900000015/type/journal_article)
 * [Chang et al., 2020. Algorithm 1012: DELAUNAYSPARSE: Interpolation via a Sparse Subset of the Delaunay Triangulation in Medium to High Dimensions](https://dl.acm.org/doi/10.1145/3422818)
 * [Chang, 2020. Mathematical Software for Multiobjective Optimization Problems](https://vtechworks.lib.vt.edu/handle/10919/98915)
 * [Chang et al., 2025. Leveraging Interpolation Models and Error Bounds for Verifiable Scientific Machine Learning](https://linkinghub.elsevier.com/retrieve/pii/S0021999125000099)
 * [Chen et al., 2004. Optimal Delaunay triangulations](https://www.math.uci.edu/~chenlong/Papers/Chen.L%3BXu.J2004.pdf)
 * [Chen et al., 2016. XGBoost: A Scalable Tree Boosting System](https://dl.acm.org/doi/10.1145/2939672.2939785)
 * [Cheney et al., 2009. A Course in Approximation Theory](http://www.ams.org/gsm/101)
 * [Chollet et al., 2015. Keras](https://keras.io)
 * [Christianson et al., 2022. Traditional kriging versus modern Gaussian processes for large-scale mining data](https://arxiv.org/abs/2207.10138)
 * [Conn et al., 2008. Geometry of interpolation sets in derivative free optimization](http://link.springer.com/10.1007/s10107-006-0073-5)
 * [Dauphin et al., 2014. Identifying and attacking the saddle point problem in high-dimensional non-convex optimization](https://proceedings.neurips.cc/paper_files/paper/2014/file/04192426585542c54b96ba14445be996-Paper.pdf)
 * [de Boor, 1978. A Practical Guide to Splines](https://www.researchgate.net/publication/200744645_A_Practical_Guide_to_Spline)
 * [Delaunay, 1934. Sur la sph\'ere vide](https://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=im&paperid=4937&option_lang=eng)
 * [De Ryck et al., 2022. Generic bounds on the approximation error for physics-informed (and) operator learning](https://proceedings.neurips.cc/paper_files/paper/2022/file/46f0114c06524debc60ef2a72769f7a9-Paper-Conference.pdf)
 * [Devlin et al., 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://aclanthology.org/N19-1423/)
 * [Diamond et al., 2016. CVXPY: A Python-embedded modeling language for convex optimization](http://jmlr.org/papers/v17/15-408.html)
 * [Domahidi et al., 2013. ECOS: An SOCP solver for embedded systems](https://ieeexplore.ieee.org/document/6669541)
 * [Duchi et al., 2011. Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](http://jmlr.org/papers/v12/duchi11a.html)
 * [Egele et al., 2022. AutoDEUQ: Automated deep ensemble with uncertainty quantification](https://ieeexplore.ieee.org/document/9956231/)
 * [Farhan et al., 2020. Reinforcement Learning in AnyLogic Simulation Models: A Guiding Example using Pathmind](https://ieeexplore.ieee.org/document/9383916)
 * [Fawzi et al., 2022. Discovering faster matrix multiplication algorithms with reinforcement learning](https://www.nature.com/articles/s41586-022-05172-4)
 * [Fukushima, 1975. Cognitron: A self-organizing multilayered neural network](http://link.springer.com/10.1007/BF00342633)
 * [Garg et al., 2023. SF-SFD: Stochastic optimization of Fourier coefficients for space-filling designs](https://ieeexplore.ieee.org/document/10408245/)
 * [Garnett, 2023. Bayesian Optimization](https://bayesoptbook.com)
 * [Geman et al., 1992. Neural networks and the bias/variance dilemma](https://direct.mit.edu/neco/article/4/1/1-58/5624)
 * [Gillette et al., 2022. Data-driven geometric scale detection via Delaunay interpolation](https://arxiv.org/html/2203.05685v2)
 * [Gillette et al., 2024. Algorithm 1049: The Delaunay Density Diagnostic](https://doi.org/10.1145/3700134)
 * [Goh, 2017. Why Momentum Really Works](http://distill.pub/2017/momentum)
 * [Golub et al., 2013. Matrix computations](https://www.press.jhu.edu/books/title/10678/matrix-computations)
 * [Gorban et al., 2017. Stochastic separation theorems](https://linkinghub.elsevier.com/retrieve/pii/S0893608017301776)
 * [Gramacy et al., 2012. Cases for the nugget in modeling computer experiments](http://link.springer.com/10.1007/s11222-010-9224-x)
 * [Graves, 2014. Generating Sequences With Recurrent Neural Networks](https://arxiv.org/abs/1308.0850)
 * [G{\"u}hring et al., 2020. Error bounds for approximations with deep ReLU neural networks in $W^s,p$ norms](https://doi.com/10.1142/S0219530519410021)
 * [Harris et al., 2020. Array programming with NumPy](https://www.nature.com/articles/s41586-020-2649-2)
 * [Hinton et al., 1983. Optimal perceptual inference](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b89e9f0cef5ace08946a7c07bf7284854c418445)
 * [Hochreiter et al., 1997. Long Short-Term Memory](https://direct.mit.edu/neco/article/9/8/1735-1780/6109)
 * [Hof, 2015. Google Tries to Make Machine Learning a Little More Human](https://www.technologyreview.com/2015/11/05/165175/google-tries-to-make-machine-learning-a-little-more-human)
 * [Huangfu et al., 2018. Parallelizing the dual revised simplex method](http://link.springer.com/10.1007/s12532-017-0130-5)
 * [Ilyas et al., 2019. Adversarial Examples Are Not Bugs, They Are Features](https://proceedings.neurips.cc/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf)
 * [Jordan, 1986. Serial order: a parallel distributed processing approach](https://www.osti.gov/biblio/6910294)
 * [Jrad et al., 2019. Self-Learning, Adaptive Software for Aerospace Engineering Applications: Example of Oblique Shocks in Supersonic Flow](https://arc.aiaa.org/doi/10.2514/6.2019-1704)
 * [Kandasamy et al., 2020. Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly](http://jmlr.org/papers/v21/18-223.html)
 * [Karpatne et al., 2017. Theory-Guided Data Science: A New Paradigm for Scientific Discovery from Data](http://ieeexplore.ieee.org/document/7959606)
 * [Kimeldorf et al., 1971. Some results on Tchebycheffian spline functions](https://pages.stat.wisc.edu/~wahba/ftp1/oldie/kw71.pdf)
 * [Kingma et al., 2014. Auto-encoding variational Bayes](https://arxiv.org/abs/1312.6114)
 * [Kingma et al., 2015. Adam: A method for stochastic optimization](https://arxiv.org/abs/1412.6980)
 * [Kovachki et al., 2021. Neural Operator: Learning Maps Between Function Spaces](https://www.jmlr.org/papers/volume24/21-1524/21-1524.pdf)
 * [Krizhevsky et al., 2012. ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
 * [Lai, 2003. Stochastic approximation](https://projecteuclid.org/journals/annals-of-statistics/volume-31/issue-2/Stochastic-approximation-invited-paper/10.1214/aos/1051027873.full)
 * [Lax, 2002. Functional analysis](https://books.google.com/books?hl=en&lr=&id=18VqDwAAQBAJ&oi=fnd&pg=PR17&ots=8FU4i_jAff&sig=Lh4GrUCrS_gt-HKqHSq4X7BaxMs#v=onepage&q&f=false)
 * [LeCun et al., 1989. Backpropagation Applied to Handwritten Zip Code Recognition](https://direct.mit.edu/neco/article/1/4/541-551/5515)
 * [LeCun et al., 1995. Convolutional networks for images, speech, and time series](https://www.cs.utoronto.ca/~bonner/courses/2016s/csc321/readings/Convolutional%20networks%20for%20images,%20speech,%20and%20time%20series.pdf)
 * [LeCun et al., 1998. Gradient-based learning applied to document recognition](http://ieeexplore.ieee.org/document/726791/)
 * [Lindauer et al., 2022. SMAC3: A Versatile Bayesian Optimization Package for Hyperparameter Optimization](http://jmlr.org/papers/v23/21-0888.html)
 * [Liu et al., 2019. Nonparametric functional approximation with Delaunay triangulation learner](https://ieeexplore.ieee.org/document/8944414)
 * [Lundberg et al., 2017. A Unified Approach to Interpreting Model Predictions](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf)
 * [Lux et al., 2018. Nonparametric distribution models for predicting and managing computational performance variability](https://ieeexplore.ieee.org/document/8478814)
 * [Lux et al., 2018. Predictive modeling of I/O characteristics in high performance computing systems](https://par.nsf.gov/servlets/purl/10111447)
 * [Lux et al., 2020. Analytic test functions for generalizable evaluation of convex optimization techniques](https://ieeexplore.ieee.org/document/9368254/)
 * [Lux et al., 2021. Interpolation of sparse high-dimensional data](https://link.springer.com/10.1007/s11075-020-01040-2)
 * [Lux et al., 2023. Algorithm 1031: MQSI---Monotone quintic spline interpolation](https://dl.acm.org/doi/10.1145/3570157)
 * [MacKay, 1992. A practical Bayesian framework for backpropagation networks](https://direct.mit.edu/neco/article/4/3/448-472/5654)
 * [Manton et al., 2015. A primer on reproducing kernel Hilbert spaces](https://doi.com/10.1561/2000000050)
 * [Mikolov et al., 2013. Efficient estimation of word representations in vector space](https://openreview.net/forum?id=idpCdOWtqXd60&noteld=C8Vn84fq)
 * [Mikolov et al., 2013. Linguistic regularities in continuous space word representations](https://aclanthology.org/N13-1090.pdf)
 * [M\"obius, 1827. Der barycentrische Calcul](https://books.google.com/books?id=eFPluv_UqFEC&printsec=frontcover#v=onepage&q&f=false)
 * [Moriwaki et al., 2018. Mordred: a molecular descriptor calculator](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0258-y)
 * [Myers et al., 2016. Response Surface Methodology: Process and Design Optimization Using Designed Experiments](https://books.google.com/books?hl=en&lr=&id=T-BbCwAAQBAJ&oi=fnd&pg=PR13&dq=Response+Surface+Methodology:+Process+and+Product+Optimization+Using+Designed+Experiments,+4th+Edition&ots=O3jdPna83T&sig=IimJlE46JBVkHOu7eik3RN9Z5GA#v=onepage&q=Response%20Surface%20Methodology%3A%20Process%20and%20Product%20Optimization%20Using%20Designed%20Experiments%2C%204th%20Edition&f=false)
 * [Nair et al., 2010. Rectified linear units improve restricted Boltzmann machines](https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf)
 * [Nesterov, 1983. A method for solving the convex programming problem with convergence rate $O(1/k^2)$](https://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=dan&paperid=46009&option_lang=eng)
 * [Ng, 2004. Feature selection, L1 vs. L2 regularization, and rotational invariance](https://doi.org/10.1145/1015330.1015435)
 * [Omohundro, 1990. Geometric learning algorithms](https://linkinghub.elsevier.com/retrieve/pii/0167278990900854)
 * [Park et al., 1991. Universal approximation using radial-basis-function networks](https://direct.mit.edu/neco/article/3/2/246-257/5580)
 * [Paszke et al., 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf)
 * [Patel, 2025. The Marriage of Computable Phenotypes With Machine Learning—A Pathway to Evidence-Based Care for Critically Ill Children](https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2829845/patel\_2025\_ic\_240355\_1738013025.0942.pdf)
 * [Pearson, 1901. LIII. On lines and planes of closest fit to systems of points in space](https://www.tandfonline.com/doi/full/10.1080/14786440109462720)
 * [Pedregosa et al., 2011. Scikit-learn: Machine learning in Python](https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf)
 * [Powell, 1994. The uniform convergence of thin plate spline interpolation in two dimensions](http://link.springer.com/10.1007/s002110050051)
 * [Raissi et al., 2019. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations](https://linkinghub.elsevier.com/retrieve/pii/S0021999118307125)
 * [Ranjan et al., 2011. A computationally stable approach to Gaussian process interpolation of deterministic computer simulation data](http://www.tandfonline.com/doi/abs/10.1198/TECH.2011.09141)
 * [Rasmussen et al., 2006. Gaussian processes for machine learning](https://gaussianprocess.org/gpml)
 * [Recht et al., 2019. Do ImageNet Classifiers Generalize to ImageNet?](https://proceedings.mlr.press/v97/recht19a.html)
 * [Regis, 2015. The calculus of simplex gradients](http://link.springer.com/10.1007/s11590-014-0815-x)
 * [Rosenblatt, 1958. The perceptron: a probabilistic model for information storage and organization in the brain.](https://doi.apa.org/doi/10.1037/h0042519)
 * [Roy et al., 2023. Quasi-Monte Carlo Methods in Python](https://joss.theoj.org/papers/10.21105/joss.05309)
 * [Rumelhart et al., 1985. Learning internal representations by error propagation](https://www.cs.toronto.edu/~hinton/absps/pdp8.pdf)
 * [Rumelhart et al., 1986. Learning representations by back-propagating errors](https://www.nature.com/articles/323533a0)
 * [Sapsis et al., 2022. Optimal criteria and their asymptotic form for data selection in data-driven reduced-order modelling with Gaussian process regression](https://royalsocietypublishing.org/doi/10.1098/rsta.2021.0197)
 * [Schaback, 1995. Error estimates and condition numbers for radial basis function interpolation](http://link.springer.com/10.1007/BF02432002)
 * [Schulman et al., 2017. Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)
 * [Sennrich et al., 2016. Neural Machine Translation of Rare Words with Subword Units](https://aclanthology.org/P16-1162/)
 * [Shapley et al., 1953. A value for n-person games](http://www.library.fa.ru/files/Roth2.pdf#page=39)
 * [Shewchuk, 2002. What is a good linear finite element? Interpolation, conditioning, anisotropy, and quality measures](https://people.eecs.berkeley.edu/~jrs/papers/elemj.pdf)
 * [Shields et al., 2021. Bayesian reaction optimization as a tool for chemical synthesis](https://www.nature.com/articles/s41586-021-03213-y)
 * [Shroff et al., 1992. Adaptive condition estimation for rank-one updates of QR factorizations](http://epubs.siam.org/doi/10.1137/0613077)
 * [Shwartz-Ziv et al., 2022. Tabular data: Deep learning is not all you need](https://linkinghub.elsevier.com/retrieve/pii/S1566253521002360)
 * [Silver et al., 2016. Mastering the game of Go with deep neural networks and tree search](https://www.nature.com/articles/nature16961)
 * [Sohl-Dickstein et al., 2015. Deep Unsupervised Learning using Nonequilibrium Thermodynamics](https://proceedings.mlr.press/v37/sohl-dickstein15.html)
 * [Srivastava et al., 2014. Dropout: a simple way to prevent neural networks from overfitting](https://jmlr.org/papers/v15/srivastava14a.html)
 * [Stall et al., 2019. Make scientific data FAIR](https://www.nature.com/articles/d41586-019-01720-7)
 * [Tavallaee et al., 2009. A detailed analysis of the KDD CUP 99 data set](http://ieeexplore.ieee.org/document/5356528)
 * [Thacker et al., 2010. Algorithm 905: SHEPPACK: Modified Shepard algorithm for interpolation of scattered multivariate data](https://dl.acm.org/doi/10.1145/1824801.1824812)
 * [Tian et al., 2022. Improving Simulated Annealing Algorithm for FPGA Placement Based on Reinforcement Learning](https://ieeexplore.ieee.org/document/9836761/)
 * [van der Maaten et al., 2008. Visualizing Data using t-SNE](http://jmlr.org/papers/v9/vandermaaten08a.html)
 * [Vaswani et al., 2017. Attention is all you need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
 * [Vinyals et al., 2019. Grandmaster level in StarCraft II using multi-agent reinforcement learning](https://doi.org/10.1038/s41586-019-1724-z)
 * [Virtanen et al., 2020. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python](https://www.nature.com/articles/s41592-019-0686-2)
 * [Wang et al., 2018. On the numerical rank of radial basis function kernels in high dimensions](https://epubs.siam.org/doi/10.1137/17M1135803)
 * [Wathen et al., 2015. On spectral distribution of kernel matrices related to radial basis functions](http://link.springer.com/10.1007/s11075-015-9970-0)
 * [Weinan, 2020. Machine learning and computational mathematics](https://global-sci.com/article/79736/machine-learning-and-computational-mathematics)
 * [Zhang et al., 2017. Understanding deep learning requires rethinking generalization](https://openreview.net/forum?id=Sy8gdB9xx)
 * [Zhu et al., 1997. Algorithm 778: L-BFGS-B: Fortran Subroutines for Large-Scale Bound-Constrained Optimization](https://dl.acm.org/doi/10.1145/279232.279236)

## optimization

 * [Adams et al., 2022. Dakota, A Multilevel Parallel Object-Oriented Framework for Design Optimization, Parameter Estimation, Uncertainty Quantification, and Sensitivity Analysis: Version 6.16 User's Manual](https://dakota.sandia.gov/sites/default/files/docs/6.16.0/Users-6.16.0.pdf)
 * [Agrawal et al., 2019. Differentiable Convex Optimization Layers](https://proceedings.neurips.cc/paper_files/paper/2019/file/9ce3c52fc54362e22053399d3181c638-Paper.pdf)
 * [Akhtar et al., 2016. Multi objective optimization of computationally expensive multi-modal functions with RBF surrogates and multi-rule selection](http://link.springer.com/10.1007/s10898-015-0270-y)
 * [Akiba et al., 2019. Optuna: A next-generation hyperparameter optimization framework](https://dl.acm.org/doi/10.1145/3292500.3330701)
 * [Al-Dujaili et al., 2016. Dividing rectangles attack multi-objective optimization](http://ieeexplore.ieee.org/document/7744246)
 * [Al-Dujaili et al., 2016. A MATLAB toolbox for surrogate-assisted multi-objective optimization: A preliminary study](https://dl.acm.org/doi/10.1145/2908961.2931703)
 * [Alizadeh et al., 2020. Managing computational complexity using surrogate models: a critical review](https://link.springer.com/10.1007/s00163-020-00336-7)
 * [Amos et al., 2017. OptNet: Differentiable Optimization as a Layer in Neural Networks](https://proceedings.mlr.press/v70/amos17a.html)
 * [Amos et al., 2020. Algorithm 1007: QNSTOP: Quasi-Newton algorithm for stochastic optimization](https://dl.acm.org/doi/10.1145/3374219)
 * [Amos, 2023. Tutorial on Amortized Optimization](https://doi.org/10.1561/2200000102)
 * [Andersen et al., 2000. The MOSEK interior point optimizer for linear programming: an implementation of the homogeneous algorithm](https://link.springer.com/chapter/10.1007/978-1-4757-3216-0_8)
 * [Andreani et al., 2022. Using first-order information in direct multisearch for multiobjective optimization](https://www.tandfonline.com/doi/full/10.1080/10556788.2022.2060971)
 * [Andr\'{e}s-Thi\'{o} et al., 2025. solar: A solar thermal power plant simulator for blackbox optimization benchmarking](https://link.springer.com/10.1007/s11081-024-09952-x)
 * [Applegate et al., 2021. Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient](https://proceedings.neurips.cc/paper_files/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf)
 * [Astudillo et al., 2021. Thinking inside the box: a tutorial on grey-box bayesian optimization](https://ieeexplore.ieee.org/document/9715343)
 * [Audet et al., 2008. Multiobjective optimization through a series of single-objective formulations](http://epubs.siam.org/doi/10.1137/060677513)
 * [Audet et al., 2008. Nonsmooth optimization through Mesh Adaptive Direct Search and Variable Neighborhood Search](http://link.springer.com/10.1007/s10898-007-9234-1)
 * [Audet et al., 2009. A Progressive Barrier for Derivative-Free Nonlinear Programming](http://epubs.siam.org/doi/10.1137/070692662)
 * [Audet et al., 2010. A mesh adaptive direct search algorithm for multiobjective optimization](https://linkinghub.elsevier.com/retrieve/pii/S0377221709008601)
 * [Audet et al., 2017. Derivative-free and blackbox optimization](http://link.springer.com/10.1007/978-3-319-68913-5)
 * [Audet et al., 2021. Performance indicators in multiobjective optimization](https://www.sciencedirect.com/science/article/pii/S0377221720309620)
 * [Audet et al., 2021. Stochastic mesh adaptive direct search for blackbox optimization using probabilistic estimates](https://doi.org/10.1007/s10589-020-00249-0)
 * [Audet et al., 2022. Algorithm 1027: NOMAD Version 4: Nonlinear Optimization with the MADS Algorithm](https://dl.acm.org/doi/10.1145/3544489)
 * [Audet et al., 2023. A general mathematical framework for constrained mixed-variable blackbox optimization problems with meta and categorical variables](https://link.springer.com/10.1007/s43069-022-00180-6)
 * [Ba et al., 2016. Layer Normalization](https://arxiv.org/abs/1607.06450v1)
 * [Balandat et al., 2020. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization](https://proceedings.neurips.cc/paper/2020/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf)
 * [Balaprakash et al., 2018. DeepHyper: Asynchronous hyperparameter search for deep neural networks](https://ieeexplore.ieee.org/document/8638041)
 * [Balay et al., 2022. PETSc/TAO Users Manual](https://petsc.org/release/docs/manual/manual.pdf)
 * [Bambade et al., 2022. PROX-QP: Yet another Quadratic Programming Solver for Robotics and beyond](https://hal.inria.fr/hal-03683733)
 * [Bandyopadhyay et al., 2008. A Simulated Annealing-Based Multiobjective Optimization Algorithm: AMOSA](http://ieeexplore.ieee.org/document/4358775)
 * [Bansal et al., 2022. JAHS-Bench-201: A Foundation For Research On Joint Architecture And Hyperparameter Search](https://proceedings.neurips.cc/paper_files/paper/2022/file/fd78f2f65881c1c7ce47e26b040cf48f-Paper-Datasets_and_Benchmarks.pdf)
 * [Barba-González et al., 2018. jMetalSP: A framework for dynamic multi-objective big data optimization](https://linkinghub.elsevier.com/retrieve/pii/S1568494617302557)
 * [Ben{\'i}tez-Hidalgo et al., 2019. jMetalPy: A Python framework for multi-objective optimization with metaheuristics](https://linkinghub.elsevier.com/retrieve/pii/S2210650219301397)
 * [Bergstra et al., 2011. Algorithms for Hyper-Parameter Optimization](https://proceedings.neurips.cc/paper_files/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf)
 * [Berkemeier et al., 2021. Derivative-Free Multiobjective Trust Region Descent Method Using Radial Basis Function Surrogate Models](https://www.mdpi.com/2297-8747/26/2/31)
 * [Beume et al., 2009. On the complexity of computing the hypervolume indicator](http://ieeexplore.ieee.org/document/5208224)
 * [Bian et al., 2010. Towards scalable placement for FPGAs](https://doi.org/10.1145/1723112.1723140)
 * [Biedron et al., 2019. FUN3D Manual: 13.6](https://fun3d.larc.nasa.gov/papers/FUN3D_Manual-13.6.pdf)
 * [Bigeon et al., 2020. DMulti-MADS: Mesh adaptive direct multisearch for blackbox multiobjective optimization](https://link.springer.com/10.1007/s10589-021-00272-9)
 * [Biscani et al., 2020. A parallel global multiobjective framework for optimization: pagmo](https://joss.theoj.org/papers/10.21105/joss.02338)
 * [Blank et al., 2020. pymoo: Multi-Objective Optimization in Python](https://ieeexplore.ieee.org/document/9078759)
 * [Bollapragada et al., 2020. Optimization and supervised machine learning methods for fitting numerical physics models without derivatives](https://iopscience.iop.org/article/10.1088/1361-6471/abd009)
 * [Bouhlel et al., 2019. A Python surrogate modeling framework with derivatives](https://linkinghub.elsevier.com/retrieve/pii/S0965997818309360)
 * [Boyd et al., 2004. Convex optimization](https://stanford.edu/~boyd/cvxbook/)
 * [Bradford et al., 2018. Efficient multiobjective optimization employing Gaussian processes, spectral sampling and a genetic algorithm](http://link.springer.com/10.1007/s10898-018-0609-2)
 * [Br{\'a}s et al., 2020. On the use of polynomial models in multiobjective directional direct search](https://link.springer.com/10.1007/s10589-020-00233-8)
 * [Bringmann et al., 2013. Approximation quality of the hypervolume indicator](https://linkinghub.elsevier.com/retrieve/pii/S0004370212001178)
 * [Byrd et al., 2006. Knitro: An Integrated Package for Nonlinear Optimization](https://link.springer.com/chapter/10.1007/0-387-30065-1_4)
 * [Campana et al., 2018. A multi-objective DIRECT algorithm for ship hull optimization](http://link.springer.com/10.1007/s10589-017-9955-0)
 * [Caron et al., 2024. qpbenchmark: Benchmark for quadratic programming solvers available in Python](https://github.com/qpsolvers/qpbenchmark)
 * [Chang et al., 2020. Algorithm 1012: DELAUNAYSPARSE: Interpolation via a Sparse Subset of the Delaunay Triangulation in Medium to High Dimensions](https://dl.acm.org/doi/10.1145/3422818)
 * [Chang et al., 2020. Managing computationally expensive blackbox multiobjective optimization problems using libEnsemble](https://dl.acm.org/doi/abs/10.5555/3408207.3408245)
 * [Chang, 2020. Mathematical Software for Multiobjective Optimization Problems](https://vtechworks.lib.vt.edu/handle/10919/98915)
 * [Chang et al., 2020. Multiobjective optimization of the variability of the high-performance LINPACK solver](https://ieeexplore.ieee.org/document/9383875)
 * [Chang et al., 2022. Algorithm 1028: VTMOP: Solver for Blackbox Multiobjective Optimization Problems](https://dl.acm.org/doi/10.1145/3529258)
 * [Chang et al., 2023. A framework for fully autonomous design of materials via multiobjective optimization and active learning: challenges and next steps](https://openreview.net/forum?id=8KJS7RPjMqG)
 * [Chang et al., 2023. ParMOO: A Python library for parallel multiobjective simulation optimization](https://joss.theoj.org/papers/10.21105/joss.04468)
 * [Chang et al., 2024. ParMOO: Python library for parallel multiobjective simulation optimization](https://parmoo.readthedocs.io/en/latest)
 * [Chang et al., 2024. Remark on Algorithm 1012: Computing projections with large data sets](https://dl.acm.org/doi/10.1145/3656581)
 * [Chang et al., 2025. Designing a Framework for Solving Multiobjective Simulation Optimization Problems](https://pubsonline.informs.org/doi/10.1287/ijoc.2023.0250)
 * [Chang et al., 2025. Repository for ``Designing a Framework for Solving Multiobjective Simulation Optimization Problems''](https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0250)
 * [Chen et al., 2017. FPGA placement and routing](http://ieeexplore.ieee.org/document/8203878/)
 * [Chen et al., 2023. An Integrated Multi-Physics Optimization Framework for Particle Accelerator Design](https://doi.com/10.48550/arXiv.2311.09415)
 * [Chugh, 2020. Scalarizing functions in Bayesian multiobjective optimization](https://ieeexplore.ieee.org/document/9185706/)
 * [Cocchi et al., 2018. An implicit filtering algorithm for derivative-free multiobjective optimization with box constraints](http://link.springer.com/10.1007/s10589-017-9953-2)
 * [Cocchi et al., 2020. An augmented Lagrangian algorithm for multi-objective optimization](https://link.springer.com/10.1007/s10589-020-00204-z)
 * [Conn et al., 1992. LANCELOT: A Fortran Package for Large-Scale Nonlinear Optimization (Release A)](http://link.springer.com/10.1007/978-3-662-12211-2)
 * [Conn et al., 2008. Geometry of interpolation sets in derivative free optimization](http://link.springer.com/10.1007/s10107-006-0073-5)
 * [Conn et al., 2009. Introduction to derivative-free optimization](http://epubs.siam.org/doi/book/10.1137/1.9780898718768)
 * [Cooper et al., 2020. PyMOSO: Software for multi-objective simulation optimization with R-PERLE and R-MinRLE](http://pubsonline.informs.org/doi/10.1287/ijoc.2019.0902)
 * [Costa et al., 2018. RBFOpt: an open-source library for black-box optimization with costly function evaluations](http://link.springer.com/10.1007/s12532-018-0144-7)
 * [Cristescu et al., 2015. Surrogate-based multiobjective optimization: ParEGO update and test](https://www.cs.bham.ac.uk/~jdk/UKCI-2015.pdf)
 * [Cust\'odio et al., 2011. Direct Multisearch for Multiobjective Optimization](http://epubs.siam.org/doi/10.1137/10079731X)
 * [Cust{\'{o}}dio et al., 2018. MultiGLODS: global and local multiobjective optimization using direct search](http://link.springer.com/10.1007/s10898-018-0618-1)
 * [Dandurand et al., 2016. Quadratic scalarization for decomposed multiobjective optimization](http://link.springer.com/10.1007/s00291-016-0453-z)
 * [Dantzig, 1998. Linear Programming and Extensions](https://d1wqtxts1xzle7.cloudfront.net/56278680/Libro_Linear_Programming_George_Dantzig-libre.pdf?1523307505=&response-content-disposition=inline%3B+filename%3DLinear_Programming_and_Extensions.pdf&Expires=1746491165&Signature=WQRD07CTKkhpfjxG1R6Kb2tSq0cRnDUia1ETKdgTQX2wbUxpA2p7ZGudVpOpbsKgUZzsKL-U3CddGBaVVSTr~TSLwPadmYe8xHRVZ4KqyB~ms5zyu08vntJ0V-pRNY0sws9H~ktLJTgoABlZMkoYDA23Dbrh07yQqukyaqHsDuoTEZRzng6AIqN7CXO1KW2M4J~rS-M1mmM3bdTSMAoWPozK7Suea-HJPd7QbCMq2hB0JY5mhhi6nUHa6zIQVmjTCcPPdnX9O4lYgYPQgOBiMlIJ5yhYolhlHKXMA~2-g3rbpe4kqJXIEqICSWPByh72uohGvRJkDgUX-CkBw7FZNA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)
 * [Das et al., 1998. Normal-boundary intersection: A new method for generating the Pareto surface in nonlinear multicriteria optimization problems](http://epubs.siam.org/doi/10.1137/S1052623496307510)
 * [Dash et al., 2024. Optimizing Distributed Training on Frontier for Large Language Models](https://ieeexplore.ieee.org/document/10528939/)
 * [Datta et al., 2016. A surrogate-assisted evolution strategy for constrained multi-objective optimization](https://linkinghub.elsevier.com/retrieve/pii/S0957417416301452)
 * [Daulton et al., 2020. Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization](https://proceedings.neurips.cc/paper/2020/file/6fec24eac8f18ed793f5eaad3dd7977c-Paper.pdf)
 * [Daulton et al., 2021. Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement](https://proceedings.neurips.cc/paper/2021/file/11704817e347269b7254e744b5e22dac-Paper.pdf)
 * [Dauphin et al., 2014. Identifying and attacking the saddle point problem in high-dimensional non-convex optimization](https://proceedings.neurips.cc/paper_files/paper/2014/file/04192426585542c54b96ba14445be996-Paper.pdf)
 * [Deb et al., 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II](http://ieeexplore.ieee.org/document/996017)
 * [Deb et al., 2002. Scalable multi-objective optimization test problems](http://ieeexplore.ieee.org/document/1007032)
 * [Deb et al., 2013. An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part I: solving problems with box constraints](http://ieeexplore.ieee.org/document/6600851)
 * [Deshpande et al., 2011. Data driven surrogate-based optimization in the problem solving environment WBCSim](http://link.springer.com/10.1007/s00366-010-0192-8)
 * [Deshpande et al., 2016. Multiobjective optimization using an adaptive weighting scheme](http://www.tandfonline.com/doi/full/10.1080/10556788.2015.1048861)
 * [Diamond et al., 2016. CVXPY: A Python-embedded modeling language for convex optimization](http://jmlr.org/papers/v17/15-408.html)
 * [Domahidi et al., 2013. ECOS: An SOCP solver for embedded systems](https://ieeexplore.ieee.org/document/6669541)
 * [Dong et al., 2020. NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search](https://openreview.net/forum?id=HJxyZkBKDr)
 * [Duchi et al., 2011. Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](http://jmlr.org/papers/v12/duchi11a.html)
 * [Dunlop et al., 2008. On the use of a genetic algorithm in high performance computing benchmark tuning](https://ieeexplore.ieee.org/document/4667550)
 * [Dunning et al., 2017. JuMP: A Modeling Language for Mathematical Optimization](https://epubs.siam.org/doi/10.1137/15M1020575)
 * [Durillo et al., 2011. jMetal: A Java framework for multi-objective optimization](https://linkinghub.elsevier.com/retrieve/pii/S0965997811001219)
 * [Dzahini et al., 2025. A Class of Sparse Johnson–Lindenstrauss Transforms and Analysis of their Extreme Singular Values](https://doi.org/10.1137/23M1605661)
 * [Eckman et al., 2023. SimOpt: A Testbed for Simulation-Optimization Experiments](https://pubsonline.informs.org/doi/10.1287/ijoc.2023.1273)
 * [Egele et al., 2023. Parallel multi-objective hyperparameter optimization with uniform normalization and bounded objectives](https://doi.com/10.48550/arXiv.2309.14936)
 * [Eggensperger et al., 2021. HPOBench: A Collection of Reproducible Multi-Fidelity Benchmark Problems for HPO](https://openreview.net/forum?id=1k4rJYEwda-)
 * [Ehrgott, 2005. Multicriteria Optimization](http://link.springer.com/10.1007/3-540-27659-9)
 * [Eichfelder, 2009. Scalarizations for adaptively solving multi-objective optimization problems](http://link.springer.com/10.1007/s10589-007-9155-4)
 * [Elsken et al., 2019. Neural architecture search: A survey](https://www.jmlr.org/papers/volume20/18-598/18-598.pdf)
 * [Eriksson et al., 2019. Scalable global optimization via local bayesian optimization](https://proceedings.neurips.cc/paper/2019/file/6c990b7aca7bc7058f5e98ea909e924b-Paper.pdf)
 * [Eriksson et al., 2021. Latency-Aware Neural Architecture Search with Multi-Objective Bayesian Optimization](https://openreview.net/forum?id=0ciyfd4SvbI)
 * [Farhan et al., 2020. Reinforcement Learning in AnyLogic Simulation Models: A Guiding Example using Pathmind](https://ieeexplore.ieee.org/document/9383916)
 * [Feldman et al., 2018. SCORE Allocations for Bi-objective Ranking and Selection](https://dl.acm.org/doi/10.1145/3158666)
 * [Feliot et al., 2016. A Bayesian approach to constrained single- and multi-objective optimization](http://link.springer.com/10.1007/s10898-016-0427-3)
 * [Fiduccia et al., 1982. A linear-time heuristic for improving network partitions](http://ieeexplore.ieee.org/document/1585498/)
 * [Fletcher, 1993. Resolving degeneracy in quadratic programming](http://link.springer.com/10.1007/BF02023102)
 * [Fletcher, 2000. Stable reduced Hessian updates for indefinite quadratic programming](http://link.springer.com/10.1007/s101070050113)
 * [Fortin et al., 2012. DEAP: Evolutionary Algorithms Made Easy](https://www.jmlr.org/papers/v13/fortin12a.html)
 * [Fourer et al., 2003. AMPL: A Modeling Language for Mathematical Programming](https://dev.ampl.com/ampl/books/ampl/index.html)
 * [Fowkes et al., 2022. PyCUTEst: an open source Python package of optimization test problems](https://joss.theoj.org/papers/10.21105/joss.04377)
 * [Fowkes et al., 2023. GALAHAD 4.0: an open source library of Fortran packages with C and Matlab interfaces for continuous optimization](https://doi.org/10.21105/joss.04882)
 * [Frazier, 2018. A Tutorial on Bayesian Optimization](http://arxiv.org/abs/1807.02811)
 * [Garnett, 2023. Bayesian Optimization](https://bayesoptbook.com)
 * [Gavin, 2019. The Levenberg-Marquardt algorithm for nonlinear least squares curve-fitting problems](https://people.duke.edu/~hpgavin/lm.pdf)
 * [Goh, 2017. Why Momentum Really Works](http://distill.pub/2017/momentum)
 * [Golovin et al., 2017. Google Vizier: A Service for Black-Box Optimization](https://dl.acm.org/doi/10.1145/3097983.3098043)
 * [Gould et al., 2003. GALAHAD, a library of thread-safe Fortran 90 packages for large-scale nonlinear optimization](https://doi.org/10.1145/962437.962438)
 * [Gould et al., 2015. CUTEst: a Constrained and Unconstrained Testing Environment with safe threads for mathematical optimization](https://doi.org/10.1007/s10589-014-9687-3)
 * [Graves, 2014. Generating Sequences With Recurrent Neural Networks](https://arxiv.org/abs/1308.0850)
 * [Gray et al., 2019. OpenMDAO: An open-source framework for multidisciplinary design, analysis, and optimization](http://link.springer.com/10.1007/s00158-019-02211-z)
 * [Hadka, 2015. Platypus -- multiobjective optimization in Python](https://platypus.readthedocs.io/en/latest)
 * [Hanson et al., 1982. Algorithm 587: Two Algorithms for the Linearly Constrained Least Squares Problem](https://dl.acm.org/doi/10.1145/356004.356010)
 * [Hart et al., 2017. Pyomo -- optimization modeling in Python](http://link.springer.com/10.1007/978-3-319-58821-6)
 * [H{\"a}se et al., 2018. Chimera: enabling hierarchy based multi-objective optimization for self-driving laboratories](https://xlink.rsc.org/?DOI=C8SC02239A)
 * [Hayes et al., 2022. A practical guide to multi-objective reinforcement learning and planning](https://link.springer.com/10.1007/s10458-022-09552-y)
 * [He et al., 2009. Algorithm 897: VTDIRECT95: Serial and Parallel Codes for the Global Optimization Algorithm DIRECT](https://dl.acm.org/doi/10.1145/1527286.1527291)
 * [He et al., 2009. Performance modeling and analysis of a massively parallel DIRECT -- part 1](https://journals.sagepub.com/doi/10.1177/1094342008098463)
 * [He et al., 2016. Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385)
 * [Hoffman et al., 2022. Optimizing molecules using efficient queries from property evaluations](https://www.nature.com/articles/s42256-021-00422-y)
 * [Huangfu et al., 2018. Parallelizing the dual revised simplex method](http://link.springer.com/10.1007/s12532-017-0130-5)
 * [Hunter et al., 2019. An introduction to multiobjective simulation optimization](https://dl.acm.org/doi/10.1145/3299872)
 * [Ishibuchi et al., 2015. Modified distance calculation in generational distance and inverted generational distance](https://dl.acm.org/doi/10.1145/2739480.2754792)
 * [Jain et al., 2013. An evolutionary many-objective optimization algorithm using reference-point based nondominated sorting approach, part II: Handling constraints and extending to an adaptive approach](http://ieeexplore.ieee.org/document/6595567)
 * [Jones et al., 1993. Lipschitzian optimization without the Lipschitz constant](http://link.springer.com/10.1007/BF00941892)
 * [Jones et al., 1998. Efficient global optimization of expensive black-box functions](http://link.springer.com/10.1023/A:1008306431147)
 * [Kandasamy et al., 2020. Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly](http://jmlr.org/papers/v21/18-223.html)
 * [Karl et al., 2023. Multi-Objective Hyperparameter Optimization in Machine Learning -- An Overview](https://dl.acm.org/doi/10.1145/3610536)
 * [Karypis et al., 1998. A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs](http://epubs.siam.org/doi/10.1137/S1064827595287997)
 * [Karypis et al., 1998. hMETIS: A hypergraph partitioning package](https://course.ece.cmu.edu/~ee760/760docs/hMetisManual.pdf)
 * [Karypis et al., 1999. Multilevel hypergraph partitioning: applications in VLSI domain](http://ieeexplore.ieee.org/document/748202/)
 * [Khan et al., 2018. Manifold Sampling for Optimization of Nonconvex Functions that are Piecewise Linear Compositions of Smooth Components](https://epubs.siam.org/doi/10.1137/17M114741X)
 * [Kim et al., 2004. SPEA2+: Improving the performance of the Strength Pareto Evolutionary Algorithm 2](http://link.springer.com/10.1007/978-3-540-30217-9_75)
 * [Kingma et al., 2015. Adam: A method for stochastic optimization](https://arxiv.org/abs/1412.6980)
 * [Klee et al., 1972. How good is the simplex algorithm?](https://en.wikipedia.org/wiki/Klee%E2%80%93Minty_cube)
 * [Knowles, 2006. ParEGO: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems](http://ieeexplore.ieee.org/document/1583627)
 * [Kushner, 1964. A New Method of Locating the Maximum Point of an Arbitrary Multipeak Curve in the Presence of Noise](https://asmedigitalcollection.asme.org/fluidsengineering/article-pdf/86/1/97/5763745/97\_1.pdf)
 * [Lai, 2003. Stochastic approximation](https://projecteuclid.org/journals/annals-of-statistics/volume-31/issue-2/Stochastic-approximation-invited-paper/10.1214/aos/1051027873.full)
 * [Lakhmiri et al., 2021. HyperNOMAD: Hyperparameter Optimization of Deep Neural Networks Using Mesh Adaptive Direct Search](https://dl.acm.org/doi/10.1145/3450975)
 * [Larson et al., 2018. Asynchronously parallel optimization solver for finding multiple minima](http://link.springer.com/10.1007/s12532-017-0131-4)
 * [Larson et al., 2019. Derivative-free optimization methods](https://www.cambridge.org/core/product/identifier/S0962492919000060/type/journal_article)
 * [Larson et al., 2024. Structure-Aware Methods for Expensive Derivative-Free Nonsmooth Composite Optimization](https://link.springer.com/10.1007/s12532-023-00245-5)
 * [Lasserre, 2001. Global optimization with polynomials and the problem of moments](http://epubs.siam.org/doi/10.1137/S1052623400366802)
 * [Laumanns et al., 2006. An efficient, adaptive parameter variation scheme for metaheuristics based on the epsilon-constraint method](https://linkinghub.elsevier.com/retrieve/pii/S0377221704005715)
 * [Le Digabel, 2011. Algorithm 909: NOMAD: Nonlinear Optimization with the MADS Algorithm](https://dl.acm.org/doi/10.1145/1916461.1916468)
 * [Le Digabel et al., 2024. A Taxonomy of Constraints in Black-Box Simulation-Based Optimization](https://link.springer.com/10.1007/s11081-023-09839-3)
 * [Lewis et al., 2002. A Globally Convergent Augmented Lagrangian Pattern Search Algorithm for Optimization with General Constraints and Simple Bounds](http://epubs.siam.org/doi/10.1137/S1052623498339727)
 * [Lindauer et al., 2022. SMAC3: A Versatile Bayesian Optimization Package for Hyperparameter Optimization](http://jmlr.org/papers/v23/21-0888.html)
 * [Liu et al., 2016. A surrogate model assisted evolutionary algorithm for computationally expensive design optimization problems with discrete variables](http://ieeexplore.ieee.org/document/7743986)
 * [Liu et al., 2017. An adaptive sampling approach for Kriging metamodeling by maximizing expected prediction error](https://linkinghub.elsevier.com/retrieve/pii/S009813541730234X)
 * [Liu et al., 2019. DARTS: Differentiable Architecture Search](https://openreview.net/forum?id=S1eYHoC5FX)
 * [Liuzzi et al., 2016. A derivative-free approach to constrained multiobjective nonsmooth optimization](http://epubs.siam.org/doi/10.1137/15M1037810)
 * [Liuzzi et al., 2024. DFO-lib](https://github.com/DerivativeFreeLibrary)
 * [Lovison et al., 2021. On the Extension of the DIRECT Algorithm to Multiple Objectives](https://link.springer.com/10.1007/s10898-020-00942-8)
 * [Lu et al., 2019. NSGA-Net: neural architecture search using multi-objective genetic algorithm](https://doi.org/10.1145/3321707.3321729)
 * [Lux et al., 2020. Analytic test functions for generalizable evaluation of convex optimization techniques](https://ieeexplore.ieee.org/document/9368254/)
 * [Mannor et al., 2014. Approachability in unknown games: Online learning meets multi-objective optimization](https://proceedings.mlr.press/v35/mannor14.html)
 * [Marler et al., 2004. Survey of multi-objective optimization methods for engineering](http://link.springer.com/10.1007/s00158-003-0368-6)
 * [M{\"a}rtens et al., 2013. The asynchronous island model and NSGA-II: study of a new migration operator and its performance](https://doi.org/10.1145/2463372.2463516)
 * [Martins et al., 2009. pyMDO: An Object-Oriented Framework for Multidisciplinary Design Optimization](https://dl.acm.org/doi/10.1145/1555386.1555389)
 * [Megiddo, 1991. On finding primal- and dual-optimal bases](https://pubsonline.informs.org/doi/10.1287/ijoc.3.1.63)
 * [Misitano et al., 2021. DESDEO: The Modular and Open Source Framework for Interactive Multiobjective Optimization](https://ieeexplore.ieee.org/document/9591595)
 * [Mor\'{e} et al., 2009. Benchmarking Derivative-Free Optimization Algorithms](http://epubs.siam.org/doi/10.1137/080724083)
 * [Moriwaki et al., 2018. Mordred: a molecular descriptor calculator](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0258-y)
 * [M{\"u}ller, 2017. SOCEMO: Surrogate optimization of computationally expensive multiobjective problems](https://pubsonline.informs.org/doi/10.1287/ijoc.2017.0749)
 * [Munson et al., 2015. TAO 3.5 Users Manual](https://www.mcs.anl.gov/petsc/petsc-3.5.4/docs/tao_manual.pdf)
 * [Myers et al., 2016. Response Surface Methodology: Process and Design Optimization Using Designed Experiments](https://books.google.com/books?hl=en&lr=&id=T-BbCwAAQBAJ&oi=fnd&pg=PR13&dq=Response+Surface+Methodology:+Process+and+Product+Optimization+Using+Designed+Experiments,+4th+Edition&ots=O3jdPna83T&sig=IimJlE46JBVkHOu7eik3RN9Z5GA#v=onepage&q=Response%20Surface%20Methodology%3A%20Process%20and%20Product%20Optimization%20Using%20Designed%20Experiments%2C%204th%20Edition&f=false)
 * [Nesterov, 1983. A method for solving the convex programming problem with convergence rate $O(1/k^2)$](https://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=dan&paperid=46009&option_lang=eng)
 * [Neveu et al., 2023. Comparison of multiobjective optimization methods for the LCLS-II photoinjector](https://linkinghub.elsevier.com/retrieve/pii/S0010465522002855)
 * [Nocedal et al., 2006. Numerical Optimization](http://link.springer.com/10.1007/978-0-387-40065-5)
 * [O'Donoghue et al., 2016. Conic Optimization via Operator Splitting and Homogeneous Self-Dual Embedding](http://link.springer.com/10.1007/s10957-016-0892-3)
 * [Parsa et al., 2019. PABO: Pseudo Agent-Based Multi-Objective Bayesian Hyperparameter Optimization for Efficient Neural Accelerator Design](https://ieeexplore.ieee.org/document/8942046)
 * [Parsa et al., 2020. Bayesian Multi-objective Hyperparameter Optimization for Accurate, Fast, and Efficient Neural Network Accelerator Design](https://www.frontiersin.org/article/10.3389/fnins.2020.00667/full)
 * [Pfisterer et al., 2022. YAHPO Gym - An Efficient Multi-Objective Multi-Fidelity Benchmark for Hyperparameter Optimization](https://proceedings.mlr.press/v188/pfisterer22a.html)
 * [Powell, 1994. A direct search optimization method that models the objective and constraint functions by linear interpolation](http://link.springer.com/10.1007/978-94-015-8330-5_4)
 * [Raghunath et al., 2017. Global deterministic and stochastic optimization in a service oriented architecture](http://dl.acm.org/citation.cfm?id=3108103)
 * [Ragonneau et al., 2021. PDFO: Cross-Platform Interfaces for Powell’s Derivative-Free Optimization Solvers](https://github.com/pdfo/pdfo)
 * [Regis, 2015. The calculus of simplex gradients](http://link.springer.com/10.1007/s11590-014-0815-x)
 * [Regis, 2016. Multi-objective constrained black-box optimization using radial basis function surrogates](http://linkinghub.elsevier.com/retrieve/pii/S1877750316300904)
 * [Ryu et al., 2009. Pareto front approximation with adaptive weighted sum method in multiobjective simulation optimization](http://ieeexplore.ieee.org/document/5429562)
 * [Ryu et al., 2014. A derivative-free trust-region method for biobjective optimization](http://epubs.siam.org/doi/10.1137/120864738)
 * [Sapsis et al., 2022. Optimal criteria and their asymptotic form for data selection in data-driven reduced-order modelling with Gaussian process regression](https://royalsocietypublishing.org/doi/10.1098/rsta.2021.0197)
 * [Saves et al., 2024. SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes](https://www.sciencedirect.com/science/article/pii/S096599782300162X)
 * [Schulman et al., 2017. Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)
 * [Schweidtmann et al., 2018. Machine learning meets continuous flow chemistry: Automated optimization towards the Pareto front of multiple objectives](https://linkinghub.elsevier.com/retrieve/pii/S1385894718312634)
 * [Shang et al., 2020. A survey on the hypervolume indicator in evolutionary multiobjective optimization](https://ieeexplore.ieee.org/document/9153850)
 * [Shashaani et al., 2016. ASTRO-DF: Adaptive sampling trust-region optimization algorithms, heuristics, and numerical experience](http://ieeexplore.ieee.org/document/7822121/)
 * [Shi et al., 2023. On the numerical performance of finite-difference-based methods for derivative-free optimization](https://doi.org/10.1080/10556788.2022.2121832)
 * [Shields et al., 2021. Bayesian reaction optimization as a tool for chemical synthesis](https://www.nature.com/articles/s41586-021-03213-y)
 * [Smale, 1998. Mathematical problems for the next century](http://link.springer.com/10.1007/BF03025291)
 * [Sobieszczanski-Sobieski et al., 2015. Multidisciplinary Design Optimization Supported by Knowledge Based Engineering](https://doi.com/10.1002/9781118897072)
 * [Stellato et al., 2020. OSQP: an operator splitting solver for quadratic programs](http://link.springer.com/10.1007/s12532-020-00179-2)
 * [Steuer et al., 1983. An interactive weighted Tchebycheff procedure for multiple objective programming](http://link.springer.com/10.1007/BF02591870)
 * [2005. Evolutionary Multiobjective Optimization: Theoretical Advances and Applications](http://link.springer.com/10.1007/1-84628-137-7)
 * [Tavares et al., 2022. Parallel Strategies for Direct Multisearch](https://link.springer.com/10.1007/s11075-022-01364-1)
 * [Thomann et al., 2019. A Trust-Region Algorithm for Heterogeneous Multiobjective Optimization](https://epubs.siam.org/doi/10.1137/18M1173277)
 * [Tian et al., 2017. PlatEMO: A MATLAB Platform for Evolutionary Multi-Objective Optimization [Educational Forum]](http://ieeexplore.ieee.org/document/8065138)
 * [Tian et al., 2022. Improving Simulated Annealing Algorithm for FPGA Placement Based on Reinforcement Learning](https://ieeexplore.ieee.org/document/9836761/)
 * [Tu\vsar et al., 2015. Visualization of Pareto Front Approximations in Evolutionary Multiobjective Optimization: A Critical Review and the Prosection Method](https://ieeexplore.ieee.org/document/6777535)
 * [Urquhart et al., 2020. Surrogate-based optimisation using adaptively scaled radial basis functions](https://linkinghub.elsevier.com/retrieve/pii/S1568494619308324)
 * [Vanaret et al., 2024. Unifying nonlinearly constrained nonconvex optimization](https://arxiv.org/abs/2406.13454)
 * [Vandevender et al., 1982. The SLATEC Mathematical Subroutine Library](https://dl.acm.org/doi/10.1145/1057594.1057595)
 * [Virtanen et al., 2020. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python](https://www.nature.com/articles/s41592-019-0686-2)
 * [Watson et al., 1997. Algorithm 777: HOMPACK90: A suite of Fortran 90 codes for globally convergent homotopy algorithms](https://dl.acm.org/doi/10.1145/279232.279235)
 * [Whaley et al., 2001. Automated empirical optimizations of software and the ATLAS project](https://linkinghub.elsevier.com/retrieve/pii/S0167819100000879)
 * [Wierzbicki, 1999. Reference Point Approaches](http://link.springer.com/10.1007/978-1-4615-5025-9_9)
 * [Wild et al., 2008. ORBIT: Optimization by Radial Basis Function Interpolation in Trust-Regions](http://epubs.siam.org/doi/10.1137/070691814)
 * [Wild et al., 2011. Global Convergence of Radial Basis Function Trust Region Derivative-Free Algorithms](http://epubs.siam.org/doi/10.1137/09074927X)
 * [Wild, 2017. Solving Derivative-Free Nonlinear Least Squares Problems with POUNDERS](http://www.mcs.anl.gov/papers/P5120-0414.pdf)
 * [Wong et al., 2016. Hypervolume-Based DIRECT for Multi-Objective Optimisation](https://dl.acm.org/doi/10.1145/2908961.2931702)
 * [Wu et al., 2025. ytopt: Autotuning Scientific Applications for Energy Efficiency at Large Scales](https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.8322)
 * [Wächter et al., 2006. On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming](http://link.springer.com/10.1007/s10107-004-0559-y)
 * [Xin et al., 2018. Interactive Multiobjective Optimization: A Review of the State-of-the-Art](https://ieeexplore.ieee.org/document/8412189)
 * [Yang et al., 2019. Multi-Objective Bayesian Global Optimization Using Expected Hypervolume Improvement Gradient](https://linkinghub.elsevier.com/retrieve/pii/S2210650217307861)
 * [Yang et al., 2019. A multi-point mechanism of expected hypervolume improvement for parallel multi-objective Bayesian global optimization](https://dl.acm.org/doi/10.1145/3321707.3321784)
 * [Yuan et al., 2023. Active learning to overcome exponential-wall problem for effective structure prediction of chemical-disordered materials](https://www.nature.com/articles/s41524-023-00967-z)
 * [Yukish, 2004. Algorithms to identify Pareto points in multi-dimensional data sets](https://etda.libraries.psu.edu/catalog/6336)
 * [Zhang et al., 2010. A Derivative-Free Algorithm for Least-Squares Minimization](http://epubs.siam.org/doi/10.1137/09075531X)
 * [Zhang et al., 2012. On the Local Convergence of a Derivative-Free Algorithm for Least-Squares Minimization](http://link.springer.com/10.1007/s10589-010-9367-x)
 * [Zhang, 2023. PRIMA: Reference Implementation for Powell's Methods with Modernization and Amelioration](http://www.libprima.net)
 * [Zhao et al., 2018. Multiobjective Optimization of Composite Flying-wings with SpaRibs and Multiple Control Surfaces](https://arc.aiaa.org/doi/10.2514/6.2018-3424)
 * [Zhu et al., 1997. Algorithm 778: L-BFGS-B: Fortran Subroutines for Large-Scale Bound-Constrained Optimization](https://dl.acm.org/doi/10.1145/279232.279236)
 * [Zitzler et al., 2001. SPEA2: Improving the strength Pareto evolutionary algorithm](https://doi.com/10.3929/ethz-a-004284029)

## HPC

 * [Adams et al., 2022. Dakota, A Multilevel Parallel Object-Oriented Framework for Design Optimization, Parameter Estimation, Uncertainty Quantification, and Sensitivity Analysis: Version 6.16 User's Manual](https://dakota.sandia.gov/sites/default/files/docs/6.16.0/Users-6.16.0.pdf)
 * [Akiba et al., 2019. Optuna: A next-generation hyperparameter optimization framework](https://dl.acm.org/doi/10.1145/3292500.3330701)
 * [Anderson et al., 1999. LAPACK Users' Guide](https://netlib.org/lapack/lug/)
 * [Audet et al., 2022. Algorithm 1027: NOMAD Version 4: Nonlinear Optimization with the MADS Algorithm](https://dl.acm.org/doi/10.1145/3544489)
 * [Balandat et al., 2020. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization](https://proceedings.neurips.cc/paper/2020/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf)
 * [Balaprakash et al., 2018. DeepHyper: Asynchronous hyperparameter search for deep neural networks](https://ieeexplore.ieee.org/document/8638041)
 * [Balay et al., 2022. PETSc/TAO Users Manual](https://petsc.org/release/docs/manual/manual.pdf)
 * [Barba-González et al., 2018. jMetalSP: A framework for dynamic multi-objective big data optimization](https://linkinghub.elsevier.com/retrieve/pii/S1568494617302557)
 * [Barker et al., 2022. Introducing the FAIR Principles for research software](https://www.nature.com/articles/s41597-022-01710-x)
 * [Biedron et al., 2019. FUN3D Manual: 13.6](https://fun3d.larc.nasa.gov/papers/FUN3D_Manual-13.6.pdf)
 * [Blackford et al., 1997. ScaLAPACK Users' Guide](https://www.netlib.org/scalapack/)
 * [Bradbury et al., 2018. JAX: composable transformations of Python+NumPy programs](http://github.com/google/jax)
 * [Cameron et al., 2019. MOANA: Modeling and analyzing I/O variability in parallel system experimental design](https://ieeexplore.ieee.org/document/8631172)
 * [Cao et al., 2017. On the performance variation in modern storage stacks](https://www.usenix.org/conference/fast17/technical-sessions/presentation/cao)
 * [Capps et al., 2016. IOzone Filesystem Benchmark](www.iozone.org)
 * [Chandy et al., 1997. A parallel circuit-partitioned algorithm for timing driven cell placement](http://ieeexplore.ieee.org/document/628930/)
 * [Chang et al., 2018. Predicting system performance by interpolation using a high-dimensional Delaunay triangulation](https://par.nsf.gov/servlets/purl/10111451)
 * [Chang et al., 2020. Algorithm 1012: DELAUNAYSPARSE: Interpolation via a Sparse Subset of the Delaunay Triangulation in Medium to High Dimensions](https://dl.acm.org/doi/10.1145/3422818)
 * [Chang et al., 2020. Managing computationally expensive blackbox multiobjective optimization problems using libEnsemble](https://dl.acm.org/doi/abs/10.5555/3408207.3408245)
 * [Chang, 2020. Mathematical Software for Multiobjective Optimization Problems](https://vtechworks.lib.vt.edu/handle/10919/98915)
 * [Chang et al., 2020. Multiobjective optimization of the variability of the high-performance LINPACK solver](https://ieeexplore.ieee.org/document/9383875)
 * [Chang et al., 2022. Algorithm 1028: VTMOP: Solver for Blackbox Multiobjective Optimization Problems](https://dl.acm.org/doi/10.1145/3529258)
 * [Chang et al., 2023. ParMOO: A Python library for parallel multiobjective simulation optimization](https://joss.theoj.org/papers/10.21105/joss.04468)
 * [Chang et al., 2024. ParMOO: Python library for parallel multiobjective simulation optimization](https://parmoo.readthedocs.io/en/latest)
 * [Chang et al., 2025. Designing a Framework for Solving Multiobjective Simulation Optimization Problems](https://pubsonline.informs.org/doi/10.1287/ijoc.2023.0250)
 * [Chang et al., 2025. Repository for ``Designing a Framework for Solving Multiobjective Simulation Optimization Problems''](https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0250)
 * [Chard et al., 2020. funcX: A federated function serving fabric for science](https://dl.acm.org/doi/10.1145/3369583.3392683)
 * [Chen et al., 2016. XGBoost: A Scalable Tree Boosting System](https://dl.acm.org/doi/10.1145/2939672.2939785)
 * [Chen et al., 2023. An Integrated Multi-Physics Optimization Framework for Particle Accelerator Design](https://doi.com/10.48550/arXiv.2311.09415)
 * [Dantzig, 1998. Linear Programming and Extensions](https://d1wqtxts1xzle7.cloudfront.net/56278680/Libro_Linear_Programming_George_Dantzig-libre.pdf?1523307505=&response-content-disposition=inline%3B+filename%3DLinear_Programming_and_Extensions.pdf&Expires=1746491165&Signature=WQRD07CTKkhpfjxG1R6Kb2tSq0cRnDUia1ETKdgTQX2wbUxpA2p7ZGudVpOpbsKgUZzsKL-U3CddGBaVVSTr~TSLwPadmYe8xHRVZ4KqyB~ms5zyu08vntJ0V-pRNY0sws9H~ktLJTgoABlZMkoYDA23Dbrh07yQqukyaqHsDuoTEZRzng6AIqN7CXO1KW2M4J~rS-M1mmM3bdTSMAoWPozK7Suea-HJPd7QbCMq2hB0JY5mhhi6nUHa6zIQVmjTCcPPdnX9O4lYgYPQgOBiMlIJ5yhYolhlHKXMA~2-g3rbpe4kqJXIEqICSWPByh72uohGvRJkDgUX-CkBw7FZNA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)
 * [Dash et al., 2024. Optimizing Distributed Training on Frontier for Large Language Models](https://ieeexplore.ieee.org/document/10528939/)
 * [De et al., 2008. A trace-driven emulation framework to predict scalability of large clusters in presence of OS jitter](http://ieeexplore.ieee.org/document/4663776)
 * [Dean et al., 2008. MapReduce: simplified data processing on large clusters](https://doi.org/10.1145/1327452.1327492)
 * [Dean et al., 2013. The tail at scale](https://research.google/pubs/the-tail-at-scale)
 * [2019. Press Release: U.S.\ Department of Energy and Intel to deliver first exascale supercomputer](https://www.anl.gov/article/us-department-of-energy-and-intel-to-deliver-first-exascale-supercomputer)
 * [Devlin et al., 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://aclanthology.org/N19-1423/)
 * [Dongarra et al., 2003. The LINPACK benchmark: past, present, and future](https://onlinelibrary.wiley.com/doi/10.1002/cpe.728)
 * [Dubey et al., 2021. Performance Portability in the Exascale Computing Project: Exploration Through a Panel Series](https://ieeexplore.ieee.org/document/9495114)
 * [Dunlop et al., 2008. On the use of a genetic algorithm in high performance computing benchmark tuning](https://ieeexplore.ieee.org/document/4667550)
 * [Dunning et al., 2017. JuMP: A Modeling Language for Mathematical Optimization](https://epubs.siam.org/doi/10.1137/15M1020575)
 * [Elias et al., 2020. The Manufacturing Data and Machine Learning Platform: Enabling Real-time Monitoring and Control of Scientific Experiments via IoT](https://ieeexplore.ieee.org/document/9221078)
 * [Fortin et al., 2012. DEAP: Evolutionary Algorithms Made Easy](https://www.jmlr.org/papers/v13/fortin12a.html)
 * [Forum, 2023. MPI: A Message-Passing Interface Standard](https://www.mpi-forum.org/docs/mpi-4.1/mpi41-report.pdf)
 * [Germann, 2021. Co-design in the Exascale Computing Project](https://journals.sagepub.com/doi/10.1177/10943420211059380)
 * [Golub et al., 2013. Matrix computations](https://www.press.jhu.edu/books/title/10678/matrix-computations)
 * [Grattafiori et al., 2024. The LLaMA 3 herd of models](https://arxiv.org/abs/2407.21783)
 * [Gray et al., 2019. OpenMDAO: An open-source framework for multidisciplinary design, analysis, and optimization](http://link.springer.com/10.1007/s00158-019-02211-z)
 * [Hanson et al., 1982. Algorithm 587: Two Algorithms for the Linearly Constrained Least Squares Problem](https://dl.acm.org/doi/10.1145/356004.356010)
 * [Harris et al., 2020. Array programming with NumPy](https://www.nature.com/articles/s41586-020-2649-2)
 * [He et al., 2009. Algorithm 897: VTDIRECT95: Serial and Parallel Codes for the Global Optimization Algorithm DIRECT](https://dl.acm.org/doi/10.1145/1527286.1527291)
 * [He et al., 2009. Performance modeling and analysis of a massively parallel DIRECT -- part 1](https://journals.sagepub.com/doi/10.1177/1094342008098463)
 * [Heroux et al., 2020. Advancing Scientific Productivity through Better Scientific Software: Developer Productivity and Software Sustainability Report](https://www.osti.gov/servlets/purl/1606662)
 * [Hert et al., 2020. dD Convex Hulls and Delaunay Triangulations](https://doc.cgal.org/5.0.2/Manual/packages.html#PkgConvexHullD)
 * [Huang et al., 2019. Cpp-Taskflow: Fast Task-Based Parallel Programming Using Modern C++](https://ieeexplore.ieee.org/document/8821011/)
 * [Huangfu et al., 2018. Parallelizing the dual revised simplex method](http://link.springer.com/10.1007/s12532-017-0130-5)
 * [Hudson et al., 2022. libEnsemble: A Library to Coordinate the Concurrent Evaluation of Dynamic Ensembles of Calculations](https://ieeexplore.ieee.org/document/9439163)
 * [Hudson et al., 2023. libEnsemble: A complete Python toolkit for dynamic ensembles of calculations](https://joss.theoj.org/papers/10.21105/joss.06031)
 * [Intel, 2025. oneAPI Threading Building Blocks (oneTBB)](https://uxlfoundation.github.io/oneTBB)
 * [2004. Information technology -- Programming languages -- Fortran -- Part 1: Base Language](https://j3-fortran.org/doc/year/04/04-007.pdf)
 * [2010. Information technology -- Programming languages -- Fortran -- Part 1: Base Language](https://j3-fortran.org/doc/year/10/10-007.pdf)
 * [Kale et al., 1993. CHARM++: a portable concurrent object oriented system based on C++](https://dl.acm.org/doi/10.1145/165854.165874)
 * [Kleen, 2005. A NUMA API for Linux](https://halobates.de/numaapi3.pdf)
 * [Kolonay et al., 2011. Service oriented computing environment (SORCER) for large scale, distributed, dynamic fidelity aeroelastic analysis](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.656.7539)
 * [Kreps et al., 2011. Kafka: A distributed messaging system for log processing](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/09/Kafka.pdf)
 * [Krizhevsky et al., 2012. ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
 * [Lasalle et al., 2013. Multi-threaded Graph Partitioning](http://ieeexplore.ieee.org/document/6569814/)
 * [Lavely, 2022. Powering Extreme-Scale HPC with Cerebras Wafer-Scale Accelerators](https://8968533.fs1.hubspotusercontent-na1.net/hubfs/8968533/Powering-Extreme-Scale-HPC-with-Cerebras.pdf)
 * [Le Digabel, 2011. Algorithm 909: NOMAD: Nonlinear Optimization with the MADS Algorithm](https://dl.acm.org/doi/10.1145/1916461.1916468)
 * [Liu et al., 2024. DeepSeek-V3 technical report](https://doi.com/10.48550/arXiv.2412.19437)
 * [Louw et al., 2021. Using the Graphcore IPU for traditional HPC applications](https://easychair.org/publications/preprint/ztfj)
 * [Luo et al., 2020. Pre-exascale accelerated application development: The ORNL Summit experience](https://ieeexplore.ieee.org/document/8960361)
 * [Lux et al., 2018. Nonparametric distribution models for predicting and managing computational performance variability](https://ieeexplore.ieee.org/document/8478814)
 * [Lux et al., 2018. Predictive modeling of I/O characteristics in high performance computing systems](https://par.nsf.gov/servlets/purl/10111447)
 * [M{\"a}rtens et al., 2013. The asynchronous island model and NSGA-II: study of a new migration operator and its performance](https://doi.org/10.1145/2463372.2463516)
 * [Mayes, 2023. PySuperfish](https://github.com/ChristopherMayes/PySuperfish)
 * [Menzel et al., 1987. Users guide for the POISSON/SUPERFISH group of codes](https://www.osti.gov/servlets/purl/10140823)
 * [Mills et al., 2021. Toward performance-portable PETSc for GPU-based exascale systems](https://linkinghub.elsevier.com/retrieve/pii/S016781912100079X)
 * [Munson et al., 2015. TAO 3.5 Users Manual](https://www.mcs.anl.gov/petsc/petsc-3.5.4/docs/tao_manual.pdf)
 * [Neveu et al., 2023. Comparison of multiobjective optimization methods for the LCLS-II photoinjector](https://linkinghub.elsevier.com/retrieve/pii/S0010465522002855)
 * [NVIDIA Corporation, 2025. cuBLAS API](https://docs.nvidia.com/cuda/pdf/CUBLAS_Library.pdf)
 * [NVIDIA HPC Compilers, 2025. CUDA Fortran programming guide](https://docs.nvidia.com/hpc-sdk/archive/23.3/pdf/hpc233cudaforug.pdf)
 * [OpenMP, 2015. OpenMP Application Programming Interface](https://www.openmp.org/wp-content/uploads/openmp-4.5.pdf)
 * [Paszke et al., 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf)
 * [Petitet et al., 2018. HPL -- A Portable Implementation of the High-Performance Linpack Benchmark for Distributed-Memory Computers](https://www.netlib.org/benchmark/hpl/)
 * [Petrini et al., 2003. The case of the missing supercomputer performance: Achieving optimal performance on the 8,192 processors of ASCI Q](https://dl.acm.org/doi/10.1145/1048935.1050204)
 * [Raghunath et al., 2017. Global deterministic and stochastic optimization in a service oriented architecture](http://dl.acm.org/citation.cfm?id=3108103)
 * [Shroff et al., 1992. Adaptive condition estimation for rank-one updates of QR factorizations](http://epubs.siam.org/doi/10.1137/0613077)
 * [Slepicka, 2020. Poisson Superfish via Docker](https://github.com/hhslepicka/docker-poisson-superfish-nobin)
 * [Stall et al., 2019. Make scientific data FAIR](https://www.nature.com/articles/d41586-019-01720-7)
 * [Strohmaier et al., 2019. The Top 500 List](https://www.top500.org)
 * [Tavares et al., 2022. Parallel Strategies for Direct Multisearch](https://link.springer.com/10.1007/s11075-022-01364-1)
 * [Trott et al., 2022. Kokkos 3: Programming Model Extensions for the Exascale Era](https://ieeexplore.ieee.org/document/9485033/)
 * [Vandevender et al., 1982. The SLATEC Mathematical Subroutine Library](https://dl.acm.org/doi/10.1145/1057594.1057595)
 * [Virtanen et al., 2020. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python](https://www.nature.com/articles/s41592-019-0686-2)
 * [Voss et al., 2019. TBB on NUMA Architectures](https://doi.org/10.1007/978-1-4842-4398-5_20)
 * [Wang et al., 2023. Design strategies and approximation methods for high-performance computing variability management](https://www.tandfonline.com/doi/full/10.1080/00224065.2022.2035285)
 * [Whaley et al., 2001. Automated empirical optimizations of software and the ATLAS project](https://linkinghub.elsevier.com/retrieve/pii/S0167819100000879)
 * [Wu et al., 2025. ytopt: Autotuning Scientific Applications for Energy Efficiency at Large Scales](https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.8322)
 * [Xiong et al., 2023. DREAMPlaceFPGA-MP: An Open-Source GPU-Accelerated Macro Placer for Modern FPGAs with Cascade Shapes and Region Constraints](https://arxiv.org/abs/2311.08582)
 * [Xu et al., 2020. Modeling I/O performance variability in high-performance computing systems using mixture distributions](https://linkinghub.elsevier.com/retrieve/pii/S0743731519302746)
 * [Zhang, 2023. PRIMA: Reference Implementation for Powell's Methods with Modernization and Amelioration](http://www.libprima.net)
 * [Zhu et al., 1997. Algorithm 778: L-BFGS-B: Fortran Subroutines for Large-Scale Bound-Constrained Optimization](https://dl.acm.org/doi/10.1145/279232.279236)

## software

 * [Adams et al., 2022. Dakota, A Multilevel Parallel Object-Oriented Framework for Design Optimization, Parameter Estimation, Uncertainty Quantification, and Sensitivity Analysis: Version 6.16 User's Manual](https://dakota.sandia.gov/sites/default/files/docs/6.16.0/Users-6.16.0.pdf)
 * [Agrawal et al., 2019. Differentiable Convex Optimization Layers](https://proceedings.neurips.cc/paper_files/paper/2019/file/9ce3c52fc54362e22053399d3181c638-Paper.pdf)
 * [Akiba et al., 2019. Optuna: A next-generation hyperparameter optimization framework](https://dl.acm.org/doi/10.1145/3292500.3330701)
 * [AMD Vivado Developers, 2024. Vivado Design Suite User Guide](https://docs.amd.com/r/2024.1-English/ug893-vivado-ide)
 * [Amos et al., 2020. Algorithm 1007: QNSTOP: Quasi-Newton algorithm for stochastic optimization](https://dl.acm.org/doi/10.1145/3374219)
 * [Andersen et al., 2000. The MOSEK interior point optimizer for linear programming: an implementation of the homogeneous algorithm](https://link.springer.com/chapter/10.1007/978-1-4757-3216-0_8)
 * [Anderson et al., 1999. LAPACK Users' Guide](https://netlib.org/lapack/lug/)
 * [Andr\'{e}s-Thi\'{o} et al., 2025. solar: A solar thermal power plant simulator for blackbox optimization benchmarking](https://link.springer.com/10.1007/s11081-024-09952-x)
 * [Applegate et al., 2021. Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient](https://proceedings.neurips.cc/paper_files/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf)
 * [Audet et al., 2008. Nonsmooth optimization through Mesh Adaptive Direct Search and Variable Neighborhood Search](http://link.springer.com/10.1007/s10898-007-9234-1)
 * [Audet et al., 2021. Stochastic mesh adaptive direct search for blackbox optimization using probabilistic estimates](https://doi.org/10.1007/s10589-020-00249-0)
 * [Audet et al., 2022. Algorithm 1027: NOMAD Version 4: Nonlinear Optimization with the MADS Algorithm](https://dl.acm.org/doi/10.1145/3544489)
 * [Balandat et al., 2020. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization](https://proceedings.neurips.cc/paper/2020/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf)
 * [Balaprakash et al., 2018. DeepHyper: Asynchronous hyperparameter search for deep neural networks](https://ieeexplore.ieee.org/document/8638041)
 * [Balay et al., 2022. PETSc/TAO Users Manual](https://petsc.org/release/docs/manual/manual.pdf)
 * [Bambade et al., 2022. PROX-QP: Yet another Quadratic Programming Solver for Robotics and beyond](https://hal.inria.fr/hal-03683733)
 * [Bansal et al., 2022. JAHS-Bench-201: A Foundation For Research On Joint Architecture And Hyperparameter Search](https://proceedings.neurips.cc/paper_files/paper/2022/file/fd78f2f65881c1c7ce47e26b040cf48f-Paper-Datasets_and_Benchmarks.pdf)
 * [Barba-González et al., 2018. jMetalSP: A framework for dynamic multi-objective big data optimization](https://linkinghub.elsevier.com/retrieve/pii/S1568494617302557)
 * [Barber et al., 1996. The Quickhull algorithm for convex hulls](https://dl.acm.org/doi/10.1145/235815.235821)
 * [Barker et al., 2022. Introducing the FAIR Principles for research software](https://www.nature.com/articles/s41597-022-01710-x)
 * [Ben{\'i}tez-Hidalgo et al., 2019. jMetalPy: A Python framework for multi-objective optimization with metaheuristics](https://linkinghub.elsevier.com/retrieve/pii/S2210650219301397)
 * [Betz et al., 1997. VPR: a new packing, placement and routing tool for FPGA research](https://link.springer.com/chapter/10.1007/3-540-63465-7_226)
 * [Biedron et al., 2019. FUN3D Manual: 13.6](https://fun3d.larc.nasa.gov/papers/FUN3D_Manual-13.6.pdf)
 * [Biscani et al., 2020. A parallel global multiobjective framework for optimization: pagmo](https://joss.theoj.org/papers/10.21105/joss.02338)
 * [Blackford et al., 1997. ScaLAPACK Users' Guide](https://www.netlib.org/scalapack/)
 * [Blank et al., 2020. pymoo: Multi-Objective Optimization in Python](https://ieeexplore.ieee.org/document/9078759)
 * [Bouhlel et al., 2019. A Python surrogate modeling framework with derivatives](https://linkinghub.elsevier.com/retrieve/pii/S0965997818309360)
 * [Bradbury et al., 2018. JAX: composable transformations of Python+NumPy programs](http://github.com/google/jax)
 * [Bratley et al., 1988. Algorithm 659: Implementing Sobol's Quasirandom Sequence Generator](https://doi.org/10.1145/42288.214372)
 * [Brockman et al., 2016. OpenAI Gym](https://github.com/openai/gym)
 * [Byrd et al., 2006. Knitro: An Integrated Package for Nonlinear Optimization](https://link.springer.com/chapter/10.1007/0-387-30065-1_4)
 * [Capps et al., 2016. IOzone Filesystem Benchmark](www.iozone.org)
 * [Caron et al., 2024. qpbenchmark: Benchmark for quadratic programming solvers available in Python](https://github.com/qpsolvers/qpbenchmark)
 * [Chang et al., 2020. Algorithm 1012: DELAUNAYSPARSE: Interpolation via a Sparse Subset of the Delaunay Triangulation in Medium to High Dimensions](https://dl.acm.org/doi/10.1145/3422818)
 * [Chang, 2020. Mathematical Software for Multiobjective Optimization Problems](https://vtechworks.lib.vt.edu/handle/10919/98915)
 * [Chang et al., 2022. Algorithm 1028: VTMOP: Solver for Blackbox Multiobjective Optimization Problems](https://dl.acm.org/doi/10.1145/3529258)
 * [Chang et al., 2023. ParMOO: A Python library for parallel multiobjective simulation optimization](https://joss.theoj.org/papers/10.21105/joss.04468)
 * [Chang et al., 2024. ParMOO: Python library for parallel multiobjective simulation optimization](https://parmoo.readthedocs.io/en/latest)
 * [Chang et al., 2025. Designing a Framework for Solving Multiobjective Simulation Optimization Problems](https://pubsonline.informs.org/doi/10.1287/ijoc.2023.0250)
 * [Chang et al., 2025. Repository for ``Designing a Framework for Solving Multiobjective Simulation Optimization Problems''](https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0250)
 * [Chard et al., 2020. funcX: A federated function serving fabric for science](https://dl.acm.org/doi/10.1145/3369583.3392683)
 * [Chen et al., 2016. XGBoost: A Scalable Tree Boosting System](https://dl.acm.org/doi/10.1145/2939672.2939785)
 * [Chollet et al., 2015. Keras](https://keras.io)
 * [Chowdhary et al., 2024. PyOED: An Extensible Suite for Data Assimilation and Model-Constrained Optimal Design of Experiments](https://dl.acm.org/doi/10.1145/3653071)
 * [Conn et al., 1992. LANCELOT: A Fortran Package for Large-Scale Nonlinear Optimization (Release A)](http://link.springer.com/10.1007/978-3-662-12211-2)
 * [Cooper et al., 2020. PyMOSO: Software for multi-objective simulation optimization with R-PERLE and R-MinRLE](http://pubsonline.informs.org/doi/10.1287/ijoc.2019.0902)
 * [Costa et al., 2018. RBFOpt: an open-source library for black-box optimization with costly function evaluations](http://link.springer.com/10.1007/s12532-018-0144-7)
 * [Cristescu et al., 2015. Surrogate-based multiobjective optimization: ParEGO update and test](https://www.cs.bham.ac.uk/~jdk/UKCI-2015.pdf)
 * [2019. Press Release: U.S.\ Department of Energy and Intel to deliver first exascale supercomputer](https://www.anl.gov/article/us-department-of-energy-and-intel-to-deliver-first-exascale-supercomputer)
 * [Diamond et al., 2016. CVXPY: A Python-embedded modeling language for convex optimization](http://jmlr.org/papers/v17/15-408.html)
 * [Domahidi et al., 2013. ECOS: An SOCP solver for embedded systems](https://ieeexplore.ieee.org/document/6669541)
 * [Dongarra et al., 2003. The LINPACK benchmark: past, present, and future](https://onlinelibrary.wiley.com/doi/10.1002/cpe.728)
 * [Dubey et al., 2021. Performance Portability in the Exascale Computing Project: Exploration Through a Panel Series](https://ieeexplore.ieee.org/document/9495114)
 * [Dunning et al., 2017. JuMP: A Modeling Language for Mathematical Optimization](https://epubs.siam.org/doi/10.1137/15M1020575)
 * [Durillo et al., 2011. jMetal: A Java framework for multi-objective optimization](https://linkinghub.elsevier.com/retrieve/pii/S0965997811001219)
 * [Eckman et al., 2023. SimOpt: A Testbed for Simulation-Optimization Experiments](https://pubsonline.informs.org/doi/10.1287/ijoc.2023.1273)
 * [Eggensperger et al., 2021. HPOBench: A Collection of Reproducible Multi-Fidelity Benchmark Problems for HPO](https://openreview.net/forum?id=1k4rJYEwda-)
 * [Elias et al., 2020. The Manufacturing Data and Machine Learning Platform: Enabling Real-time Monitoring and Control of Scientific Experiments via IoT](https://ieeexplore.ieee.org/document/9221078)
 * [Farhan et al., 2020. Reinforcement Learning in AnyLogic Simulation Models: A Guiding Example using Pathmind](https://ieeexplore.ieee.org/document/9383916)
 * [Fletcher, 1993. Resolving degeneracy in quadratic programming](http://link.springer.com/10.1007/BF02023102)
 * [Fortin et al., 2012. DEAP: Evolutionary Algorithms Made Easy](https://www.jmlr.org/papers/v13/fortin12a.html)
 * [Forum, 2023. MPI: A Message-Passing Interface Standard](https://www.mpi-forum.org/docs/mpi-4.1/mpi41-report.pdf)
 * [Fourer et al., 2003. AMPL: A Modeling Language for Mathematical Programming](https://dev.ampl.com/ampl/books/ampl/index.html)
 * [Fowkes et al., 2022. PyCUTEst: an open source Python package of optimization test problems](https://joss.theoj.org/papers/10.21105/joss.04377)
 * [Fowkes et al., 2023. GALAHAD 4.0: an open source library of Fortran packages with C and Matlab interfaces for continuous optimization](https://doi.org/10.21105/joss.04882)
 * [Gamma et al., 1995. Design patterns: elements of reusable object-oriented software](https://en.wikipedia.org/wiki/Design_Patterns)
 * [Germann, 2021. Co-design in the Exascale Computing Project](https://journals.sagepub.com/doi/10.1177/10943420211059380)
 * [Gillette et al., 2024. Algorithm 1049: The Delaunay Density Diagnostic](https://doi.org/10.1145/3700134)
 * [Golovin et al., 2017. Google Vizier: A Service for Black-Box Optimization](https://dl.acm.org/doi/10.1145/3097983.3098043)
 * [Golub et al., 2013. Matrix computations](https://www.press.jhu.edu/books/title/10678/matrix-computations)
 * [Gould et al., 2003. GALAHAD, a library of thread-safe Fortran 90 packages for large-scale nonlinear optimization](https://doi.org/10.1145/962437.962438)
 * [Gould et al., 2015. CUTEst: a Constrained and Unconstrained Testing Environment with safe threads for mathematical optimization](https://doi.org/10.1007/s10589-014-9687-3)
 * [Gray et al., 2019. OpenMDAO: An open-source framework for multidisciplinary design, analysis, and optimization](http://link.springer.com/10.1007/s00158-019-02211-z)
 * [Hadka, 2015. Platypus -- multiobjective optimization in Python](https://platypus.readthedocs.io/en/latest)
 * [Hanson et al., 1982. Algorithm 587: Two Algorithms for the Linearly Constrained Least Squares Problem](https://dl.acm.org/doi/10.1145/356004.356010)
 * [Harris et al., 2020. Array programming with NumPy](https://www.nature.com/articles/s41586-020-2649-2)
 * [Hart et al., 2017. Pyomo -- optimization modeling in Python](http://link.springer.com/10.1007/978-3-319-58821-6)
 * [H{\"a}se et al., 2018. Chimera: enabling hierarchy based multi-objective optimization for self-driving laboratories](https://xlink.rsc.org/?DOI=C8SC02239A)
 * [He et al., 2009. Algorithm 897: VTDIRECT95: Serial and Parallel Codes for the Global Optimization Algorithm DIRECT](https://dl.acm.org/doi/10.1145/1527286.1527291)
 * [He et al., 2016. Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385)
 * [Heroux et al., 2020. Advancing Scientific Productivity through Better Scientific Software: Developer Productivity and Software Sustainability Report](https://www.osti.gov/servlets/purl/1606662)
 * [Hert et al., 2020. dD Convex Hulls and Delaunay Triangulations](https://doc.cgal.org/5.0.2/Manual/packages.html#PkgConvexHullD)
 * [Holzmann, 2006. The power of 10: rules for developing safety-critical code](https://spinroot.com/gerard/pdf/P10.pdf)
 * [Huang et al., 2019. Cpp-Taskflow: Fast Task-Based Parallel Programming Using Modern C++](https://ieeexplore.ieee.org/document/8821011/)
 * [Huangfu et al., 2018. Parallelizing the dual revised simplex method](http://link.springer.com/10.1007/s12532-017-0130-5)
 * [Hudson et al., 2023. libEnsemble: A complete Python toolkit for dynamic ensembles of calculations](https://joss.theoj.org/papers/10.21105/joss.06031)
 * [Intel, 2025. oneAPI Threading Building Blocks (oneTBB)](https://uxlfoundation.github.io/oneTBB)
 * [2004. Information technology -- Programming languages -- Fortran -- Part 1: Base Language](https://j3-fortran.org/doc/year/04/04-007.pdf)
 * [2010. Information technology -- Programming languages -- Fortran -- Part 1: Base Language](https://j3-fortran.org/doc/year/10/10-007.pdf)
 * [Jain et al., 2022. tiktoken](https://github.com/openai/tiktoken)
 * [Joe et al., 2003. Remark on Algorithm 659: Implementing Sobol's Quasirandom Sequence Generator](https://dl.acm.org/doi/10.1145/641876.641879)
 * [Kale et al., 1993. CHARM++: a portable concurrent object oriented system based on C++](https://dl.acm.org/doi/10.1145/165854.165874)
 * [Kandasamy et al., 2020. Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly](http://jmlr.org/papers/v21/18-223.html)
 * [Karypis et al., 1998. hMETIS: A hypergraph partitioning package](https://course.ece.cmu.edu/~ee760/760docs/hMetisManual.pdf)
 * [Kleen, 2005. A NUMA API for Linux](https://halobates.de/numaapi3.pdf)
 * [Kolonay et al., 2011. Service oriented computing environment (SORCER) for large scale, distributed, dynamic fidelity aeroelastic analysis](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.656.7539)
 * [Kreps et al., 2011. Kafka: A distributed messaging system for log processing](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/09/Kafka.pdf)
 * [Le Digabel, 2011. Algorithm 909: NOMAD: Nonlinear Optimization with the MADS Algorithm](https://dl.acm.org/doi/10.1145/1916461.1916468)
 * [Lee et al., 2015. pyDOE: The experimental design package for python](https://github.com/tisimst/pyDOE)
 * [Liang et al., 2024. AMF-Placer 2.0: Open-Source Timing-Driven Analytical Mixed-Size Placer for Large-Scale Heterogeneous FPGA](https://ieeexplore.ieee.org/document/10459236/)
 * [Lindauer et al., 2022. SMAC3: A Versatile Bayesian Optimization Package for Hyperparameter Optimization](http://jmlr.org/papers/v23/21-0888.html)
 * [Liuzzi et al., 2024. DFO-lib](https://github.com/DerivativeFreeLibrary)
 * [Lu et al., 2019. NSGA-Net: neural architecture search using multi-objective genetic algorithm](https://doi.org/10.1145/3321707.3321729)
 * [Lundberg et al., 2017. A Unified Approach to Interpreting Model Predictions](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf)
 * [Luu et al., 2011. VPR 5.0: FPGA CAD and architecture exploration tools with single-driver routing, heterogeneity and process scaling](https://doi.org/10.1145/2068716.2068718)
 * [Lux et al., 2023. Algorithm 1031: MQSI---Monotone quintic spline interpolation](https://dl.acm.org/doi/10.1145/3570157)
 * [Martins et al., 2009. pyMDO: An Object-Oriented Framework for Multidisciplinary Design Optimization](https://dl.acm.org/doi/10.1145/1555386.1555389)
 * [Mayes, 2023. PySuperfish](https://github.com/ChristopherMayes/PySuperfish)
 * [Menzel et al., 1987. Users guide for the POISSON/SUPERFISH group of codes](https://www.osti.gov/servlets/purl/10140823)
 * [Mikolov et al., 2013. Efficient estimation of word representations in vector space](https://openreview.net/forum?id=idpCdOWtqXd60&noteld=C8Vn84fq)
 * [Mills et al., 2021. Toward performance-portable PETSc for GPU-based exascale systems](https://linkinghub.elsevier.com/retrieve/pii/S016781912100079X)
 * [Misitano et al., 2021. DESDEO: The Modular and Open Source Framework for Interactive Multiobjective Optimization](https://ieeexplore.ieee.org/document/9591595)
 * [Moriwaki et al., 2018. Mordred: a molecular descriptor calculator](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0258-y)
 * [Munson et al., 2015. TAO 3.5 Users Manual](https://www.mcs.anl.gov/petsc/petsc-3.5.4/docs/tao_manual.pdf)
 * [Murray et al., 2020. VTR 8: High-performance CAD and Customizable FPGA Architecture Modelling](https://doi.org/10.1145/3388617)
 * [NVIDIA Corporation, 2025. cuBLAS API](https://docs.nvidia.com/cuda/pdf/CUBLAS_Library.pdf)
 * [NVIDIA HPC Compilers, 2025. CUDA Fortran programming guide](https://docs.nvidia.com/hpc-sdk/archive/23.3/pdf/hpc233cudaforug.pdf)
 * [O'Donoghue et al., 2016. Conic Optimization via Operator Splitting and Homogeneous Self-Dual Embedding](http://link.springer.com/10.1007/s10957-016-0892-3)
 * [OpenMP, 2015. OpenMP Application Programming Interface](https://www.openmp.org/wp-content/uploads/openmp-4.5.pdf)
 * [Papazafeiropoulos, 2014. MATLAB Computational Geometry Toolbox version 1.2](https://www.mathworks.com/matlabcentral/fileexchange/48509-computational-geometry-toolbox)
 * [Paszke et al., 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf)
 * [Pedregosa et al., 2011. Scikit-learn: Machine learning in Python](https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf)
 * [Petitet et al., 2018. HPL -- A Portable Implementation of the High-Performance Linpack Benchmark for Distributed-Memory Computers](https://www.netlib.org/benchmark/hpl/)
 * [Pfisterer et al., 2022. YAHPO Gym - An Efficient Multi-Objective Multi-Fidelity Benchmark for Hyperparameter Optimization](https://proceedings.mlr.press/v188/pfisterer22a.html)
 * [Raghunath et al., 2017. Global deterministic and stochastic optimization in a service oriented architecture](http://dl.acm.org/citation.cfm?id=3108103)
 * [Ragonneau et al., 2021. PDFO: Cross-Platform Interfaces for Powell’s Derivative-Free Optimization Solvers](https://github.com/pdfo/pdfo)
 * [Rajarathnam et al., 2022. DREAMPlaceFPGA: An Open-Source Analytical Placer for Large Scale Heterogeneous FPGAs using Deep-Learning Toolkit](https://ieeexplore.ieee.org/document/9712562/)
 * [Rose et al., 2012. The VTR project: architecture and CAD for FPGAs from verilog to routing](https://doi.org/10.1145/2145694.2145708)
 * [Roy et al., 2023. Quasi-Monte Carlo Methods in Python](https://joss.theoj.org/papers/10.21105/joss.05309)
 * [Saves et al., 2024. SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes](https://www.sciencedirect.com/science/article/pii/S096599782300162X)
 * [Shashaani et al., 2016. ASTRO-DF: Adaptive sampling trust-region optimization algorithms, heuristics, and numerical experience](http://ieeexplore.ieee.org/document/7822121/)
 * [Shields et al., 2021. Bayesian reaction optimization as a tool for chemical synthesis](https://www.nature.com/articles/s41586-021-03213-y)
 * [Slepicka, 2020. Poisson Superfish via Docker](https://github.com/hhslepicka/docker-poisson-superfish-nobin)
 * [Stall et al., 2019. Make scientific data FAIR](https://www.nature.com/articles/d41586-019-01720-7)
 * [Stellato et al., 2020. OSQP: an operator splitting solver for quadratic programs](http://link.springer.com/10.1007/s12532-020-00179-2)
 * [Tavares et al., 2022. Parallel Strategies for Direct Multisearch](https://link.springer.com/10.1007/s11075-022-01364-1)
 * [Thacker et al., 2010. Algorithm 905: SHEPPACK: Modified Shepard algorithm for interpolation of scattered multivariate data](https://dl.acm.org/doi/10.1145/1824801.1824812)
 * [Tian et al., 2017. PlatEMO: A MATLAB Platform for Evolutionary Multi-Objective Optimization [Educational Forum]](http://ieeexplore.ieee.org/document/8065138)
 * [Trott et al., 2022. Kokkos 3: Programming Model Extensions for the Exascale Era](https://ieeexplore.ieee.org/document/9485033/)
 * [Vanaret et al., 2024. Unifying nonlinearly constrained nonconvex optimization](https://arxiv.org/abs/2406.13454)
 * [van der Maaten et al., 2008. Visualizing Data using t-SNE](http://jmlr.org/papers/v9/vandermaaten08a.html)
 * [Vandevender et al., 1982. The SLATEC Mathematical Subroutine Library](https://dl.acm.org/doi/10.1145/1057594.1057595)
 * [Virtanen et al., 2020. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python](https://www.nature.com/articles/s41592-019-0686-2)
 * [Voss et al., 2019. TBB on NUMA Architectures](https://doi.org/10.1007/978-1-4842-4398-5_20)
 * [VTR Developers, 2024. Verilog-to-routing documentation](https://readthedocs.org/projects/vtr/downloads/pdf/latest)
 * [Wang et al., 2022. Pyomo.DOE: An open-source package for model-based design of experiments in Python](https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.17813)
 * [Watson et al., 1997. Algorithm 777: HOMPACK90: A suite of Fortran 90 codes for globally convergent homotopy algorithms](https://dl.acm.org/doi/10.1145/279232.279235)
 * [Whaley et al., 2001. Automated empirical optimizations of software and the ATLAS project](https://linkinghub.elsevier.com/retrieve/pii/S0167819100000879)
 * [Wu et al., 2025. ytopt: Autotuning Scientific Applications for Energy Efficiency at Large Scales](https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.8322)
 * [Wächter et al., 2006. On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming](http://link.springer.com/10.1007/s10107-004-0559-y)
 * [Xiong et al., 2023. DREAMPlaceFPGA-MP: An Open-Source GPU-Accelerated Macro Placer for Modern FPGAs with Cascade Shapes and Region Constraints](https://arxiv.org/abs/2311.08582)
 * [Zhang, 2023. PRIMA: Reference Implementation for Powell's Methods with Modernization and Amelioration](http://www.libprima.net)
 * [Zhu et al., 1997. Algorithm 778: L-BFGS-B: Fortran Subroutines for Large-Scale Bound-Constrained Optimization](https://dl.acm.org/doi/10.1145/279232.279236)

## computational geometry

 * [Aurenhammer et al., 2013. Voronoi diagrams and Delaunay triangulations](https://www.worldscientific.com/worldscibooks/10.1142/8685?srsltid=AfmBOoqYyCEcMxI7JQyJKonU2CZAy-dXYFcqnxJkrlJCSsAMHLbMPI70#t=aboutBook)
 * [Bambade et al., 2022. PROX-QP: Yet another Quadratic Programming Solver for Robotics and beyond](https://hal.inria.fr/hal-03683733)
 * [Barber et al., 1996. The Quickhull algorithm for convex hulls](https://dl.acm.org/doi/10.1145/235815.235821)
 * [Boissonnat et al., 2009. Incremental construction of the Delaunay triangulation and the Delaunay graph in medium dimension](https://dl.acm.org/doi/10.1145/1542362.1542403)
 * [Bowyer, 1981. Computing Dirichlet tessellations](https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/24.2.162)
 * [Boyd et al., 2004. Convex optimization](https://stanford.edu/~boyd/cvxbook/)
 * [Chang et al., 2018. Computing the umbrella neighbourhood of a vertex in the Delaunay triangulation and a single Voronoi cell in arbitrary dimension](https://ieeexplore.ieee.org/document/8479003)
 * [Chang et al., 2018. A polynomial time algorithm for multivariate interpolation in arbitrary dimension via the Delaunay triangulation](https://dl.acm.org/doi/10.1145/3190645.3190680)
 * [Chang et al., 2018. Predicting system performance by interpolation using a high-dimensional Delaunay triangulation](https://par.nsf.gov/servlets/purl/10111451)
 * [Chang et al., 2020. Algorithm 1012: DELAUNAYSPARSE: Interpolation via a Sparse Subset of the Delaunay Triangulation in Medium to High Dimensions](https://dl.acm.org/doi/10.1145/3422818)
 * [Chang, 2020. Mathematical Software for Multiobjective Optimization Problems](https://vtechworks.lib.vt.edu/handle/10919/98915)
 * [Chang et al., 2024. Remark on Algorithm 1012: Computing projections with large data sets](https://dl.acm.org/doi/10.1145/3656581)
 * [Chen et al., 2004. Optimal Delaunay triangulations](https://www.math.uci.edu/~chenlong/Papers/Chen.L%3BXu.J2004.pdf)
 * [Cheng et al., 2012. Delaunay Mesh Generation](https://people.eecs.berkeley.edu/~jrs/meshbook.html)
 * [Choudhary et al., 2019. Polynomial-sized topological approximations using the permutahedron](http://link.springer.com/10.1007/s00454-017-9951-2)
 * [Cignoni et al., 1998. DeWall: A fast divide and conquer Delaunay triangulation algorithm in $\mathbbE^d$](https://linkinghub.elsevier.com/retrieve/pii/S0010448597000821)
 * [Dantzig, 1998. Linear Programming and Extensions](https://d1wqtxts1xzle7.cloudfront.net/56278680/Libro_Linear_Programming_George_Dantzig-libre.pdf?1523307505=&response-content-disposition=inline%3B+filename%3DLinear_Programming_and_Extensions.pdf&Expires=1746491165&Signature=WQRD07CTKkhpfjxG1R6Kb2tSq0cRnDUia1ETKdgTQX2wbUxpA2p7ZGudVpOpbsKgUZzsKL-U3CddGBaVVSTr~TSLwPadmYe8xHRVZ4KqyB~ms5zyu08vntJ0V-pRNY0sws9H~ktLJTgoABlZMkoYDA23Dbrh07yQqukyaqHsDuoTEZRzng6AIqN7CXO1KW2M4J~rS-M1mmM3bdTSMAoWPozK7Suea-HJPd7QbCMq2hB0JY5mhhi6nUHa6zIQVmjTCcPPdnX9O4lYgYPQgOBiMlIJ5yhYolhlHKXMA~2-g3rbpe4kqJXIEqICSWPByh72uohGvRJkDgUX-CkBw7FZNA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)
 * [de Berg et al., 2008. Computational Geometry: Algorithms and Applications](https://cimec.org.ar/foswiki/pub/Main/Cimec/GeometriaComputacional/DeBerg_-_Computational_Geometry_-_Algorithms_and_Applications_2e.pdf)
 * [Delaunay, 1934. Sur la sph\'ere vide](https://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=im&paperid=4937&option_lang=eng)
 * [Devillers et al., 2001. Walking in a triangulation](https://dl.acm.org/doi/10.1145/378583.378643)
 * [Diamond et al., 2016. CVXPY: A Python-embedded modeling language for convex optimization](http://jmlr.org/papers/v17/15-408.html)
 * [Domahidi et al., 2013. ECOS: An SOCP solver for embedded systems](https://ieeexplore.ieee.org/document/6669541)
 * [Edelsbrunner, 1989. An acyclicity theorem for cell complexes in d dimensions](http://portal.acm.org/citation.cfm?doid=73833.73850)
 * [Edelsbrunner et al., 1990. Simulation of simplicity: a technique to cope with degenerate cases in geometric algorithms](https://dl.acm.org/doi/10.1145/77635.77639)
 * [Fortune, 1987. A sweepline algorithm for Voronoi diagrams](http://link.springer.com/10.1007/BF01840357)
 * [Fukuda, 2004. Is it possible to compute only the adjacencies of Voronoi cells in the Voronoi diagram efficiently?](http://www.cs.mcgill.ca/~fukuda/soft/polyfaq/polyfaq.html)
 * [Gillette et al., 2022. Data-driven geometric scale detection via Delaunay interpolation](https://arxiv.org/html/2203.05685v2)
 * [Gillette et al., 2024. Algorithm 1049: The Delaunay Density Diagnostic](https://doi.org/10.1145/3700134)
 * [Gorban et al., 2017. Stochastic separation theorems](https://linkinghub.elsevier.com/retrieve/pii/S0893608017301776)
 * [Hanson et al., 1982. Algorithm 587: Two Algorithms for the Linearly Constrained Least Squares Problem](https://dl.acm.org/doi/10.1145/356004.356010)
 * [Hert et al., 2020. dD Convex Hulls and Delaunay Triangulations](https://doc.cgal.org/5.0.2/Manual/packages.html#PkgConvexHullD)
 * [Huangfu et al., 2018. Parallelizing the dual revised simplex method](http://link.springer.com/10.1007/s12532-017-0130-5)
 * [Johnson et al., 1990. Minimax and maximin distance designs](https://linkinghub.elsevier.com/retrieve/pii/037837589090122B)
 * [Klee et al., 1972. How good is the simplex algorithm?](https://en.wikipedia.org/wiki/Klee%E2%80%93Minty_cube)
 * [Klee, 1980. On the complexity of d-dimensional Voronoi diagrams](http://link.springer.com/10.1007/BF01224932)
 * [Liu et al., 2019. Nonparametric functional approximation with Delaunay triangulation learner](https://ieeexplore.ieee.org/document/8944414)
 * [Lux et al., 2018. Novel meshes for multivariate interpolation and approximation](https://dl.acm.org/doi/10.1145/3190645.3190687)
 * [Lux et al., 2018. Predictive modeling of I/O characteristics in high performance computing systems](https://par.nsf.gov/servlets/purl/10111447)
 * [Lux et al., 2021. Interpolation of sparse high-dimensional data](https://link.springer.com/10.1007/s11075-020-01040-2)
 * [Megiddo, 1991. On finding primal- and dual-optimal bases](https://pubsonline.informs.org/doi/10.1287/ijoc.3.1.63)
 * [Miller et al., 2008. Linear-size meshes](https://donsheehy.net/research/miller08linear.pdf)
 * [M\"obius, 1827. Der barycentrische Calcul](https://books.google.com/books?id=eFPluv_UqFEC&printsec=frontcover#v=onepage&q&f=false)
 * [M{\"u}cke et al., 1999. Fast randomized point location without preprocessing in two- and three-dimensional Delaunay triangulations](https://www.osti.gov/biblio/231593)
 * [Omohundro, 1990. Geometric learning algorithms](https://linkinghub.elsevier.com/retrieve/pii/0167278990900854)
 * [Papazafeiropoulos, 2014. MATLAB Computational Geometry Toolbox version 1.2](https://www.mathworks.com/matlabcentral/fileexchange/48509-computational-geometry-toolbox)
 * [Polianskii et al., 2020. Voronoi Graph Traversal in High Dimensions with Applications to Topological Data Analysis and Piecewise Linear Interpolation](https://dl.acm.org/doi/10.1145/3394486.3403266)
 * [Rajan, 1994. Optimality of the Delaunay triangulation in $\R^d$](https://link.springer.com/10.1007/BF02574375)
 * [Shewchuk, 2002. What is a good linear finite element? Interpolation, conditioning, anisotropy, and quality measures](https://people.eecs.berkeley.edu/~jrs/papers/elemj.pdf)
 * [Smale, 1998. Mathematical problems for the next century](http://link.springer.com/10.1007/BF03025291)
 * [Stellato et al., 2020. OSQP: an operator splitting solver for quadratic programs](http://link.springer.com/10.1007/s12532-020-00179-2)
 * [Su et al., 1997. A comparison of sequential Delaunay triangulation algorithms](https://linkinghub.elsevier.com/retrieve/pii/S0925772196000259)
 * [Virtanen et al., 2020. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python](https://www.nature.com/articles/s41592-019-0686-2)
 * [Watson, 1981. Computing the n-dimensional Delaunay tessellation with application to Voronoi polytopes](https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/24.2.167)

## design of experiments

 * [Adams et al., 2022. Dakota, A Multilevel Parallel Object-Oriented Framework for Design Optimization, Parameter Estimation, Uncertainty Quantification, and Sensitivity Analysis: Version 6.16 User's Manual](https://dakota.sandia.gov/sites/default/files/docs/6.16.0/Users-6.16.0.pdf)
 * [Amos et al., 2020. Algorithm 1007: QNSTOP: Quasi-Newton algorithm for stochastic optimization](https://dl.acm.org/doi/10.1145/3374219)
 * [Bratley et al., 1988. Algorithm 659: Implementing Sobol's Quasirandom Sequence Generator](https://doi.org/10.1145/42288.214372)
 * [Chang, 2020. Mathematical Software for Multiobjective Optimization Problems](https://vtechworks.lib.vt.edu/handle/10919/98915)
 * [Chang et al., 2022. Algorithm 1028: VTMOP: Solver for Blackbox Multiobjective Optimization Problems](https://dl.acm.org/doi/10.1145/3529258)
 * [Chang et al., 2023. ParMOO: A Python library for parallel multiobjective simulation optimization](https://joss.theoj.org/papers/10.21105/joss.04468)
 * [Chang et al., 2024. ParMOO: Python library for parallel multiobjective simulation optimization](https://parmoo.readthedocs.io/en/latest)
 * [Chang et al., 2025. Designing a Framework for Solving Multiobjective Simulation Optimization Problems](https://pubsonline.informs.org/doi/10.1287/ijoc.2023.0250)
 * [Chang et al., 2025. Repository for ``Designing a Framework for Solving Multiobjective Simulation Optimization Problems''](https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0250)
 * [Chen et al., 2023. An Integrated Multi-Physics Optimization Framework for Particle Accelerator Design](https://doi.com/10.48550/arXiv.2311.09415)
 * [Chowdhary et al., 2024. PyOED: An Extensible Suite for Data Assimilation and Model-Constrained Optimal Design of Experiments](https://dl.acm.org/doi/10.1145/3653071)
 * [Dalal et al., 2008. Low discrepancy sequences for Monte Carlo simulations on reconfigurable platforms](http://ieeexplore.ieee.org/document/4580163)
 * [Garg et al., 2023. SF-SFD: Stochastic optimization of Fourier coefficients for space-filling designs](https://ieeexplore.ieee.org/document/10408245/)
 * [Gorban et al., 2017. Stochastic separation theorems](https://linkinghub.elsevier.com/retrieve/pii/S0893608017301776)
 * [Hickernell, 1998. A generalized discrepancy and quadrature error bound](https://www.ams.org/mcom/1998-67-221/S0025-5718-98-00894-1)
 * [Joe et al., 2003. Remark on Algorithm 659: Implementing Sobol's Quasirandom Sequence Generator](https://dl.acm.org/doi/10.1145/641876.641879)
 * [Joe et al., 2008. Constructing Sobol sequences with better two-dimensional projections](http://epubs.siam.org/doi/10.1137/070709359)
 * [Johnson et al., 1990. Minimax and maximin distance designs](https://linkinghub.elsevier.com/retrieve/pii/037837589090122B)
 * [Kuipers et al., 1974. Uniform distribution of sequences](https://web.maths.unsw.edu.au/~josefdick/preprints/KuipersNied_book.pdf)
 * [Lax, 2002. Functional analysis](https://books.google.com/books?hl=en&lr=&id=18VqDwAAQBAJ&oi=fnd&pg=PR17&ots=8FU4i_jAff&sig=Lh4GrUCrS_gt-HKqHSq4X7BaxMs#v=onepage&q&f=false)
 * [Lee et al., 2015. pyDOE: The experimental design package for python](https://github.com/tisimst/pyDOE)
 * [Liu et al., 2017. An adaptive sampling approach for Kriging metamodeling by maximizing expected prediction error](https://linkinghub.elsevier.com/retrieve/pii/S009813541730234X)
 * [Lux et al., 2018. Novel meshes for multivariate interpolation and approximation](https://dl.acm.org/doi/10.1145/3190645.3190687)
 * [M{\"u}ller, 2017. SOCEMO: Surrogate optimization of computationally expensive multiobjective problems](https://pubsonline.informs.org/doi/10.1287/ijoc.2017.0749)
 * [Myers et al., 2016. Response Surface Methodology: Process and Design Optimization Using Designed Experiments](https://books.google.com/books?hl=en&lr=&id=T-BbCwAAQBAJ&oi=fnd&pg=PR13&dq=Response+Surface+Methodology:+Process+and+Product+Optimization+Using+Designed+Experiments,+4th+Edition&ots=O3jdPna83T&sig=IimJlE46JBVkHOu7eik3RN9Z5GA#v=onepage&q=Response%20Surface%20Methodology%3A%20Process%20and%20Product%20Optimization%20Using%20Designed%20Experiments%2C%204th%20Edition&f=false)
 * [Niederreiter, 1988. Low-discrepancy and low-dispersion sequences](https://doi.org/10.1016/0022-314X(88)90025-X)
 * [Pickering et al., 2022. Discovering and forecasting extreme events via active learning in neural operators](https://www.nature.com/articles/s43588-022-00376-0)
 * [Pronzato, 2017. Minimax and maximin space-filling designs: some properties and methods for construction](http://www.numdam.org/item/JSFS_2017__158_1_7_0)
 * [Roy et al., 2023. Quasi-Monte Carlo Methods in Python](https://joss.theoj.org/papers/10.21105/joss.05309)
 * [Sapsis et al., 2022. Optimal criteria and their asymptotic form for data selection in data-driven reduced-order modelling with Gaussian process regression](https://royalsocietypublishing.org/doi/10.1098/rsta.2021.0197)
 * [Saves et al., 2024. SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes](https://www.sciencedirect.com/science/article/pii/S096599782300162X)
 * [Sobieszczanski-Sobieski et al., 2015. Multidisciplinary Design Optimization Supported by Knowledge Based Engineering](https://doi.com/10.1002/9781118897072)
 * [Sobol, 1967. Distribution of points in a cube and approximate evaluation of integrals](https://linkinghub.elsevier.com/retrieve/pii/0041555367901449)
 * [Tao, 2011. An Epsilon of Room: Pages from year three of a mathematical blog](http://www.ams.org/mbk/077)
 * [Viana, 2016. A tutorial on Latin hypercube design of experiments](https://onlinelibrary.wiley.com/doi/10.1002/qre.1924)
 * [Virtanen et al., 2020. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python](https://www.nature.com/articles/s41592-019-0686-2)
 * [Wang et al., 2022. Pyomo.DOE: An open-source package for model-based design of experiments in Python](https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.17813)
 * [Wang et al., 2023. Design strategies and approximation methods for high-performance computing variability management](https://www.tandfonline.com/doi/full/10.1080/00224065.2022.2035285)
 * [Wong et al., 1997. Sampling with Hammersley and Halton points](http://www.tandfonline.com/doi/abs/10.1080/10867651.1997.10487471)

## quantum computing

 * [Aharonov et al., 2008. Adiabatic quantum computation is equivalent to standard quantum computation](http://epubs.siam.org/doi/10.1137/080734479)
 * [Albash et al., 2018. Adiabatic quantum computation](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.90.015002)
 * [Alghassi et al., 2019. Graver Bases via Quantum Annealing with Application to Non-Linear Integer Programs](https://arxiv.org/pdf/1902.04215.pdf)
 * [Andriyash et al., 2016. Boosting integer factoring performance via quantum annealing offsets](https://www.dwavesys.com/sites/default/files/14-1002A_B_tr_Boosting_integer_factorization_via_quantum_annealing_offsets.pdf)
 * [Barahona, 1982. On the computational complexity of Ising spin glass models](https://iopscience.iop.org/article/10.1088/0305-4470/15/10/028)
 * [Biamonte et al., 2017. Quantum machine learning](https://www.nature.com/articles/nature23474)
 * [Boixo et al., 2014. Evidence for quantum annealing with more than one hundred qubits](https://www.nature.com/articles/nphys2900)
 * [Boothby et al., 2018. Next-generation topology of D-Wave quantum processors](https://www.dwavesys.com/sites/default/files/14-1026A-C_Next-Generation-Topology-of-DW-Quantum-Processors.pdf)
 * [Borle et al., 2019. Analyzing the quantum annealing approach for solving linear least squares problems](https://link.springer.com/10.1007/978-3-030-10564-8_23)
 * [Cai et al., 2014. A practical heuristic for finding graph minors](https://arxiv.org/abs/1406.2741)
 * [Chang et al., 2019. Experimental realization of quantum algorithms for a linear system inspired by adiabatic quantum computing](https://link.aps.org/doi/10.1103/PhysRevA.99.012320)
 * [Das et al., 2005. Quantum annealing and related optimization methods](https://www.researchgate.net/publication/252247914_Quantum_Annealing_and_Related_Optimization_Methods)
 * [Dattani, 2019. Quadratization in discrete optimization and quantum mechanics](https://arxiv.org/abs/1901.04405)
 * [Dridi et al., 2017. Prime factorization using quantum annealing and computational algebraic geometry](https://www.nature.com/articles/srep43048)
 * [Elgart et al., 2012. A note on the switching adiabatic theorem](https://aip.scitation.org/doi/abs/10.1063/1.4748968)
 * [Jiang et al., 2018. Quantum annealing for prime factorization](https://www.nature.com/articles/s41598-018-36058-z)
 * [Kadowaki et al., 1998. Quantum annealing in the transverse Ising model](https://link.aps.org/doi/10.1103/PhysRevE.58.5355)
 * [Karimi et al., 2019. Practical integer-to-binary mapping for quantum annealers](https://link.springer.com/article/10.1007/s11128-019-2213-x)
 * [Khoshaman et al., 2018. Quantum variational autoencoder](https://iopscience.iop.org/article/10.1088/2058-9565/aada1f/meta)
 * [Pakin, 2018. Performing fully parallel constraint logic programming on a quantum annealer](https://www.cambridge.org/core/journals/theory-and-practice-of-logic-programming/article/performing-fully-parallel-constraint-logic-programming-on-a-quantum-annealer/AB4CCF2D913D0325F770B3DA02AA262D)
 * [Peng et al., 2008. Quantum adiabatic algorithm for factorization and its experimental implementation](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.101.220405)
 * [Ray et al., 1989. Sherrington-Kirkpatrick model in a transverse field: Absence of replica symmetry breaking due to quantum fluctuations](https://link.aps.org/doi/10.1103/PhysRevB.39.11828)
 * Rosenberg, 1975. Reduction of bivalent maximization to the quadratic case
 * [Santoro et al., 2002. Theory of quantum annealing of an Ising spin glass](https://science.sciencemag.org/content/295/5564/2427?casa_token=oOyVfFb2YFkAAAAA:uuUmeZPbfJVVjm9XlBllasY6OA1n_kOEJA4E5DSOD6neFa2PuVI6pEElaMvRkbomX4sJiq9gxn_YPpY)
 * [Shor, 1999. Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer](https://epubs.siam.org/doi/abs/10.1137/S0036144598347011?casa_token=a1HjL4NT4JcAAAAA:76FzW89tOwMuu471TSx0PCrJFUTa0tbvOyNfM4isoCzj3NwY6pvUAlJJpAlvq_emxY4fuksR_WRh)
 * [Steane, 1998. Quantum computing](https://iopscience.iop.org/article/10.1088/0034-4885/61/2/002)
