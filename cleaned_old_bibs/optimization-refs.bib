@techreport{adams2022dakota,,
	author = {Adams, Brian M. and Bohnhoff, William J. and Dalbey, Keith R. and Ebeida, Mohamed S. and Eddy, John P. and Eldred, Michael S. and Hooper, Russell W. and Hough, Patricia D. and Hu, Kenneth T. and Jakeman, John D. and Khalil, Mohammad and Maupin, Kathryn A. and Monschke, Jason A. and Ridgeway, Elliott M. and Rushdi, Ahmad A. and Seidl, D. Thomas and Stephens, J. Adam and Swiler, Laura P. and Tran, Anh and Winokur, Justin G.},
	title = {Dakota, A Multilevel Parallel Object-Oriented Framework for Design Optimization, Parameter Estimation, Uncertainty Quantification, and Sensitivity Analysis: Version 6.16 User's Manual},
	year = {2022},
	number = {SAND2022-6171 version 6.16},
	institution = {Sandia National Laboratory},
	address = {Albuquerque, NM, USA},
	url = {https://dakota.sandia.gov/sites/default/files/docs/6.16.0/Users-6.16.0.pdf},
	descrip = {The Dakota blackbox and derivative-free simulation optimization framework, a numerical software package (in C++) maintained by Sandia that offers support for AI/ML surrogate modeling, multifidelity modeling, uncertainty quantification (UQ), and distributed and parallel computing},
}

@article{akhtar2016multi,
	author = {Akhtar, Taimoor and Shoemaker, Christine A.},
	title = {Multi objective optimization of computationally expensive multi-modal functions with {RBF} surrogates and multi-rule selection},
	year = {2016},
	month = {1},
	journal = {Journal of Global Optimization},
	volume = {64},
	number = {1},
	pages = {17--32},
	publisher = {Springer},
	doi = {10.1007/s10898-015-0270-y},
	url = {http://link.springer.com/10.1007/s10898-015-0270-y},
	issn = {0925-5001},
	descrip = {Using RBF surrogates to solve blackbox / derivative-free multiobjective optimization problems},
}

@inproceedings{aldujaili2016dividing,
	author = {Al-Dujaili, Abdullah and Suresh, Sundaram},
	title = {Dividing rectangles attack multi-objective optimization},
	year = {2016},
	month = {7},
	booktitle = {Proc. 2016 IEEE Congress on Evolutionary Computation (CEC '16)},
	pages = {3606--3613},
	organization = {IEEE},
	location = {Vancouver, BC, Canada},
	doi = {10.1109/CEC.2016.7744246},
	url = {http://ieeexplore.ieee.org/document/7744246/},
	descrip = {Introducing an algorithm for solving multiobjective optimization (MOO) problems via the global optimization algorithm DIRECT. Some theory and preliminary results, but no software. Likely not scalable for real-world computationally expensive problems, due to the number of boxes that would need to be divided per iteration using this method. More of a theoretical foundation for a later practical algorithm},
}

@inproceedings{aldujaili2016matlab,
	author = {Al-Dujaili, Abdullah and Suresh, Sundaram},
	title = {A {MATLAB} toolbox for surrogate-assisted multi-objective optimization: A preliminary study},
	year = {2016},
	month = {7},
	booktitle = {Proc. 2016 Genetic and Evolutionary Computation Conference Companion (GECCO '16)},
	pages = {1209--1216},
	organization = {ACM},
	location = {Denver, CO, USA},
	doi = {10.1145/2908961.2931703},
	url = {https://dl.acm.org/doi/10.1145/2908961.2931703},
	descrip = {A numerical software package written in MATLAB -- provides a surrogate modeling toolbox for multiobjective optimization problems},
}

@article{alizadeh2020managing,
	author = {Alizadeh, Reza and Allen, Janet K. and Mistree, Farrokh},
	title = {Managing computational complexity using surrogate models: a critical review},
	year = {2020},
	month = {7},
	journal = {Research in Engineering Design},
	volume = {31},
	number = {3},
	pages = {275--298},
	publisher = {Springer},
	doi = {10.1007/s00163-020-00336-7},
	url = {https://link.springer.com/10.1007/s00163-020-00336-7},
	issn = {0934-9839},
	descrip = {A survey and review of surrogate modeling and response-surface modeling (RSM) techniques used in engineering},
}

@article{andreani2022using,
	author = {Andreani, R. and Cust{\'o}dio, Ana Lu{\'i}sa and Raydan, M.},
	title = {Using first-order information in direct multisearch for multiobjective optimization},
	year = {2022},
	month = {11},
	journal = {Optimization Methods and Software},
	volume = {37},
	number = {6},
	pages = {2135--2156},
	publisher = {Taylor \& Francis},
	doi = {10.1080/10556788.2022.2060971},
	url = {https://www.tandfonline.com/doi/full/10.1080/10556788.2022.2060971},
	issn = {1055-6788},
	descrip = {Is derivative / gradient information counterproductive for solving MOOs? In this paper, it appears to make direct-search type methods perform worse by the metrics used. It could be that the metrics favor diversity over convergence, in which case one can get better diversity by taking bad evaluations. But I need to read more carefully to decide whether that is what's going on here},
}

@inproceedings{astudillo2021thinking,
	author = {Astudillo, Raul and Frazier, Peter I.},
	title = {Thinking inside the box: a tutorial on grey-box bayesian optimization},
	year = {2021},
	month = {12},
	booktitle = {Proc. 2021 Winter Simulation Conference (WSC 2021)},
	articleno = {2},
	numpages = {15},
	organization = {IEEE},
	location = {Phoenix, Arizona},
	doi = {10.1109/WSC52266.2021.9715343},
	url = {https://ieeexplore.ieee.org/document/9715343/},
	descrip = {Applying grey-box bayesian optimization tutorial: using Bayesian optimization on structured problems, where a blackbox function is composed with an algebraic function, just like with ParMOO and Jeff's GOOMBAH paper. Tutorial performed using BoTorch},
}

@article{audet2008multiobjective,
	author = {Audet, Charles and Savard, Gilles and Zghal, Walid},
	title = {Multiobjective optimization through a series of single-objective formulations},
	year = {2008},
	month = {1},
	journal = {SIAM Journal on Optimization},
	volume = {19},
	number = {1},
	pages = {188--210},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/060677513},
	url = {http://epubs.siam.org/doi/10.1137/060677513},
	issn = {1052-6234},
	descrip = {BiMADS -- a biobjective direct search / generalized pattern search via the MADS algorithm with an adaptive weighting scheme to trace the Pareto front from one end to the other. The numerical software implementation is part of the NOMAD software package (written in C++)},
}

@article{audet2009progressive,
	author = {Audet, Charles and Dennis, John E.},
	title = {A Progressive Barrier for Derivative-Free Nonlinear Programming},
	year = {2009},
	month = {1},
	journal = {SIAM Journal on Optimization},
	volume = {20},
	number = {1},
	pages = {445--472},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/070692662},
	url = {http://epubs.siam.org/doi/10.1137/070692662},
	issn = {1052-6234},
	descrip = {The progressive barrier penalty for nonlinear blackbox optimization methods. Basically adds a progressive penalty for violating constraints based on the distance to feasibility},
}

@article{audet2010mesh,
	author = {Audet, Charles and Savard, Gilles and Zghal, Walid},
	title = {A mesh adaptive direct search algorithm for multiobjective optimization},
	year = {2010},
	month = {8},
	journal = {European Journal of Operational Research},
	volume = {204},
	number = {3},
	pages = {545--556},
	publisher = {Elsevier BV},
	doi = {10.1016/j.ejor.2009.11.010},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221709008601},
	issn = {0377-2217},
	descrip = {Multi-MADS -- a multiobjective direct search / generalized pattern search via MADS algorithm, using normal boundary intersection (NBI) for adaptive weighting},
}

@book{audet2017derivativefree,
	author = {Audet, Charles and Hare, Warren},
	title = {Derivative-free and blackbox optimization},
	year = {2017},
	booktitle = {Springer Series in Operations Research and Financial Engineering},
	series = {Springer Series in Operations Research and Financial Engineering},
	publisher = {Springer International},
	address = {Charm, Switzerland},
	doi = {10.1007/978-3-319-68913-5},
	url = {http://link.springer.com/10.1007/978-3-319-68913-5},
	isbn = {9783319689128},
	issn = {1431-8598},
	descrip = {Book on fundamental methods, terminology, and theory in blackbox and derivative-free optimization (DFO) -- covers topics such as definitions of blackbox functions, heuristics, classical methods, positive bases and minimum spanning sets, generalized pattern search, and direct search, fully linear and quadratic models, model-drive descent and trust-region methods and ensuring model quality, general surrogate modeling, constraints, and multiobjective basics.},
}

@article{audet2021performance,
	author = {Audet, Charles and Bigeon, Jean and Cartier, Dominique and Digabel}, SÃ©bastien {Le and Salomon, Ludovic},
	title = {Performance indicators in multiobjective optimization},
	year = {2021},
	month = {7},
	journal = {European Journal of Operational Research},
	volume = {292},
	number = {2},
	pages = {397--422},
	publisher = {Elsevier BV},
	doi = {10.1016/j.ejor.2020.11.016},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221720309620},
	issn = {0377-2217},
	descrip = {A thorough survey of over 50 commonly used performance indicators in multiobjective optimization -- key takeaways: performance metrics can measure different properties of an algorithm, such as whether it is converging to the true Pareto front, the coverage of the true Pareto front, and the average diversity of solutions. One of the only metrics that is monotonic (i.e., cannot become worse when a solution contains a previous solution) is the hypervolume indicator, which is the standard in evolutionary algorithms},
	keywords = {Multiobjective optimization, Quality indicators, Performance indicators},
}

@article{audet2022algorithm,
	author = {Audet, Charles and Le Digabel, S\'{e}bastien and Rochon Montplaisir, Viviane and Tribes, Christophe},
	title = {{Algorithm 1027}: {NOMAD} Version 4: Nonlinear Optimization with the {MADS} Algorithm},
	year = {2022},
	month = {9},
	journal = {ACM Transactions on Mathematical Software},
	volume = {48},
	number = {3},
	articleno = {35},
	numpages = {22},
	publisher = {ACM},
	doi = {10.1145/3544489},
	url = {https://dl.acm.org/doi/10.1145/3544489},
	issn = {0098-3500},
	descrip = {NOMAD v4 -- open source numerical software package (in C++) for blackbox and derivative-free optimization via the MADS algorithms. After publication, they have added support for multiobjective optimization, mixed variables, nonlinear constraints, etc. Great example of high-impact open source numerical and optimization software. Improvements over NOMAD v3 include improvements to fundamental algorithms, coding practices, release process, and general project structure to support continuous research and development into the future},
}

@inproceedings{audet2023general,
	author = {Audet, Charles and Hall{\'e}-Hannan, Edward and Le Digabel, S{\'e}bastien},
	title = {A general mathematical framework for constrained mixed-variable blackbox optimization problems with meta and categorical variables},
	year = {2023},
	month = {2},
	booktitle = {Operations Research Forum},
	volume = {4},
	number = {1},
	numpages = {12},
	organization = {Springer},
	doi = {10.1007/s43069-022-00180-6},
	url = {https://link.springer.com/10.1007/s43069-022-00180-6},
	issn = {2662-2556},
	descrip = {Handling categorical/integer/mixed variables in blackbox optimization: This is the method used to perform hyperparameter tuning of neural-networks and other AI models via MADS. In general, they decompose variables into meta variables (which determine whether other variables are active or not, such as the number of layers in the network which can deactivate variables associated with inactive layers), categorical variables (which either need to be embedded somehow or can be explored in an unordered manner via direct search / generalized pattern search), and finally standard variables which includes both continuous and relaxed integer variables},
}

@inproceedings{balandat2020botorch,
	author = {Balandat, Maximilian and Karrer, Brian and Jiang, Daniel and Daulton, Samuel and Letham, Ben and Wilson, Andrew G and Bakshy, Eytan},
	editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.},
	title = {{BoTorch}: A Framework for Efficient {M}onte-{C}arlo {B}ayesian Optimization},
	year = {2020},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {33},
	pages = {21524--21538},
	organization = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper/2020/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf},
	descrip = {BoTorch: Modular bayesian optimization framework and numerical software package. Uses Ax for deploying A/B testing applications. Uses pytorch for autograd, and uses monte carlo sampling and kernel reparameterization tricks in order to efficiently evaluate composite objective and acquisition functions and non gaussian kernels. Great example of high-impact open source numerical software and optimization software},
}

@techreport{balay2022petsc/tao,
	author = {Balay, Satish and Abhyankar, Shrirang and Adams, Mark F. and Benson, Steven and Brown, Jed and Brune, Peter and Buschelman, Kris and Constantinescu, Emil and Dalcin, Lisandro and Dener, Alp and Eijkhout, Victor and Gropp, William D. and Hapla, V\'{a}clav and Isaac, Tobin and Jolivet, Pierre and Karpeev, Dmitry and Kaushik, Dinesh and Knepley, Matthew G. and Kong, Fande and Kruger, Scott and May, Dave A. and McInnes, Lois Curfman and Mills, Richard Tran and Mitchell, Lawrence and Munson, Todd and Roman, Jose E. and Rupp, Karl and Sanan, Patrick and Sarich, Jason and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Hong and Zhang, Junchao},
	title = {{PETSc/TAO} Users Manual},
	year = {2022},
	number = {ANL-21/39 - Revision 3.17},
	institution = {Argonne National Laboratory},
	address = {Lemont, IL, USA},
	url = {https://petsc.org/release/docs/manual/manual.pdf},
	descrip = {The PETSc user's guide. I haven't used it but PETSc is a widely-used C++ numerical software library and linear algebra / iterative algorithms framework developed at Argonne and used for implementing many well-known iterative solvers, especially in the area of CFD. This is a great example of high-impact open source numerical software and best practices in open source scientific software. Now ships together with TAO, a similar simulation optimization software package},
}

@article{bandyopadhyay2008simulated,
	author = {Bandyopadhyay, Sanghamitra and Saha, Sriparna and Maulik, Ujjwal and Deb, Kalyanmoy},
	title = {A Simulated Annealing-Based Multiobjective Optimization Algorithm: {AMOSA}},
	year = {2008},
	month = {6},
	journal = {IEEE Transactions on Evolutionary Computation},
	volume = {12},
	number = {3},
	pages = {269--283},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/TEVC.2007.900837},
	url = {http://ieeexplore.ieee.org/document/4358775/},
	issn = {1941-0026},
	descrip = {AMOSA algorithm -- apparently this is a widely-known standard in multiobjective simulated annealing because reviewers regularly ask me to cite this. But I've never met anyone who uses this and I can't find the software anywhere. The algorithm seems very reasonable though},
}

@article{barbagonzÃ¡lez2018jmetalsp,
	author = {Barba-GonzÃ¡lez, CristÃ³bal and GarcÃ­a-Nieto, JosÃ© and Nebro, Antonio J. and Cordero, JosÃ© A. and Durillo, Juan J. and Navas-Delgado, Ismael and Aldana-Montes, JosÃ© F.},
	title = {{jMetalSP}: A framework for dynamic multi-objective big data optimization},
	year = {2018},
	month = {8},
	journal = {Applied Soft Computing},
	volume = {69},
	pages = {737--748},
	publisher = {Elsevier BV},
	doi = {10.1016/j.asoc.2017.05.004},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1568494617302557},
	issn = {1568-4946},
	descrip = {An open source numerical software library for solving multiobjective optimization problems in java in real-time via heuristics. The authors combine jMetal with data streaming via Apache Spark to solve distributed multiobjective optimization problems with streaming data in real-time},
}

@article{barker2022introducing,
	author = {Barker, Michelle and Chue Hong, Neil P. and Katz, Daniel S. and Lamprecht, Anna-Lena and Martinez-Ortiz, Carlos and Psomopoulos, Fotis and Harrow, Jennifer and Castro, Leyla Jael and Gruenpeter, Morane and Martinez, Paula Andrea and Honeyman, Tom},
	title = {Introducing the {FAIR} Principles for research software},
	year = {2022},
	month = {10},
	journal = {Scientific Data},
	volume = {9},
	number = {1},
	numpages = {622},
	publisher = {Nature Publishing Group},
	doi = {10.1038/s41597-022-01710-x},
	url = {https://www.nature.com/articles/s41597-022-01710-x},
	issn = {2052-4463},
	descrip = {The FAIR principles for open source scientific software, data, source code, and experiments should by findable (via DOIs or other), accessible (clear purpose and metadata), interoperable (should use standard interfaces, data formats, and schemas), and reusable (well documented, understandable, and not overly specialized to an unnecessarilly niche use-case). These are good principles for any open source software development practices},
}

@article{benitezhidalgo2019jmetalpy,
	author = {Ben{\'i}tez-Hidalgo, Antonio and Nebro, Antonio J. and Garc{\'i}a-Nieto, Jos{\'e} and Oregi, Izaskun and Ser}, Javier {Del},
	title = {{jMetalPy}: A {P}ython framework for multi-objective optimization with metaheuristics},
	year = {2019},
	month = {12},
	journal = {Swarm and Evolutionary Computation},
	volume = {51},
	numpages = {100598},
	publisher = {Elsevier BV},
	doi = {10.1016/j.swevo.2019.100598},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2210650219301397},
	issn = {2210-6502},
	descrip = {jMetalPy -- a Python framework for solving MOOs with EAs -- this open source numerical software is a Python implementation of jMetal, with some improvements to code quality and new features for better open source software development and parallelism},
}

@article{berkemeier2021derivativefree,
	author = {Berkemeier, Manuel and Peitz, Sebastian},
	title = {Derivative-Free Multiobjective Trust Region Descent Method Using Radial Basis Function Surrogate Models},
	year = {2021},
	month = {4},
	journal = {Mathematical and Computational Applications},
	volume = {26},
	number = {2},
	numpages = {31},
	publisher = {Multidisciplinary Digital Publishing Institute},
	doi = {10.3390/mca26020031},
	url = {https://www.mdpi.com/2297-8747/26/2/31},
	issn = {2297-8747},
	descrip = {A numerical algorithm for multiobjective descent, using RBF surrogates + trust regions. Builds heavily off of Stefan's PhD thesis (ORBIT)},
}

@article{beume2009complexity,
	author = {Beume, Nicola and Fonseca, Carlos M. and Lopez-Ibanez, Manuel and Paquete, Luis and Vahrenhold, Jan},
	title = {On the complexity of computing the hypervolume indicator},
	year = {2009},
	month = {10},
	journal = {IEEE Transactions on Evolutionary Computation},
	volume = {13},
	number = {5},
	pages = {1075--1082},
	publisher = {IEEE},
	doi = {10.1109/TEVC.2009.2015575},
	url = {http://ieeexplore.ieee.org/document/5208224/},
	issn = {1941-0026},
	descrip = {Proof that the complexity of calculating the hypervolume indicator with o objectives is exponential. Roughly the same reasons that calculating simplices in an o-dimensional Delaunay triangulation or computing the facets of an o-dimensional convex hull are exponential},
}

@techreport{biedron2019fun3d,
	author = {Biedron, Robert T. and Carlson, Jan Renee and Derlaga, Joseph M. and Gnoffo, Peter A. and Hammond, Dana P. and Jones, William T. and Kleb, Bill and Lee-Rausch, Elizabeth M. and Nielson, Eric J. and Park, Michael A. and Rumsey, Christopher L. and Thomas, James L. and Thompson, Kyle B. and Wood, William A.},
	title = {{FUN3D Manual}: 13.6},
	year = {2019},
	number = {{NASA} {T}echnical {M}emorandum ({TM}) 2019-220416},
	institution = {NASA Langley Research Center},
	address = {Hampton, VA, USA},
	url = {https://fun3d.larc.nasa.gov/papers/FUN3D_Manual-13.6.pdf},
	descrip = {NASA's FUN3D CFD solver. This is one of the oldest and standard numerical softwares for solving CFD problems. Written in mostly Fortran 90. Uses a form of the problem that yields the adjoints, which can be used to optimize structures in fewer steps and perform sensitivity analyses. The kernel uses an iterative solver to solve a massive block-sparse linear system (I think derived from the weak form). Some a priori multiobjective optimization solvers are described in Section 9.9},
}

@article{bigeon2020dmultimads,
	author = {Bigeon, Jean and Le Digabel, S{\'e}bastien and Salomon, Ludovic},
	title = {{DM}ulti-{MADS}: {M}esh adaptive direct multisearch for blackbox multiobjective optimization},
	year = {2020},
	month = {6},
	journal = {Computational Optimization and Applications},
	volume = {79},
	number = {2},
	pages = {301--338},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s10589-021-00272-9},
	url = {https://link.springer.com/10.1007/s10589-021-00272-9},
	issn = {0926-6003},
	descrip = {DMulti-MADS: Improved Multi-MADS using direct search / generalized pattern search plus some improvements to the Multi-MADS algorithm -- I need to re-read this to remember what the improvements were},
}

@article{biscani2020parallel,
	author = {Biscani, Francesco and Izzo, Dario},
	title = {A parallel global multiobjective framework for optimization: pagmo},
	year = {2020},
	month = {9},
	journal = {Journal of Open Source Software},
	volume = {5},
	number = {53},
	numpages = {2338},
	publisher = {The Open Journal},
	doi = {10.21105/joss.02338},
	url = {https://joss.theoj.org/papers/10.21105/joss.02338},
	issn = {2475-9066},
	descrip = {pagmo/pygmo - Parallel frameworks for solving multiobjective optimization problems (MOO) in Java and Python. Great example of open source numerical software, published in JOSS},
}

@article{blank2020pymoo,
	author = {Blank, Julian and Deb, Kalyanmoy},
	title = {{pymoo}: Multi-Objective Optimization in {Python}},
	year = {2020},
	journal = {IEEE Access},
	volume = {8},
	pages = {89497--89509},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/ACCESS.2020.2990567},
	url = {https://ieeexplore.ieee.org/document/9078759/},
	issn = {2169-3536},
	git = {http://github.com/anyoptimization/pymoo},
	descrip = {pymoo is an open source software package implementing NSGA-II, NSGA-III, and many other multiobjective evolutionary algorithms (MOEAs), plus extensions for handling things such as categorical variables. This is a well-maintained and well-documented open-source numerical software package. It is maintained by the lab of the original NSGA-II author, and therefore could be considered the official NSGA-II implementation. all source code in Python},
}

@article{bollapragada2020optimization,
	author = {Bollapragada, Raghu and Menickelly, Matt and Nazarewicz, Witold and O'Neal, Jared and Reinhard, Paul-Gerhard and Wild, Stefan M.},
	title = {Optimization and supervised machine learning methods for fitting numerical physics models without derivatives},
	year = {2020},
	month = {2},
	journal = {Journal of Physics G: Nuclear and Particle Physics},
	volume = {48},
	number = {2},
	numpages = {24001},
	publisher = {IOP Publishing},
	doi = {10.1088/1361-6471/abd009},
	url = {https://iopscience.iop.org/article/10.1088/1361-6471/abd009},
	issn = {0954-3899},
	descrip = {Methodolgies for calibrating the Fayans EDF model to experimental data. Data is expensive and limited and the model itself is computationally expensive, so this is a classical inverse problem. The problem is actually multiobective because the data themselves come from various categories representing different types of observations, and the standard deviations for each of these observables is not known. Could be configured as a 3 or 9-objective problem},
}

@article{bouhlel2019python,
	author = {Bouhlel, Mohamed Amine and Hwang, John T. and Bartoli, Nathalie and Lafage, RÃ©mi and Morlier, Joseph and Martins, Joaquim R.R.A.},
	title = {A {P}ython surrogate modeling framework with derivatives},
	year = {2019},
	month = {9},
	journal = {Advances in Engineering Software},
	volume = {135},
	pages = {102--662},
	publisher = {Elsevier BV},
	doi = {10.1016/j.advengsoft.2019.03.005},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0965997818309360},
	issn = {0965-9978},
	descrip = {The open source numerical software package (in Python) pySMT. This is a surrogate modeling and Bayesian optimization toolbox for solving multidisciplinary engineering design optimization (MDO) problems, while utilizing derivatives and providing numerical stability analysis for each surrogate model class.},
}

@article{bradford2018efficient,
	author = {Bradford, Eric and Schweidtmann, Artur M. and Lapkin, Alexei},
	title = {Efficient multiobjective optimization employing {Gaussian} processes, spectral sampling and a genetic algorithm},
	year = {2018},
	month = {6},
	journal = {Journal of Global Optimization},
	volume = {71},
	number = {2},
	pages = {407--438},
	publisher = {Springer},
	doi = {10.1007/s10898-018-0609-2},
	url = {http://link.springer.com/10.1007/s10898-018-0609-2},
	issn = {0925-5001},
	descrip = {A Multiobjective Bayesian optimization algorithm, very similar to ParEGO -- this algorithm uses the Gaussian process surrogates with NSGA-II to solve the problem. However, spectral sampling and thompson sampling are then employed to subselect a diverse set of candidates for batch evaluation. The resulting algorithm is called TSEMO},
}

@article{bras2020use,
	author = {Br{\'a}s, Carmo P. and Cust{\'o}dio, Ana Lu{\'\i}sa},
	title = {On the use of polynomial models in multiobjective directional direct search},
	year = {2020},
	month = {12},
	journal = {Computational Optimization and Applications},
	volume = {77},
	number = {3},
	pages = {897--918},
	publisher = {Springer},
	doi = {10.1007/s10589-020-00233-8},
	url = {https://link.springer.com/10.1007/s10589-020-00233-8},
	issn = {0926-6003},
	descrip = {A study on utilizing polynomial surrogate models during multiobjective direct search and generalized pattern search techniques},
}

@article{bratley1988algorithm,
	author = {Bratley, Paul and Fox, Bennett L.},
	title = {Algorithm 659: Implementing Sobol's Quasirandom Sequence Generator},
	year = {1988},
	month = {3},
	journal = {ACM Transactions on Mathematical Software},
	volume = {14},
	number = {1},
	numpages = {13},
	publisher = {Association for Computing Machinery},
	doi = {10.1145/42288.214372},
	url = {https://doi.org/10.1145/42288.214372},
	issn = {0098-3500},
	descrip = {The original TOMS open source numerical software code implementing Sobol sequence (low discrepancy sequence) generation in Fortran 90. Apparently there is a bug or limitation to this code, fixed by Joe et al. 2003 in their TOMS Remark on 659, and subsequent publication of a new generator used in Scipy},
}

@article{bringmann2013approximation,
	author = {Bringmann, Karl and Friedrich, Tobias},
	title = {Approximation quality of the hypervolume indicator},
	year = {2013},
	month = {2},
	journal = {Artificial Intelligence},
	volume = {195},
	number = {0004-3702},
	pages = {265--290},
	publisher = {Elsevier BV},
	doi = {10.1016/j.artint.2012.09.005},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370212001178},
	issn = {0004-3702},
	descrip = {Analysis of hypervolume indicator as proxy for solution set quality -- results for 2-objectives only, this paper shows that the hypervolume indicator is the best single indicator we have, but with some caveates},
}

@article{cameron2019moana,
	author = {Cameron, Kirk W. and Anwar, Ali and Cheng, Yue and Xu, Li and Li, Bo Ananth  Uday and Bernard, Jon and Jearls, Chandler and Lux, Thomas and Hong, Yili and Watson, Layne T. and Butt, Ali R.},
	title = {{MOANA}: {M}odeling and analyzing {I/O} variability in parallel system experimental design},
	year = {2019},
	month = {8},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	volume = {30},
	number = {8},
	pages = {1843--1856},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/tpds.2019.2892129},
	url = {https://ieeexplore.ieee.org/document/8631172/},
	issn = {1045-9219},
	descrip = {Key findings from the VarSys project on modeling HPC performance variability with surrogates and RSM, and using these models to inform decision making through visualizations, optimization, and otherwise},
}

@article{campana2018multiobjective,
	author = {Campana, Emilio Fortunato and Diez, Matteo and Liuzzi, Giampaolo and Lucidi, Stefano and Pellegrini, Riccardo and Piccialli, Veronica and Rinaldi, Francesco and Serani, Andrea},
	title = {A multi-objective {DIRECT} algorithm for ship hull optimization},
	year = {2018},
	month = {9},
	journal = {Computational Optimization and Applications},
	volume = {71},
	number = {1},
	pages = {53--72},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s10589-017-9955-0},
	url = {http://link.springer.com/10.1007/s10589-017-9955-0},
	issn = {0926-6003},
	descrip = {The open source numerical software MODIR is proposed here. MODIR can be used to solve multiobjective blackbox optimization problems via a multiobjective variant of the DIRECT blackbox algorithm (direct search method). The motivating application is a multidisciplinary shiphull engineering design problem},
}

@inproceedings{chang2020managing,
	author = {Chang, Tyler H. and Larson, Jeffrey and Watson, Layne T. and Lux, Thomas C. H.},
	title = {Managing computationally expensive blackbox multiobjective optimization problems using {libEnsemble}},
	year = {2020},
	booktitle = {Proc. 2020 Spring Simulation Conference (SpringSim 2020), the 28th High Performance Computing Symposium (HPC '20)},
	numpages = {31},
	organization = {SCS},
	location = {Fairfax, VA, USA},
	doi = {10.22360/SpringSim.2020.HPC.001},
	url = {https://dl.acm.org/doi/abs/10.5555/3408207.3408245},
	descrip = {Paper on the challenges of integrating VTMOP into the libEnsemble parallel computing Python software library at Argonne},
}

@phdthesis{chang2020mathematical,
	author = {Chang, Tyler H.},
	title = {Mathematical Software for Multiobjective Optimization Problems},
	year = {2020},
	school = {Virginia Tech, Dept. of Computer Science},
	url = {https://vtechworks.lib.vt.edu/handle/10919/98915},
	descrip = {My PhD thesis, including multiobjective optimization techniques, algorithm, performance analysis, and software review; description of VTMOP, running parallel simulations, integrating with libE. Also scientific machine learning via Delaunay interpolation and algorithms and proofs for doing so. Several applications related to HPC performance modeling and autotuning.},
}

@inproceedings{chang2020multiobjective,
	author = {Chang, Tyler H. and Larson, Jeffrey and Watson, Layne T.},
	title = {Multiobjective optimization of the variability of the high-performance {LINPACK} solver},
	year = {2020},
	month = {12},
	booktitle = {Proc. 2020 Winter Simulation Conference (WSC 2020)},
	pages = {3081--3092},
	organization = {IEEE},
	location = {Orlando, FL, USA},
	doi = {10.1109/WSC48552.2020.9383875},
	url = {https://ieeexplore.ieee.org/document/9383875/},
	descrip = {A study on the multiobjective optimization of the LINPACK benchmark's config files on the leadership class HPC Bebop at Argonne National Laboratory. We used VTMOP but some modifications were required to ensure that mixed variables were properly handled. Some of the techniques that we used here inspired me to provide automatic support in ParMOO. Ultimately, we achieve 3x reduction in performance variability without sacrificing max/mean throughput.},
}

@article{chang2022algorithm,
	author = {Chang, Tyler H. and Watson, Layne T. and Larson, Jeffrey and Neveu, Nicole and Thacker, William I. and Deshpande, Shubhangi and Lux, Thomas C. H.},
	title = {{Algorithm 1028}: {VTMOP}: Solver for Blackbox Multiobjective Optimization Problems},
	year = {2022},
	month = {9},
	journal = {{ACM} Transactions on Mathematical Software},
	volume = {48},
	number = {3},
	numpages = {36},
	publisher = {Association for Computing Machinery (ACM)},
	doi = {10.1145/3529258},
	url = {https://dl.acm.org/doi/10.1145/3529258},
	issn = {0098-3500},
	git = {https://github.com/Libensemble/libe-community-examples/tree/main/vtmop},
	descrip = {Publication of my second open source numerical software package: VTMOP a Fortran software for solving blackbox multiobjective optimization problems. Uses surrogate modeling (RSM), with an adaptive weighting scheme, within a trust region framework. The motivating application is a particle accelerator tuning problem at SLAC},
}

@inproceedings{chang2023framework,
	author = {Chang, Tyler H. and Elias, Jakob R. and Wild, Stefan M. and Chaudhuri, Santanu and Libera, Joseph A.},
	title = {A framework for fully autonomous design of materials via multiobjective optimization and active learning: challenges and next steps},
	year = {2023},
	booktitle = {11th Intl. Conf. on Learning Representation (ICLR 2023), Workshop on Machine Learning for Materials (ML4Materials)},
	pages = {1--10},
	location = {Kigali, Rwanda},
	url = {https://openreview.net/forum?id=8KJS7RPjMqG},
	note = {to appear},
	descrip = {Using ParMOO software with the MDML software (wrapper on Apache Kafka with automatic data logging and analysis dashboard) in order to optimize chemical manufacturing processes in a wet-lab environment. The kafka querries are sent directly to a continuous flow reactor (CFR) through a smart-lab setup in the MERF at Argonne. Through this setup, ParMOO is able to automatically steer the solvents, bases, temperatures, flow rates, and mixing ratios of a complex chemical manufacturing process in order to produce optimized yields and purities -- achieving multi-hundred-fold improvement over the previous manual process},
}

@article{chang2023parmoo,
	author = {Chang, Tyler H. and Wild, Stefan M.},
	title = {{ParMOO}: A {P}ython library for parallel multiobjective simulation optimization},
	year = {2023},
	month = {2},
	journal = {Journal of Open Source Software},
	volume = {8},
	number = {82},
	numpages = {4468},
	publisher = {The Open Journal},
	doi = {10.21105/joss.04468},
	url = {https://joss.theoj.org/papers/10.21105/joss.04468},
	issn = {2475-9066},
	descrip = {The ParMOO JOSS article -- ParMOO is my open source numerical software package and library ParMOO, written in Python, which can be used for implementing custom solvers for multiobjective simulation optimization problems, while supporting mixed variables, non linear constraints, and diverse and custom surrogte models, and composite structures where some components of the problem are blackbox, but the rest are algebraic. In later releases, ParMOO also supports interactive visualization of results via Plotly + Dash, parallel and distributed function evaluations via libEnsemble, and automatic gradient calculations and just-in-time compilation via jax},
}

@misc{chang2024designing,
	author = {Chang, Tyler H. and Wild, Stefan M.},
	title = {Designing a Framework for Solving Multiobjective Simulation Optimization Problems},
	year = {2024},
	month = {3},
	booktitle = {INFORMS Journal on Computing},
	publisher = {INFORMS Journal on Computing},
	doi = {10.1287/ijoc.2023.0250.cd},
	url = {https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0250},
	issn = {1091-9856},
	note = {Available for download at https://github.com/INFORMSJoC/2023.0250},
	descrip = {This is the OJOC ParMOO repository DOI -- this is an archive of the software experiments for obtaining our test problems and reproducing our experimental results on those test problems with customized ParMOO solvers.},
}

@techreport{chang2024parmoo,
	author = {Chang, Tyler H. and Wild, Stefan M. and Dickinson, Hyrum},
	title = {{ParMOO}: {P}ython library for parallel multiobjective simulation optimization},
	year = {2024},
	number = {Version 0.4.1},
	institution = {Argonne National Laboratory},
	address = {Lemont, IL, USA},
	url = {https://parmoo.readthedocs.io/en/latest},
	descrip = {The ParMOO docs -- ParMOO is my open source numerical software package and library ParMOO, written in Python, which can be used for implementing custom solvers for multiobjective simulation optimization problems, while supporting mixed variables, non linear constraints, and diverse and custom surrogte models, and composite structures where some components of the problem are blackbox, but the rest are algebraic. In later releases, ParMOO also supports interactive visualization of results via Plotly + Dash, parallel and distributed function evaluations via libEnsemble, and automatic gradient calculations and just-in-time compilation via jax},
}

@article{chang2025designing,
	author = {Chang, Tyler H. and Wild, Stefan M.},
	title = {Designing a Framework for Solving Multiobjective Simulation Optimization Problems},
	year = {2025},
	month = {3},
	journal = {INFORMS Journal on Computing},
	publisher = {Institute for Operations Research and the Management Sciences (INFORMS)},
	doi = {10.1287/ijoc.2023.0250},
	url = {https://pubsonline.informs.org/doi/10.1287/ijoc.2023.0250},
	issn = {1091-9856},
	descrip = {The ParMOO IJOC article describing the design of the ParMOO software, motivation, and providing examples of how ParMOO can be used to solve common scientific problems more efficiently with low effort -- ParMOO is my open source numerical software package and library ParMOO, written in Python, which can be used for implementing custom solvers for multiobjective simulation optimization problems, while supporting mixed variables, non linear constraints, and diverse and custom surrogte models, and composite structures where some components of the problem are blackbox, but the rest are algebraic. In later releases, ParMOO also supports interactive visualization of results via Plotly + Dash, parallel and distributed function evaluations via libEnsemble, and automatic gradient calculations and just-in-time compilation via jax},
}

@inproceedings{chard2020funcx,
	author = {Chard, Ryan and Babuji, Yadu and Li, Zhuozhao and Skluzacek, Tyler and Woodard, Anna and Blaiszik, Ben and Foster, Ian and Chard, Kyle},
	title = {{funcX}: A federated function serving fabric for science},
	year = {2020},
	month = {6},
	booktitle = {Proc. 29th International Symposium on High-Performance Parallel and Distributed Computing (HPDC '20)},
	pages = {65--76},
	organization = {ACM},
	location = {Stockholm, Sweden},
	doi = {10.1145/3369583.3392683},
	url = {https://dl.acm.org/doi/10.1145/3369583.3392683},
	descrip = {The funcX and updated Globus publication on the techniques and benefits of using a function-as-a-service (FaaS) framework to perform scientific experimentation at Argonne and other labs. funcX and Globus are scientific software products for performing distributed function evaluations and parallel computing that started at Argonne, and spun off into independent companies},
}

@inproceedings{chen2023integrated,
	author = {Chen, Gongxiaohui and Chang, Tyler H. and Power, John and Jing, Chungunag},
	title = {An Integrated Multi-Physics Optimization Framework for Particle Accelerator Design},
	year = {2023},
	booktitle = {Proc. 2023 Winter Simulation Conference (WSC 2023), Industrial Applications Track},
	numpages = {2},
	location = {Orlando, FL, USA},
	doi = {10.48550/arXiv.2311.09415},
	descrip = {A particle accelerator tuning application with ParMOO -- we achieved very good results on a several hundred evaluation budget for the Argonne wakefield accelerator project},
}

@book{cheney2009course,
	author = {Cheney, Elliott W. and Light, William A.},
	title = {A Course in Approximation Theory},
	year = {2009},
	month = {1},
	booktitle = {Graduate Studies in Mathematics},
	series = {Graduate Studies in Mathematics},
	publisher = {AMS},
	address = {Providence, RI, USA},
	doi = {10.1090/gsm/101},
	url = {http://www.ams.org/gsm/101},
	isbn = {9780821847985},
	issn = {1065-7339},
	descrip = {The classic textbook by Cheney and Light on the fundamentals of approximation theory for multivariate functions -- topics include: basics of interpolation, approximation theory, and linear operators; multivariate polynomials, their interpolation nodes, and error kernels; selecting good polynomial interpolants via Newton and Lagrange type methods; positive-definite functions, kernel interpretations, and good kernels for interpolation; basis functions, orthonormal bases, common bases for interpolation and convergence rates; Chebyshev nodes; B-splines, Box splines, and thin-plate splines; and basics of artificial neural networks. Other topics include wavelets, orthogonal projection algorithms, Hilbert spaces, and reproducing kernel Hilbert spaces (RKHS).},
}

@misc{chollet2015keras,
	author = {Chollet, Fran\c{c}ois and others, },
	title = {Keras},
	year = {2015},
	howpublished = {\url{https://keras.io}},
	descrip = {The Keras docs -- great and highly impactful open source Python software, needs no introduction. A simplified interface for quickly building neural networks and other deep learning models with various backends frameworks such as Tensorflow, jax, and Pytorch.},
}

@techreport{chowdhary2024pyoed,
	author = {Chowdhary, Abhijit and Ahmed, Shady E. and Attia, Ahmed},
	title = {{PyOED}: An Extensible Suite for Data Assimilation and Model-Constrained Optimal Design of Experiments},
	year = {2024},
	month = {6},
	booktitle = {ACM Transactions on Mathematical Software},
	volume = {50},
	number = {2},
	articleno = {11},
	numpages = {22},
	institution = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/3653071},
	url = {https://doi.org/10.1145/3653071},
	issn = {0098-3500},
	descrip = {pyOED an open source Python numerical software library for performing optimal experimental design, e.g, for sensor placement at Argonne},
}

@article{cocchi2018implicit,
	author = {Cocchi, Guido and Liuzzi, Giampaolo and Papini, Alessandra and Sciandrone, Marco},
	title = {An implicit filtering algorithm for derivative-free multiobjective optimization with box constraints},
	year = {2018},
	month = {3},
	journal = {Computational Optimization and Applications},
	volume = {69},
	number = {2},
	pages = {267--296},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s10589-017-9953-2},
	url = {http://link.springer.com/10.1007/s10589-017-9953-2},
	issn = {0926-6003},
	descrip = {An algorithm for multiobjective implicit filtering (MOIF). Not mentioned here, but the open source numerical software for MOIF on the author's GitHub is often cited via this paper},
}

@article{cocchi2020augmented,
	author = {Cocchi, Guido and Lapucci, Matteo},
	title = {An augmented {Lagrangian} algorithm for multi-objective optimization},
	year = {2020},
	month = {9},
	journal = {Computational Optimization and Applications},
	volume = {77},
	number = {1},
	pages = {29--56},
	publisher = {Springer},
	doi = {10.1007/s10589-020-00204-z},
	url = {https://link.springer.com/10.1007/s10589-020-00204-z},
	issn = {0926-6003},
	descrip = {Building a multiobjective augmented Lagrangian -- basically, use a standard augmented Lagrangian penalty but apply it to all components of the objective. There is a proof that this will work. I don't use this method, but I use the same trick with the progressive barrier of Audet all the time and usually cite both papers},
}

@article{conn2008geometry,
	author = {Conn, Andrew R and Scheinberg, Katya and Vicente, Lu{\'\i}s N},
	title = {Geometry of interpolation sets in derivative free optimization},
	year = {2008},
	month = {6},
	journal = {Mathematical programming},
	volume = {111},
	number = {1-2},
	pages = {141--172},
	publisher = {Springer},
	doi = {10.1007/s10107-006-0073-5},
	url = {http://link.springer.com/10.1007/s10107-006-0073-5},
	issn = {0025-5610},
	descrip = {Andrew Conn's landmark paper on interpolation dataset geometry -- leads to the definition of sets being "well-poised" for interpolation, meaning that when the interpolation set's geometry meats some local geometric conditions (basically bounded away from singularity), then the resulting interpolant's error (and gradient / hessian errors) can be bounded and the resulting models can be used to perform gradient descent or SQP within a trust-region framework with guaranteed convergence},
}

@book{conn2009introduction,
	author = {Conn, Andrew R. and Scheinberg, Katya and Vicente, Luis N.},
	title = {Introduction to derivative-free optimization},
	year = {2009},
	month = {1},
	series = {MPS-SIAM Series on Optimization},
	publisher = {SIAM},
	address = {Philadelphia, PA, USA},
	doi = {10.1137/1.9780898718768},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9780898718768},
	isbn = {9780898716689},
	descrip = {Conn and Scheinberg book on DFO -- describes the geometry of good interpolation sets, linear and quadratic interpolants and how to use them for derivative-free gradient descent and SQP frameworks, bounds on interpolation and gradient errors of various models, and how to efficiently restore good geometry when the optimization algorithm samples points in a subspace},
}

@article{cooper2020pymoso,
	author = {Cooper, Kyle and Hunter, Susan R.},
	title = {{PyMOSO}: {S}oftware for multi-objective simulation optimization with {R-PERLE} and {R-MinRLE}},
	year = {2020},
	month = {4},
	journal = {INFORMS Journal on Computing},
	volume = {32},
	number = {4},
	pages = {1101--1108},
	publisher = {Institute for Operations Research and the Management Sciences (INFORMS)},
	doi = {10.1287/ijoc.2019.0902},
	url = {http://pubsonline.informs.org/doi/10.1287/ijoc.2019.0902},
	issn = {1091-9856},
	descrip = {PyMOSO: an open source Python numerical software library for solving multiobjective simulation optimization problems with integer and discrete variables via direct search / pattern search like techniques},
}

@article{costa2018rbfopt,
	author = {Costa, Alberto and Nannicini, Giacomo},
	title = {{RBFOpt}: an open-source library for black-box optimization with costly function evaluations},
	year = {2018},
	month = {12},
	journal = {Mathematical Programming Computation},
	volume = {10},
	number = {4},
	pages = {597--629},
	publisher = {Springer},
	doi = {10.1007/s12532-018-0144-7},
	url = {http://link.springer.com/10.1007/s12532-018-0144-7},
	issn = {1867-2949},
	descrip = {RBFOpt an open source library for solving single-objective blackbox optimization},
}

@inproceedings{cristescu2015surrogatebased,
	author = {Cristescu, Cristina and Knowles, Joshua},
	title = {Surrogate-based multiobjective optimization: {ParEGO} update and test},
	year = {2015},
	booktitle = {Workshop on Computational Intelligence (UKCI)},
	volume = {770},
	url = {https://www.cs.bham.ac.uk/~jdk/UKCI-2015.pdf},
	git = {https://github.com/CristinaCristescu/ParEGO_Eigen},
	descrip = {ParEGO latest code and update introducing algorithmic updates, improved software quality, and (I think) some parallel computing -- ParEGO is the first open source numerical multiobjective bayesian optimization software package and written in C++. It is basically EGO (the original Bayesian optimization software using expected improvment acquisition) plus augmented Lagrangian scalarization},
}

@article{custodio2011direct,
	author = {Cust\'odio, Ana Lu\'isa and Madeira, Jose F. A. and Vaz, A. Ismael F. and Vicente, Lu\'is N.},
	title = {Direct Multisearch for Multiobjective Optimization},
	year = {2011},
	month = {7},
	journal = {SIAM Journal on Optimization},
	volume = {21},
	number = {3},
	pages = {1109--1140},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/10079731x},
	url = {http://epubs.siam.org/doi/10.1137/10079731X},
	issn = {1052-6234},
	descrip = {Direct multisearch (DMS) is one of Custodio's earlier multiobjective direct search algorithms, which I think is a precursor to MutiGLODS. The numerical MATLAB software can be obtained by contacting her lab, but I'm not sure if they still distribute it as part of BoostDFO},
}

@article{custodio2018multiglods,
	author = {Cust{\'{o}}dio, Ana Lu\'isa and Madeira, Jose F. A.},
	title = {{MultiGLODS}: global and local multiobjective optimization using direct search},
	year = {2018},
	month = {10},
	journal = {Journal of Global Optimization},
	volume = {72},
	number = {2},
	pages = {323--345},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s10898-018-0618-1},
	url = {http://link.springer.com/10.1007/s10898-018-0618-1},
	issn = {0925-5001},
	descrip = {The MultiGLODS numerical software package is written in MATLAB and used for solving multiobjective optimization problems via direct search / pattern search with a clever restart algorithm for selecting directions to explore in order obtain good coverage of the Pareto front. I believe this version also can use polynomial surrogates to pre-select good search directions and filter out unneeded blackbox function / simulation evaluations. It is now part of the BoostDFO MATLAB numerical software toolkit, obtainable from contacting Custodio},
}

@inproceedings{dalal2008low,
	author = {Dalal, Ishaan L. and Stefan, Deian and Harwayne-Gidansky, Jared},
	title = {Low discrepancy sequences for {M}onte {C}arlo simulations on reconfigurable platforms},
	year = {2008},
	month = {7},
	booktitle = {2008 International Conference on Application-Specific Systems, Architectures and Processors},
	volume = {},
	number = {},
	pages = {108--113},
	organization = {IEEE},
	location = {Leuven, Belgium},
	doi = {10.1109/ASAP.2008.4580163},
	url = {http://ieeexplore.ieee.org/document/4580163/},
	descrip = {Applications of low-discrepancy sequences in Monte carlo simulation},
}

@article{dandurand2016quadratic,
	author = {Dandurand, Brian and Wiecek, Margaret M.},
	title = {Quadratic scalarization for decomposed multiobjective optimization},
	year = {2016},
	month = {10},
	journal = {{OR} Spectrum},
	volume = {38},
	number = {4},
	pages = {1071--1096},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s00291-016-0453-z},
	url = {http://link.springer.com/10.1007/s00291-016-0453-z},
	issn = {0171-6468},
	descrip = {Description and proof of coverage for a quadratic scalarization scheme for scalarizing multiobjective optimization problems},
}

@article{das1998normalboundary,
	author = {Das, Indraneel and Dennis, John E.},
	title = {Normal-boundary intersection: A new method for generating the {P}areto surface in nonlinear multicriteria optimization problems},
	year = {1998},
	month = {8},
	journal = {SIAM Journal on Optimization},
	volume = {8},
	number = {3},
	pages = {631--657},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/S1052623496307510},
	url = {http://epubs.siam.org/doi/10.1137/S1052623496307510},
	issn = {1052-6234},
	descrip = {The normal boundary intersection (NBI) method was one of the first adaptive scalarization schemes for multiobjective optimization problems. It uses linear scalarization but does so adaptively using the angle of the intersecting vector at a target point to set the weights in order to adaptively fill in gaps on the Pareto front},
}

@article{datta2016surrogateassisted,
	author = {Datta, Rituparna and Regis, Rommel G.},
	title = {A surrogate-assisted evolution strategy for constrained multi-objective optimization},
	year = {2016},
	month = {9},
	journal = {Expert Systems with Applications},
	volume = {57},
	pages = {270--284},
	publisher = {Elsevier BV},
	doi = {10.1016/j.eswa.2016.03.044},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417416301452},
	issn = {0957-4174},
	descrip = {An early paper on using surrogate models to reduce the cost (in terms of true simulation / blackbox function evaluations) when using multiobjective evolutionary algorithm to solve computationally expensive blackbox and simulation optimization problems},
}

@inproceedings{daulton2020differentiable,
	author = {Daulton, Samuel and Balandat, Maximilian and Bakshy, Eytan},
	editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.},
	title = {Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective {B}ayesian Optimization},
	year = {2020},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {33},
	pages = {9851--9864},
	organization = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper/2020/file/6fec24eac8f18ed793f5eaad3dd7977c-Paper.pdf},
	descrip = {A technique for differentiating expected hypervolume improvement EHVI (and its monte carlo variant qEHVI), which can be used as the acquisition function for solving multiobjective blackbox optimization problems with BoTorch},
}

@inproceedings{daulton2021parallel,
	author = {Daulton, Samuel and Balandat, Maximilian and Bakshy, Eytan},
	editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P.S. and Vaughan, J. Wortman},
	title = {Parallel {B}ayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement},
	year = {2021},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {34},
	pages = {2187--2200},
	organization = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper/2021/file/11704817e347269b7254e744b5e22dac-Paper.pdf},
	descrip = {The first paper on performing parallel Bayesian optimization using the expected hypervolume improvement acquisition function in BoTorch},
}

@article{deb2002fast,
	author = {Deb, Kalyanmoy and Pratap, Amrit and Agarwel, Sameer and Meyarivan, T.},
	title = {A fast and elitist multiobjective genetic algorithm: {NSGA-II}},
	year = {2002},
	month = {4},
	journal = {IEEE Transactions on Evolutionary Computation},
	volume = {6},
	number = {2},
	pages = {182--197},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/4235.996017},
	url = {http://ieeexplore.ieee.org/document/996017/},
	issn = {1089-778X},
	descrip = {The original NSGA-II paper: a multiobjective evolutionary algorithm (MOEA) that scales well and performs extremely well in practice. The main contribution is a fast method for performing nondominated sorting so that the authors can ensure all efficient points persist in every generation. This method is generally considered to be the baseline in multiobjective optimization. While the algorithm is a simple heuristic that is extremely wasteful in terms of the number of true blackbox function / simulation evaluations, it performs extremely well in practice by the hypervolume indicator. I have found that it is very difficult to obtain better performance than NSGA-II on both benchmark and real-world problems in the limit, unless you have some "secret sauce" to exploit for your particular problem},
}

@inproceedings{deb2002scalable,
	author = {Deb, Kalyanmoy and Thiele, Lothar and Laumanns, Marco and Zitzler, Eckart},
	title = {Scalable multi-objective optimization test problems},
	year = {2002},
	booktitle = {Proc. 2002 IEEE Congress on Evolutionary Computation (CEC '02)},
	volume = {1},
	pages = {825--830},
	organization = {IEEE},
	location = {Honolulu, HI, USA},
	doi = {10.1109/CEC.2002.1007032},
	url = {http://ieeexplore.ieee.org/document/1007032/},
	descrip = {The DTLZ test problems are the standard test problems used in all multiobjective evolutionary optimization papers. They are algebraic test problems that can scale to as many objectives and variables as one desires. Each problem also has a pathological property that makes it extremely difficult or degenerate for multiobjective optimization algorithms. This maeks the suite as a whole extremely convenient for testing, scaling, and evaluating results. However, several of the problems are so difficult that no solvers can reliably solve them. Additionally, all the problems have the property that the last "n" variables are essentially unused, with their optimum being 0.5 and not changing as we move across the Pareto front, which could be unrealistic for certain problems},
}

@article{deb2013evolutionary,
	author = {Deb, Kalyanmoy and Jain, Himanshu},
	title = {An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part {I}: solving problems with box constraints},
	year = {2013},
	month = {8},
	journal = {IEEE Transactions on Evolutionary Computation},
	volume = {18},
	number = {4},
	pages = {577--601},
	publisher = {IEEE},
	doi = {10.1109/TEVC.2013.2281535},
	url = {http://ieeexplore.ieee.org/document/6600851/},
	issn = {1089-778X},
	descrip = {The orgiinal NSGA-III paper part 1: a multiobjective evolutionary algorithm similar to NSGA-II, solving the drawback of NSGA-II performing poorly with many objectives by having the user provide a collection of well-spaced reference points and optimizing toward those},
}

@article{deshpande2016multiobjective,
	author = {Deshpande, Shubhangi and Watson, Layne T. and Canfield, Robert A.},
	title = {Multiobjective optimization using an adaptive weighting scheme},
	year = {2016},
	month = {1},
	journal = {Optimization Methods and Software},
	volume = {31},
	number = {1},
	pages = {110--133},
	publisher = {Informa UK Limited},
	doi = {10.1080/10556788.2015.1048861},
	url = {http://www.tandfonline.com/doi/full/10.1080/10556788.2015.1048861},
	issn = {1055-6788},
	descrip = {An algorithm for solving blackbox multiobjective optimization problems via trust region descent, using locally linear (shepard's method) surrogate models, and a multiobjective variant of DIRECT. Also, the authors propose a novel adaptive weighting scheme within the trust regions. The motivating application is an aircraft design optimization problem.},
}

@techreport{digabel2024taxonomy,
	author = {Digabel}, S\'ebastien {Le and Wild, Stefan M.},
	title = {A Taxonomy of Constraints in Black-Box Simulation-Based Optimization},
	year = {2024},
	month = {6},
	booktitle = {Optimization and Engineering},
	volume = {25},
	number = {2},
	pages = {1125--1143},
	institution = {Springer Science and Business Media LLC},
	doi = {10.1007/s11081-023-09839-3},
	url = {https://link.springer.com/10.1007/s11081-023-09839-3},
	issn = {1389-4420},
	descrip = {A taxonomy of constraint types encountered when solving blackbox / simulation optimization: quantifiable vs nonquantifiable, relaxable vs unrelaxable, a priori vs simulation-based, and known vs hidden.},
}

@article{dubey2021performance,
	author = {Dubey, Anshu and McInnes, Lois Curfman and Thakur, Rajeev and Draeger, Erik W. and Evans, Thomas and Germann, Timothy C. and Hart, William E.},
	title = {Performance Portability in the {E}xascale {C}omputing {P}roject: Exploration Through a Panel Series},
	year = {2021},
	month = {9},
	journal = {Computing in Science \& Engineering},
	volume = {23},
	number = {5},
	pages = {46--54},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/MCSE.2021.3098231},
	url = {https://ieeexplore.ieee.org/document/9495114/},
	issn = {1521-9615},
	descrip = {Achieving performance portability of parallel codes in the exascale computing project (ECP) across various GPU-based architectures, which is challenging since different GPU vendors use different GPU programming libraries (e.g., CUDA for NVIDIA vs HIPP for AMD)},
}

@article{dunning2017jump,
	author = {Dunning, Iain and Huchette, Joey and Lubin, Miles},
	title = {{JuMP}: A Modeling Language for Mathematical Optimization},
	year = {2017},
	month = {1},
	journal = {SIAM Review},
	volume = {59},
	number = {2},
	pages = {295--320},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/15M1020575},
	url = {https://epubs.siam.org/doi/10.1137/15M1020575},
	issn = {0036-1445},
	descrip = {The JuMP modeling language in Julia -- a modeling language for modeling and solving linear and nonlinear programming (optimization) problems in Julia. The implementation is an open source numerical software},
}

@article{durillo2011jmetal,
	author = {Durillo, Juan J. and Nebro, Antonio J.},
	title = {{jMetal}: A {J}ava framework for multi-objective optimization},
	year = {2011},
	month = {10},
	journal = {Advances in Engineering Software},
	volume = {42},
	number = {10},
	pages = {760--771},
	publisher = {Elsevier BV},
	doi = {10.1016/j.advengsoft.2011.05.014},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0965997811001219},
	issn = {0965-9978},
	descrip = {jMetal is an open source numerical software library implementing multiobjective optimization solvers in Java. Last I checked, most of the solvers were heuristic methods such as evolutionary algorithms and/or simulated annealing. This is widely used in some fields of engineering},
}

@book{ehrgott2005multicriteria,
	author = {Ehrgott, Matthias},
	title = {Multicriteria Optimization},
	year = {2005},
	series = {Lecture Notes in Economics and Mathematical Systems Series},
	edition = {2},
	publisher = {Springer Verlag},
	address = {Heidelberg, Germany},
	doi = {10.1007/3-540-27659-9},
	url = {http://link.springer.com/10.1007/3-540-27659-9},
	isbn = {3540213988},
	descrip = {A classical textbook on the fundamentals of multiobjective optimization theory. Topics include: basic definitions in multiobjective optimization, partial orderings and cones and basic theories, linear scalarization and its theory and drawbacks, other scalarization methods and their theory and drawbacks, standard algorithms for common types of multiobjective optimization problems, and sample applications},
}

@article{eichfelder2009scalarizations,
	author = {Eichfelder, Gabriele},
	title = {Scalarizations for adaptively solving multi-objective optimization problems},
	year = {2009},
	month = {11},
	journal = {Computational Optimization and Applications},
	volume = {44},
	number = {2},
	pages = {249--273},
	publisher = {Springer},
	doi = {10.1007/s10589-007-9155-4},
	url = {http://link.springer.com/10.1007/s10589-007-9155-4},
	issn = {0926-6003},
	descrip = {The Pascoletti-Serafini scalarization and its variations, this method involves drawing a line through the target to reach various points on the Pareto front. It is effective with nonconvex Pareto fronts, but it is not adaptive and not commonly used in modern algorithms},
}

@article{elias2020manufacturing,
	author = {Elias, Jakob R. and Chard, Ryan and Libera, Joseph A. and Foster, Ian T. and Chaudhuri, Santanu},
	title = {The Manufacturing Data and Machine Learning Platform: Enabling Real-time Monitoring and Control of Scientific Experiments via {IoT}},
	year = {2020},
	month = {6},
	journal = {2020 IEEE 6th World Forum on Internet of Things (WF-IoT)},
	pages = {1--2},
	publisher = {IEEE},
	address = {New Orleans, LA, USA},
	doi = {10.1109/WF-IoT48130.2020.9221078},
	url = {https://ieeexplore.ieee.org/document/9221078/},
	git = {GitHub: \url{https://github.com/anl-mdml/MDML_Client}},
	descrip = {The MDML open source software is a wrapper around Apache Kafka with protocols for fast data streaming and logging and dashboard generation. This framework was developed for usage at the material engineering research facility (MERF) at Argonne in order to facilitate the creation of a "smart lab" where MDML is the protocol for sending experiment requests to various equipment in the lab and logging results -- in an old (out-of-date branch) of ParMOO, this was a valid backend for launching simulation / experiment requests},
}

@inbook{emmerich2016multicriteria,
	author = {Emmerich, Michael and Yang, Kaifeng and Deutz, Andr{\'e} and Wang, Hao and Fonseca, Carlos M.},
	editor = {Pardalos, Panos M. and Zhigljavsky, Anatoly and {\v{Z}}ilinskas, Julius},
	title = {A Multicriteria Generalization of {Bayesian} Global Optimization},
	year = {2016},
	booktitle = {Advances in Stochastic and Deterministic Global Optimization},
	pages = {229--242},
	publisher = {Springer},
	doi = {10.1007/978-3-319-29975-4},
	url = {http://link.springer.com/10.1007/978-3-319-29975-4},
	isbn = {9783319299730},
	issn = {1931-6828},
	descrip = {A chapter from an optimization textbook on performing multiobjective Bayesian optimization using the expected hypervolume improvement (EHVI) scalarization / acquisition},
}

@article{eriksson2019scalable,
	author = {Eriksson, David and Pearce, Michael and Gardner, Jacob and Turner, Ryan D and Poloczek, Matthias},
	title = {Scalable global optimization via local bayesian optimization},
	year = {2019},
	journal = {Advances in Neural Information Processing Systems},
	volume = {32},
	pages = {1--12},
	publisher = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper/2019/file/6c990b7aca7bc7058f5e98ea909e924b-Paper.pdf},
	descrip = {TURBO -- This is an open source numerical software for solving high-dimensional optimization problems via Bayesian optimization using BoTorch. Since Bayesian optimization performs poorly in high dimensions, they have resorted to applying a rudimentary trust region framework on top of their Bayesian optimization algorithm. By squeesing the trust region inward (standard practice in derivative-free optimization) they are able to force the Bayesian optimization algorithm to converge in a reasonable number of true blackbox function evaluations},
}

@inproceedings{farhan2020reinforcement,
	author = {Farhan, Mohammed and G{\"o}hre, Brett},
	title = {Reinforcement Learning in {AnyLogic} Simulation Models: A Guiding Example using {Pathmind}},
	year = {2020},
	month = {12},
	booktitle = {Proc. 2020 Winter Simulation Conference (WSC 2020)},
	pages = {3212--3223},
	organization = {IEEE},
	location = {Orlando, FL, USA},
	doi = {10.1109/WSC48552.2020.9383916},
	url = {https://ieeexplore.ieee.org/document/9383916/},
	descrip = {Publication and whitepaper on Pathmind, an RL-based solver for simulation optimization problems. They also offer multiobjective support but only by using a priori scalarization provided by the user (so not real multiobjective support). This tool is not open source, it is a service provided by a YC startup of the same name. Therefore, it could be considered industry software},
}

@article{feldman2018score,
	author = {Feldman, Guy and Hunter, Susan R.},
	title = {{SCORE} Allocations for Bi-objective Ranking and Selection},
	year = {2018},
	month = {1},
	journal = {ACM Transactions on Modeling Computer and Simulation},
	volume = {28},
	number = {1},
	articleno = {7},
	numpages = {28},
	publisher = {Association for Computing Machinery (ACM)},
	doi = {10.1145/3158666},
	url = {https://dl.acm.org/doi/10.1145/3158666},
	issn = {1049-3301},
	descrip = {A biobjective ranking and selection algorithm from Hunter's NSF Career award},
}

@article{feliot2016bayesian,
	author = {Feliot, Paul and Bect, Julien and Vazquez, Emmanuel},
	title = {A {B}ayesian approach to constrained single- and multi-objective optimization},
	year = {2016},
	month = {1},
	journal = {Journal of Global Optimization},
	volume = {67},
	number = {1-2},
	pages = {97--133},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s10898-016-0427-3},
	url = {http://link.springer.com/10.1007/s10898-016-0427-3},
	issn = {0925-5001},
	descrip = {A Bayesian optimization algorithm for solving constrained optimization problems that are both single and multiobjective -- the authors propose expected hypervolume improvement (EHVI) which merges expected improvement acquisition from Bayesian optimization with the hypervolume indicator for multiobjective optimization},
}

@article{fortin2012deap,
	author = {Fortin, F\'elix-Antoine and {De Rainville}, Fran\c{c}ois-Michel and Gardner, Marc-Andr\'e and Parizeau, Marc and Gagn\'e ", Christian},
	title = {{DEAP}: Evolutionary Algorithms Made Easy},
	year = {2012},
	journal = {Journal of Machine Learning Research},
	volume = {13},
	number = {1},
	pages = {2171--2175},
	url = {https://www.jmlr.org/papers/v13/fortin12a.html},
	descrip = {The DEAP framework is a Python framework for easily implementing and deploying parallel and distributed evolutionary algorithms. Fairly high quality open source software. This is widely used by optimization practitioners, e.g., engineers and scientists that read an evolutionary algorithm paper and want to try it out on their problem},
}

@book{gamma1995design,
	author = {Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John},
	title = {Design patterns: elements of reusable object-oriented software},
	year = {1995},
	publisher = {Addison-Wesley},
	address = {Reading, MA, USA},
	isbn = {0-201-63361-2},
	descrip = {Landmark textbook on standard design patterns, such as builders, factories, observers, etc. Nicknamed the "Gang of Four" book on design patters},
}

@book{garnett2023bayesian,
	author = {Garnett, Roman},
	title = {Bayesian Optimization},
	year = {2023},
	publisher = {Cambridge University Press},
	url = {https://bayesoptbook.com},
	isbn = {978-1108425780},
	descrip = {A community reviewed textbook on Bayesian optimization theory and implementation. Very thorough description of Gaussian process and Bayesian optimization fundamentals and theory, common techniques and acquisition functions, and implementation details, drawbacks, and real-world challenges},
}

@article{garud2017smart,
	author = {Garud, Sushant Suhas and Karimi, Iftekhar A. and Kraft, Markus},
	title = {Smart Sampling Algorithm for Surrogate Model Development},
	year = {2017},
	month = {1},
	journal = {Computers \& Chemical Engineering},
	volume = {96},
	pages = {103--114},
	publisher = {Elsevier BV},
	doi = {10.1016/j.compchemeng.2016.10.006},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0098135416303210},
	issn = {0098-1354},
	descrip = {A survey of static DOE sampling strategies for surrogate modeling, as well as a novel model-based strategy proposed by the authors},
}

@article{geer2021learning,
	author = {Geer, Alan J.},
	title = {Learning earth system models from observations: machine learning or data assimilation?},
	year = {2021},
	month = {4},
	journal = {Philosophical Transactions of the Royal Society A},
	volume = {379},
	number = {2194},
	numpages = {20200089},
	publisher = {The Royal Society Publishing},
	doi = {10.1098/rsta.2020.0089},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0089},
	issn = {1364-503X},
	descrip = {A review of data analysis and machine learning methods for earth system modeling},
}

@article{germann2021codesign,
	author = {Germann, Timothy C.},
	title = {Co-design in the {Exascale Computing Project}},
	year = {2021},
	month = {11},
	journal = {The International Journal of High Performance Computing Applications},
	volume = {35},
	number = {6},
	pages = {503--507},
	publisher = {SAGE Publications Sage UK: London, England},
	doi = {10.1177/10943420211059380},
	url = {https://journals.sagepub.com/doi/10.1177/10943420211059380},
	issn = {1094-3420},
	descrip = {An article on the benefits of co design of algorithms and software and hardware in the context of the DOE's exascale computing project (ECP)},
}

@inproceedings{golovin2017google,
	author = {Golovin, Daniel and Solnik, Benjamin and Moitra, Subhodeep and Kochanski, Greg and Karro, John and Sculley, D.},
	title = {{Google Vizier}: A Service for Black-Box Optimization},
	year = {2017},
	month = {8},
	booktitle = {Proc. 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '17)},
	pages = {1487--1495},
	organization = {ACM},
	location = {Halifax, NS, Canada},
	doi = {10.1145/3097983.3098043},
	url = {https://dl.acm.org/doi/10.1145/3097983.3098043},
	descrip = {Google's OSS Vizier service is a (now open source) blackbox / derivative-free optimization numerical software package and service. As far as I can tell, the package is primarily used for solving system optimization and A/B testing type problems},
}

@article{gorban2017stochastic,
	author = {Gorban, Alexander N and Tyukin, Ivan Yu},
	title = {Stochastic separation theorems},
	year = {2017},
	month = {10},
	journal = {Neural Networks},
	volume = {94},
	pages = {255--259},
	publisher = {Elsevier},
	doi = {10.1016/j.neunet.2017.07.014},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608017301776},
	issn = {0893-6080},
	descrip = {Theorems on the curse of dimensionality when it comes to drawing data points in high-dimensional spaces. The main theorem implies that the convex hull of N points in D dimensions has volume ~0 for D sufficiently large -- this occurs because of a concentration of measure type result},
}

@article{gray2019openmdao,
	author = {Gray, Justin S. and Hwang, John T. and Martins, Joaquim R.R.A. and Moore, Kenneth T. and Naylor, Bret A.},
	title = {{OpenMDAO}: An open-source framework for multidisciplinary design, analysis, and optimization},
	year = {2019},
	month = {4},
	journal = {Structural and Multidisciplinary Optimization},
	volume = {59},
	number = {4},
	pages = {1075--1104},
	publisher = {Springer},
	doi = {10.1007/s00158-019-02211-z},
	url = {http://link.springer.com/10.1007/s00158-019-02211-z},
	issn = {1615-147X},
	descrip = {The OpenMDAO open source numerical software library for modeling and solving multidisciplinary engineering design optimization problems. Combines surrogate modeling, gradient based optimization, parallel computing frameworks, and derivative-free optimization techniques in one package so in order to solve large mixed-variable blackbox optimization problems. Developed by NASA Glenn},
}

@techreport{hadka2015platypus,
	author = {Hadka, David},
	title = {Platypus -- multiobjective optimization in {P}ython},
	year = {2015},
	number = {Version 1.0.4},
	institution = {GitHub},
	url = {https://platypus.readthedocs.io/en/latest},
	descrip = {Platypus: an open source numerical software package for performing multiobjective optimization in Python and comparing results},
}

@article{harris2020array,
	author = {Harris, Charles R. and Millman, K. Jarrod and Walt, St{\'{e}}fan J. van der and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and Kerkwijk, Marten H. van and Brett, Matthew and Haldane, Allan and R{\'{i}}o, Jaime Fern{\'{a}}ndez del and Wiebe, Mark and Peterson, Pearu and G{\'{e}}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	title = {Array programming with {NumPy}},
	year = {2020},
	month = {9},
	journal = {Nature},
	volume = {585},
	number = {7825},
	pages = {357--362},
	publisher = {Springer Science and Business Media {LLC}},
	doi = {10.1038/s41586-020-2649-2},
	url = {https://www.nature.com/articles/s41586-020-2649-2},
	issn = {0028-0836},
	descrip = {The official publication of the open source numerical software numpy: the standard for basic multivariable computations, vector operations, and simple linear algebra in Python},
}

@book{hart2017pyomo,
	author = {Hart, William E. and Laird, Carl D. and Watson, Jean-Paul and Woodruff, David L. and Hackebeil, Gabriel A. and Nicholson, Bethany L. and Siirola, John D.},
	title = {Pyomo -- optimization modeling in {P}ython},
	year = {2017},
	booktitle = {Springer Optimization and Its Applications},
	series = {Springer Optimization and Its Applications},
	edition = {2},
	publisher = {Springer Cham},
	address = {Cham, Switzerland},
	doi = {10.1007/978-3-319-58821-6},
	url = {http://link.springer.com/10.1007/978-3-319-58821-6},
	isbn = {9783319588193},
	issn = {1931-6828},
	descrip = {The official textbook on the Pyomo modeling language: an open source optimization modeling language and scientific software developed at Sandia by Bill Hart et al. Pyomo is a standard for solving large-scale mathematical programming (linear and nonlinear optimization) problems in Python},
}

@article{hase2018chimera,
	author = {H{\"a}se, Florian and Roch, Lo{\"\i}c M and Aspuru-Guzik, Al{\'a}n},
	title = {Chimera: enabling hierarchy based multi-objective optimization for self-driving laboratories},
	year = {2018},
	journal = {Chemical science},
	volume = {9},
	number = {39},
	pages = {7642--7655},
	publisher = {Royal Society of Chemistry},
	doi = {10.1039/C8SC02239A},
	url = {https://xlink.rsc.org/?DOI=C8SC02239A},
	issn = {2041-6520},
	descrip = {Chimera: a scientific software package for steering self-driving labs via multiobjective optimization -- the software is similar to what we did with ParMOO + MDML in the MERF at Argonne. They focus on applications in robot calibration and molecular system design. The multiobjective component helps them to explore the solution space with experimentation},
}

@article{hayes2022practical,
	author = {Hayes, Conor F and R{\u{a}}dulescu, Roxana and Bargiacchi, Eugenio and K{\"a}llstr{\"o}m, Johan and Macfarlane, Matthew and Reymond, Mathieu and Verstraeten, Timothy and Zintgraf, Luisa M and Dazeley, Richard and Heintz, Fredrik and others, },
	title = {A practical guide to multi-objective reinforcement learning and planning},
	year = {2022},
	month = {4},
	journal = {Autonomous Agents and Multi-Agent Systems},
	volume = {36},
	number = {1},
	pages = {1--59},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s10458-022-09552-y},
	url = {https://link.springer.com/10.1007/s10458-022-09552-y},
	issn = {1387-2532},
	descrip = {A survey paper on multiobjective reinforcement learning -- RL is basically optimization with the addition of a dynamically changing state variable, so this is sort of relevant to multiobjecte optimization research},
}

@article{he2009algorithm,
	author = {He, Jian and Watson, Layne T. and Sosonkina, Masha},
	title = {Algorithm 897: {VTDIRECT95}: Serial and Parallel Codes for the Global Optimization Algorithm {DIRECT}},
	year = {2009},
	month = {7},
	journal = {ACM Transactions on Mathematical Software},
	volume = {36},
	number = {3},
	numpages = {17},
	publisher = {Association for Computing Machinery (ACM)},
	doi = {10.1145/1527286.1527291},
	url = {https://dl.acm.org/doi/10.1145/1527286.1527291},
	issn = {0098-3500},
	descrip = {VTDIRECT95 reference: a high-performance parallel Fortran implementation of the famous single-objective blackbox (direct search) optimization algorithm DIRECT. The numerical software is now open source (maintained by me) on Dr. Watson's GitHub page.},
}

@techreport{heroux2020advancing,
	author = {Heroux, Michael A. and McInnes, Lois and Bernholdt, David E. and Dubey, Anshu and Gonsiorowski, Elsa and Marques, Osni and Moulton, J. David and Norris, Boyana and Raybourn, Elaine and Balay, Satish and Bartlett, Roscoe A. and Childers, Lisa and Gamblin, Todd and Grubel, Patricia and Gupta, Rinku and Hartman-Baker, Rebecca and Hill, Judith C. and Hudson, Stephen and Junghans, Christoph and Klinvex, Alicia and Milewicz, Reed and Miller, Mark and Ah Nam, Hai and O'Neal, Jared and Riley, Katherine and Sims, Ben and Schuler, Jean and Smith, Barry F. and Vernon, Louis and Watson, Gregory R. and Willenbring, James and Wolfenbarger, Paul},
	title = {Advancing Scientific Productivity through Better Scientific Software: Developer Productivity and Software Sustainability Report},
	year = {2020},
	month = {1},
	number = {ORNL TM-2020 1459 / ECP-U-RPT-2020-0001},
	institution = {Oak Ridge National Laboratory},
	address = {Oak Ridge, TN, USA},
	doi = {10.2172/1606662},
	url = {https://www.osti.gov/servlets/purl/1606662/},
	descrip = {The better scientific software tech report, with recommendations and rules of thumb for improving the quality of scientific software within the DOE},
}

@article{hickernell1998generalized,
	author = {Hickernell, Fred J.},
	title = {A generalized discrepancy and quadrature error bound},
	year = {1998},
	journal = {Mathematics of computation},
	volume = {67},
	number = {221},
	pages = {299--322},
	publisher = {American Mathematical Society (AMS)},
	doi = {10.1090/S0025-5718-98-00894-1},
	url = {https://www.ams.org/mcom/1998-67-221/S0025-5718-98-00894-1/},
	issn = {0025-5718},
	descrip = {A numerical-quadrature based approximation to discrepancy. For high-dimensional ill-spaced points, the quadrature error can be huge, and although discrepancies should always be between 0 and 1, the approximation can approach (13/12)^d - 1, where d is the dimension of the problem. When points are randomly or quasi-randomly sampled, such large values of the approximation could be indicative of measure collapse. This is the technique used in scipy.stats.qmc.discrepancy(...)},
}

@article{hof2015google,
	author = {Hof, Robert D.},
	title = {Google Tries to Make Machine Learning a Little More Human},
	year = {2015},
	month = {nov},
	journal = {MIT Technology Review},
	url = {https://www.technologyreview.com/2015/11/05/165175/google-tries-to-make-machine-learning-a-little-more-human/},
	note = {Last accessed: June 20, 2022},
	descrip = {An article on Google GlassBox research: Google's research division dedicated to interpretable machine learning},
}

@article{hoffman2022optimizing,
	author = {Hoffman, Samuel C. and Chenthamarakshan, Vijil and Wadhawan, Kahini and Chen, Pin-Yu and Das, Payel},
	title = {Optimizing molecules using efficient queries from property evaluations},
	year = {2022},
	month = {12},
	journal = {Nature Machine Intelligence},
	volume = {4},
	number = {1},
	pages = {21--31},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1038/s42256-021-00422-y},
	url = {https://www.nature.com/articles/s42256-021-00422-y},
	issn = {2522-5839},
	descrip = {Techniques for optimizing molecule properties via a latent-space embedding that comes from a molecule autoencoder, from IBM Research},
}

@article{hudson2022libensemble,
	author = {Hudson, Stephen and Larson, Jeffrey and Navarro, John-Luke and Wild, Stefan M.},
	title = {{libEnsemble}: A Library to Coordinate the Concurrent Evaluation of Dynamic Ensembles of Calculations},
	year = {2022},
	month = {4},
	journal = {{IEEE} Transactions on Parallel and Distributed Systems},
	volume = {33},
	number = {4},
	pages = {977--988},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/tpds.2021.3082815},
	url = {https://ieeexplore.ieee.org/document/9439163/},
	issn = {1045-9219},
	descrip = {The original libEnsemble publication focusing on its techniques for distributing and evaluating ensembles of functions in parallel. Although not discussed, libEnsemble was already open source at the time},
}

@techreport{hudson2023libensemble,
	author = {Hudson, Stephen and Larson, Jeffrey and Navarro, John-Luke and Wild, Stefan M.},
	title = {{libEnsemble: A} complete {Python} toolkit for dynamic ensembles of calculations},
	year = {2023},
	month = {12},
	booktitle = {Journal of Open Source Software},
	volume = {8},
	number = {92},
	numpages = {6031},
	institution = {The Open Journal},
	doi = {10.21105/joss.06031},
	url = {https://joss.theoj.org/papers/10.21105/joss.06031},
	issn = {2475-9066},
	descrip = {The official JOSS paper for libEnsemble: an open source software library for performing parallel and distributed computations involving ensembles of computationally expensive function evaluations in Python},
}

@article{hunter2019introduction,
	author = {Hunter, Susan R. and Applegate, Eric A. and Arora, Viplove and Chong, Bryan},
	title = {An introduction to multiobjective simulation optimization},
	year = {2019},
	month = {1},
	journal = {ACM Transactions on Modeling and Computer Simulation},
	volume = {29},
	number = {1},
	pages = {1--36},
	publisher = {Association for Computing Machinery (ACM)},
	doi = {10.1145/3299872},
	url = {https://dl.acm.org/doi/10.1145/3299872},
	issn = {1049-3301},
	descrip = {A thorough survey on techniques and algorithms for solving multiobjective simulation optimization problems, including algorithms and techniques for handling small finite design spaces, discrete integer design spaces, and continuous design spaces. Covers theory, algorithms, and popular heuristics for all.},
}

@article{jain2013evolutionary,
	author = {Jain, Himanshu and Deb, Kalyanmoy},
	title = {An evolutionary many-objective optimization algorithm using reference-point based nondominated sorting approach, part {II}: Handling constraints and extending to an adaptive approach},
	year = {2013},
	month = {8},
	journal = {IEEE Transactions on Evolutionary Computation},
	volume = {18},
	number = {4},
	pages = {602--622},
	publisher = {IEEE},
	doi = {10.1109/TEVC.2013.2281534},
	url = {http://ieeexplore.ieee.org/document/6595567/},
	issn = {1089-778X},
	descrip = {The orgiinal NSGA-III paper part 2: a multiobjective evolutionary algorithm similar to NSGA-II, solving the drawback of NSGA-II performing poorly with many objectives by having the user provide a collection of well-spaced reference points and optimizing toward those -- this paper focuses on how to handle constraints},
}

@article{joe2003remark,
	author = {Joe, Stephen and Kuo, Frances Y.},
	title = {Remark on Algorithm 659: Implementing Sobol's Quasirandom Sequence Generator},
	year = {2003},
	month = {3},
	journal = {ACM Transactions on Mathematical Software},
	volume = {29},
	number = {1},
	numpages = {9},
	publisher = {Association for Computing Machinery},
	doi = {10.1145/641876.641879},
	url = {https://dl.acm.org/doi/10.1145/641876.641879},
	issn = {0098-3500},
	descrip = {A modification to the original Sobol sequence generator code},
}

@article{joe2008constructing,
	author = {Joe, Stephen and Kuo, Frances Y.},
	title = {Constructing Sobol sequences with better two-dimensional projections},
	year = {2008},
	month = {1},
	journal = {SIAM Journal on Scientific Computing},
	volume = {30},
	number = {5},
	pages = {2635--2654},
	publisher = {SIAM},
	doi = {10.1137/070709359},
	url = {http://epubs.siam.org/doi/10.1137/070709359},
	issn = {1064-8275},
	descrip = {The numerical software algorithm used in scipy algorithm for generating Sobol sequences (low discrepancy sequences)},
}

@article{johnson1990minimax,
	author = {Johnson, M.E. and Moore, L.M. and Ylvisaker, D.},
	title = {Minimax and maximin distance designs},
	year = {1990},
	month = {10},
	journal = {Journal of Statistical Planning and Inference},
	volume = {26},
	number = {2},
	pages = {131--148},
	publisher = {Elsevier BV},
	doi = {10.1016/0378-3758(90)90122-B},
	url = {https://linkinghub.elsevier.com/retrieve/pii/037837589090122B},
	issn = {0378-3758},
	descrip = {Original publication on maximin and minimax designs for design-of-experiments. I.e., minimize the maximum distance from any point in the bounding box to the nearest point in the design, and maximize the minimum distance between any pair of points in the design.},
}

@article{jones1993lipschitzian,
	author = {Jones, Donald R. and Perttunen, Cary D. and Stuckman, Bruce E.},
	title = {Lipschitzian optimization without the Lipschitz constant},
	year = {1993},
	month = {10},
	journal = {Journal of optimization Theory and Applications},
	volume = {79},
	number = {1},
	pages = {157--181},
	publisher = {Springer},
	doi = {10.1007/bf00941892},
	url = {http://link.springer.com/10.1007/BF00941892},
	issn = {0022-3239},
	descrip = {D.R. Jones' original paper on the landmark DIRECT (DIviding RECTangles) algorithm for direct search global blackbox optimization. The idea is that you can perform branch-and-bound style Lipschitzian optimization without knoweldge of the Lipschitz constant by dividing a rectangular design space into rectangular regions (rectangles) and subdividing those rectangles that could be potentially optimal given any Lipschitz constant by choosing those boxes on the lower left convex hull of the objective value at the center vs box diameter scatter plot},
}

@article{kandasamy2020tuning,
	author = {Kandasamy, Kirthevasan and Vysyaraju, Karun Raju and Neiswanger, Willie and Paria, Biswajit and Collins, Christopher R. and Schneider, Jeff and Poczos, Barnabus and Xing, Eric P.},
	title = {Tuning Hyperparameters without Grad Students: Scalable and Robust {Bayesian} Optimisation with {Dragonfly}},
	year = {2020},
	journal = {Journal of Machine Learning Research},
	volume = {21},
	number = {81},
	pages = {1--27},
	url = {http://jmlr.org/papers/v21/18-223.html},
	git = {http://github.com/dragonfly/dragonfly},
	descrip = {Introducing Dragonfly: an open source numerical software package for solving neural architecture search problems via Bayesian optimization and solving an optimal transport problem to evaluate the distance between two networks. Considered a bit of a landmark paper for neural network architecture search problems. The open source Python software is widely used for a variety of applications outside NAS, including molecular discovery},
}

@article{karl2023multiobjective,
	author = {Karl, Florian and Pielok, Tobias and Moosbauer, Julia and Pfisterer, Florian and Coors, Stefan and Binder, Martin and Schneider, Lennart and Thomas, Janek and Richter, Jakob and Lang, Michel and Garrido-MerchÃ¡n, Eduardo C. and Branke, Juergen and Bischl, Bernd},
	title = {Multi-Objective Hyperparameter Optimization in Machine Learning -- An Overview},
	year = {2023},
	month = {12},
	journal = {ACM Transactions on Evolutionary Learning and Optimization},
	volume = {3},
	number = {4},
	pages = {1--50},
	publisher = {Association for Computing Machinery (ACM)},
	doi = {10.1145/3610536},
	url = {https://dl.acm.org/doi/10.1145/3610536},
	issn = {2688-299X},
	descrip = {A survey of multiobjective optimization algorithms for hyperparameter tuning in the context of automatic machine learning (autoML)},
}

@article{karniadakis2021physicsinformed,
	author = {Karniadakis, George Em and Kevrekidis, Ioannis G. and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
	title = {Physics-informed machine learning},
	year = {2021},
	month = {5},
	journal = {Nature Reviews Physics},
	volume = {3},
	number = {6},
	pages = {422--440},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1038/s42254-021-00314-5},
	url = {https://www.nature.com/articles/s42254-021-00314-5},
	issn = {2522-5820},
	descrip = {A review of physics-informed machine learning techniques and models by Karniadakis himself, who is credited with starting the field of SciML},
}

@article{karpatne2017theoryguided,
	author = {Karpatne, Anuj and Atluri, Gowtham and Faghmous, James H. and Steinbach, Michael and Banerjee, Arindam and Ganguly, Auroop and Shekhar, Shashi and Samatova, Nagiza and Kumar, Vipin},
	title = {Theory-Guided Data Science: A New Paradigm for Scientific Discovery from Data},
	year = {2017},
	month = {10},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	volume = {29},
	number = {10},
	pages = {2318--2331},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/TKDE.2017.2720168},
	url = {http://ieeexplore.ieee.org/document/7959606/},
	issn = {1041-4347},
	descrip = {An introductory-level paper to theory-guided data science. I haven't read but I assume it covers the same topics he taught in his class at Virginia Tech},
}

@article{khan2018manifold,
	author = {Khan, Kamil A. and Larson, Jeffrey and Wild, Stefan M.},
	title = {Manifold Sampling for Optimization of Nonconvex Functions that are Piecewise Linear Compositions of Smooth Components},
	year = {2018},
	month = {1},
	journal = {{SIAM} Journal on Optimization},
	volume = {28},
	number = {4},
	pages = {3001--3024},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/17m114741x},
	url = {https://epubs.siam.org/doi/10.1137/17M114741X},
	issn = {1052-6234},
	descrip = {Proposes a new technique called manifold sampling to solve blackbox optimization problems where a smooth blackbox function is composed with a piecewise linear (non blackbox) function. Normally, this would create a nonsmooth blackbox function, but by modeling the blackbox function separately and sampling the different manifolds produced by the changes in active components of the piecewise function, we can still model the blackbox function with smooth techniques and solve the optimization problem efficiently},
}

@inproceedings{kim2004spea2+,
	author = {Kim, Mifa and Hiroyasu, Tomoyuki and Miki, Mitsunori and Watanabe, Shinya},
	title = {{SPEA2+}: Improving the performance of the {S}trength {P}areto {E}volutionary {A}lgorithm 2},
	year = {2004},
	booktitle = {Proc. International Conference on Parallel Problem Solving from Nature (PPSN VIII)},
	pages = {742--751},
	organization = {Springer},
	location = {Birmingham, UK},
	isbn = {978-3-540-30217-9_75},
	descrip = {The SPEA2+ algorithm for solving multiobjective optimization problems with evolutionary algorithms. Apparently this is widely-used numerical software, but I can't find the download},
}

@article{knowles2006parego,
	author = {Knowles, Joshua},
	title = {{ParEGO:} A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems},
	year = {2006},
	month = {2},
	journal = {IEEE Transactions on Evolutionary Computation},
	volume = {8},
	number = {5},
	pages = {1341--66},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/tevc.2005.851274},
	url = {http://ieeexplore.ieee.org/document/1583627/},
	issn = {1089-778X},
	descrip = {The original ParEGO algorithm paper: in each iteration of the algorithm, the authors use NSGA-II to optimize the expected improvement of the Gaussian process surrogates of each objective. Then, results are scalarized using augmented chebyshev and the best results are evaluated for the next iteration},
}

@inproceedings{kolonay2011service,
	author = {Kolonay, Raymond M. and Sobolewski, Michael},
	title = {Service oriented computing environment ({SORCER}) for large scale, distributed, dynamic fidelity aeroelastic analysis},
	year = {2011},
	booktitle = {International Forum on Aeroelasticity and Structural Dynamics (IFASD 2011), Optimization},
	pages = {26--30},
	organization = {Citeseer},
	location = {Paris, France},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.656.7539},
	descrip = {The SORCER software is a service oriented computing environment used by the US Airforce research lab (AFRL) to distribute expensive computations (such as design optimizations) across their large distributed network of computing resources},
}

@book{kuipers1974uniform,
	author = {Kuipers, L. and Niederreiter, H.},
	title = {Uniform distribution of sequences},
	year = {1974},
	series = {Pure and Applied Mathematics},
	pages = {xiv--390},
	publisher = {Wiley-Interscience [John Wiley \& Sons], New York-London-Sydney},
	descrip = {The textbook on discrepancy that Manisha used to learn about low discrepancy sequences and their motivation},
}

@article{lai2003stochastic,
	author = {Lai, Tze Leung},
	title = {Stochastic approximation},
	year = {2003},
	journal = {The annals of Statistics},
	volume = {31},
	number = {2},
	pages = {391--406},
	publisher = {Institute of Mathematical Statistics},
	descrip = {Stochastic approximation algorithm (i.e., stochastic gradient descent) and how to analyze its radius of convergence for a fixed step-size -- you can decay its step size at a square-summable but not summable rate to guarantee convergence in the limit},
}

@article{larson2018asynchronously,
	author = {Larson, Jeffrey and Wild, Stefan M},
	title = {Asynchronously parallel optimization solver for finding multiple minima},
	year = {2018},
	month = {9},
	journal = {Mathematical Programming Computation},
	volume = {10},
	number = {3},
	pages = {303--332},
	publisher = {Springer},
	doi = {10.1007/s12532-017-0131-4},
	url = {http://link.springer.com/10.1007/s12532-017-0131-4},
	issn = {1867-2949},
	descrip = {The APOSMM Python software is a framework for implementing multistart derivative-free optimization algorithms and running them in asynchronously},
}

@article{larson2019derivativefree,
	author = {Larson, Jeffrey and Menickelly, Matt and Wild, Stefan M.},
	title = {Derivative-free optimization methods},
	year = {2019},
	month = {5},
	journal = {Acta Numerica},
	volume = {28},
	pages = {287--404},
	publisher = {Cambridge University Press},
	doi = {10.1017/S0962492919000060},
	url = {https://www.cambridge.org/core/product/identifier/S0962492919000060/type/journal_article},
	issn = {0962-4929},
	descrip = {A thorough survey of techniques and algorithms in derivative-free optimization},
}

@article{larson2024structureaware,
	author = {Larson, Jeffrey and Menickelly, Matt},
	title = {Structure-Aware Methods for Expensive Derivative-Free Nonsmooth Composite Optimization},
	year = {2024},
	month = {3},
	journal = {Mathematical Programming Computation},
	volume = {16},
	number = {1},
	pages = {1--36},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s12532-023-00245-5},
	url = {https://link.springer.com/10.1007/s12532-023-00245-5},
	issn = {1867-2949},
	descrip = {Jeff's GOOMBAH paper on exploiting composite structures in derivative-free optimization, meaning that a blackbox function is composed with an algebraic function and we want to optimize the result, while exploiting the fact that we know the equation of the algebraic function. Similar technique is used in ParMOO to exploit this same structure and others that are specific to the multiobjective case},
}

@article{laumanns2006efficient,,
	author = {Laumanns, Marco and Thiele, Lothar and Zitzler, Eckart},
	title = {An efficient, adaptive parameter variation scheme for metaheuristics based on the epsilon-constraint method},
	year = {2006},
	month = {3},
	journal = {European Journal of Operational Research},
	volume = {169},
	number = {3},
	pages = {932--942},
	publisher = {Elsevier},
	doi = {10.1016/j.ejor.2004.08.029},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221704005715},
	issn = {0377-2217},
	descrip = {An adaptive scheme for selecting epsilon-constraint scalarizations when solving multiobjective optimization problems.},
}

@techreport{lavely2022powering,
	author = {Lavely, Adam},
	title = {Powering Extreme-Scale {HPC} with {C}erebras Wafer-Scale Accelerators},
	year = {2022},
	institution = {Cereberas Systems, Inc.},
	address = {Sunnyvale, CA, USA},
	url = {https://8968533.fs1.hubspotusercontent-na1.net/hubfs/8968533/Powering-Extreme-Scale-HPC-with-Cerebras.pdf},
	descrip = {A whitepaper describing Cereberus's wafer scale neuromorphic computing architectures, as used in the AI incubator at Argonne},
}

@book{lax2002functional,
	author = {Lax, Peter D.},
	title = {Functional analysis},
	year = {2002},
	series = {Pure and Applied Mathematics (New York)},
	pages = {xx--580},
	publisher = {Wiley-Interscience [John Wiley \& Sons], New York},
	isbn = {0-471-55604-1},
	descrip = {Peter Lax's classic textbook on functional analysis and all the core theorems Banach spaces, Hilbert spaces, and approximation theory},
}

@article{le digabel2011algorithm,
	author = {{Le Digabel}, S{\'e}bastien},
	title = {Algorithm 909: {NOMAD}: Nonlinear Optimization with the {MADS} Algorithm},
	year = {2011},
	month = {2},
	journal = {ACM Transactions on Mathematical Software},
	volume = {37},
	number = {4},
	numpages = {44},
	publisher = {Association for Computing Machinery (ACM)},
	doi = {10.1145/1916461.1916468},
	url = {https://dl.acm.org/doi/10.1145/1916461.1916468},
	issn = {0098-3500},
	descrip = {NOMAD v3 is a widely-used open source numerical software package (in C++) for blackbox and derivative-free optimization via the MADS algorithms. Includes the official implementations of algorithms such as Ortho-MADS, PSD-MADS, and BiMADS. Support for parallel computing and surrogate modeling, and fairly extensible. Can be linked as a C++ library, or usage from command line interface. Used by a variety of industries and officially supported by Exxon Mobile. Has recently been replaced by the major refactor/rewrite in NOMAD v4. Still an example of widely-used open source numerical software, but the NOMAD v4 paper gives a look at how open source software practices have changed (improved) in the last 10 years},
}

@misc{lee2015pydoe,
	author = {Lee, Abraham D. et al.},
	title = {py{DOE}: The experimental design package for python},
	year = {2015},
	booktitle = {GitHub repository},
	number = {0.3.8},
	publisher = {GitHub},
	url = {https://github.com/tisimst/pyDOE},
	descrip = {pyDOE a popular software repository for the common design-of-experiments in Python. This has been widely replaced by the new release of scipy which includes scipy.stats.qmc, which includes most of these techniques (used for monte carlo sampling, but still the same techniques)},
}

@article{lewis2002globally,
	author = {Lewis, Robert Michael and Torczon, Virginia},
	title = {A Globally Convergent Augmented {L}agrangian Pattern Search Algorithm for Optimization with General Constraints and Simple Bounds},
	year = {2002},
	month = {1},
	journal = {SIAM Journal on Optimization},
	volume = {12},
	number = {4},
	pages = {1075--1089},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/S1052623498339727},
	url = {http://epubs.siam.org/doi/10.1137/S1052623498339727},
	issn = {1052-6234},
	descrip = {An algorithm that combines direct search / pattern search with an augmented Lagrangian penalty term in order to solve a constrained blackbox optimization problem},
}

@inproceedings{liu2016surrogate,
	author = {Liu, Bo and Sun, Nan and Zhang, Qingfu and Grout, Vic and Gielen, Georges},
	title = {A surrogate model assisted evolutionary algorithm for computationally expensive design optimization problems with discrete variables},
	year = {2016},
	month = {7},
	booktitle = {Proc. 2016 {IEEE} Congress on Evolutionary Computation ({CEC})},
	pages = {1650--1657},
	organization = {{IEEE}},
	location = {Vancouver, BC, Canada},
	doi = {10.1109/cec.2016.7743986},
	url = {http://ieeexplore.ieee.org/document/7743986/},
	descrip = {An early paper proposing the usage of surrogate models within multiobjective evolutionary algorithms in order to improve their performance on computationally expensive blackbox / simulation optimization problems, where the function evaluation budget may be limited},
}

@article{liu2017adaptive,
	author = {Liu, Haitao and Cai, Jianfei and Ong, Yew-Soon},
	title = {An adaptive sampling approach for Kriging metamodeling by maximizing expected prediction error},
	year = {2017},
	month = {11},
	journal = {Computers \& Chemical Engineering, Special Section - ESCAPE-26},
	volume = {106},
	pages = {171--182},
	publisher = {Elsevier BV},
	doi = {10.1016/j.compchemeng.2017.05.025},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S009813541730234X},
	issn = {0098-1354},
	descrip = {Adaptive Kriging model-based sampling basically means using an interpolating Gaussian process's uncertainty information to select where to sample the next point during an adaptive sampling algorithm (for generating design-of-experiments or design space exploration).},
}

@article{liuzzi2016derivativefree,
	author = {Liuzzi, Giampaolo and Lucidi, Stefano and Rinaldi, Francesco},
	title = {A derivative-free approach to constrained multiobjective nonsmooth optimization},
	year = {2016},
	month = {1},
	journal = {SIAM Journal on Optimization},
	volume = {26},
	number = {4},
	pages = {2744--2774},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/15M1037810},
	url = {http://epubs.siam.org/doi/10.1137/15M1037810},
	issn = {1052-6234},
	descrip = {The DFMO algorithm is a multiobjective line search, which the authors recommend combining with MODIR to improve its convergence to the Pareto front after identifying the global Pareto front. The open source numerical software is implemented in Fortran and is currently bundled inside the MODIR software package on the authors' GitHub account},
}

@misc{liuzzi2024dfolib,
	author = {Liuzzi, Giampaolo et al.},
	title = {DFO-lib},
	year = {2024},
	booktitle = {GitHub repository},
	number = {0.3.8},
	publisher = {GitHub},
	url = {https://github.com/DerivativeFreeLibrary},
	descrip = {The official GitHub account for the DFO-lib -- open source numerical software in Fortran for solving blackbox optimization and multiobjective optimization problems. The library used to be obtained via download from Liuzzi's personal website, where it was referred to as the DFO lib. In 2024 it appears to have been migrated to a GitHub account, with each individual piece of software in its own separate repository. Therefore, any reference to the DFO-lib must now be directed to the account as a whole, not an individual repository.},
}

@inproceedings{louw2021using,
	author = {Louw, Thorben and McIntosh-Smith, Simon},
	title = {Using the {Graphcore IPU} for traditional {HPC} applications},
	year = {2021},
	booktitle = {Proc. 3rd Workshop on Accelerated Machine Learning (AccML)},
	pages = {1--9},
	location = {virtual event},
	url = {https://easychair.org/publications/preprint/ztfj},
	descrip = {Publication describing Graphcore's IPU architecture (intelligence processing unit), which is a neuromorphic parallel processor optimized for high-throughput vector operations},
}

@article{lovison2021extension,
	author = {Lovison, Alberto and Miettinen, Kaisa},
	title = {On the Extension of the {DIRECT} Algorithm to Multiple Objectives},
	year = {2021},
	month = {2},
	journal = {Journal of Global Optimization},
	volume = {79},
	number = {2},
	pages = {387--412},
	publisher = {Springer},
	doi = {10.1007/s10898-020-00942-8},
	url = {https://link.springer.com/10.1007/s10898-020-00942-8},
	issn = {0925-5001},
	descrip = {Multiobjective extension of the DIRECT algorithm for derivative-free blackbox optimization. This algorithm may suffer from some scalability issues, but is a good first step},
}

@article{luo2020preexascale,
	author = {Luo, L. and P. Straatsma, T. and Suarez, L. E. Aguilar and Broer, R. and Bykov, D. and F. D'Azevedo, E. and S. Faraji, S. and C. Gottiparthi, K. and De Graaf, C. and A. Harris, J. and A. Havenith, R. W. and Jensen, H. J. Aa. and Joubert, W. and K. Kathir, R. and Larkin, J. and W. Li, Y. and I. Lyakh, D. and B. Messer, O. E. and R. Norman, M. and C. Oefelein, J. and Sankaran, R. and F. Tillack, A. and L. Barnes, A. and Visscher, L. and C. Wells, J. and Wibowo, M.},
	title = {Pre-exascale accelerated application development: The {ORNL Summit} experience},
	year = {2020},
	month = {5},
	journal = {IBM Journal of Research and Development},
	volume = {64},
	number = {3/4},
	pages = {11:1--11:21},
	publisher = {IBM},
	doi = {10.1147/JRD.2020.2965881},
	url = {https://ieeexplore.ieee.org/document/8960361/},
	issn = {0018-8646},
	descrip = {Summary of discussions from Oak Ridge National Laboratory Summit discussing GPU-based architectures and other developments from the exascale computing project},
}

@inproceedings{mannor2014approachability,
	author = {Mannor, Shie and Perchet, Vianney and Stoltz, Gilles},
	title = {Approachability in unknown games: {O}nline learning meets multi-objective optimization},
	year = {2014},
	month = {13--15 June},
	booktitle = {Proc. 27th Conference on Learning Theory (PMLR)},
	series = {Proceedings of Machine Learning Research},
	volume = {35},
	pages = {339--355},
	organization = {PMLR},
	location = {Barcelona, Spain},
	url = {https://proceedings.mlr.press/v35/mannor14.html},
	descrip = {Discussion of online learning in the context of multiobjective optimization},
}

@article{marler2004survey,
	author = {Marler, Timothy R. and Arora, Jasbir S.},
	title = {Survey of multi-objective optimization methods for engineering},
	year = {2004},
	month = {4},
	journal = {Structural and Multidisciplinary Optimization},
	volume = {26},
	number = {6},
	pages = {369--395},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s00158-003-0368-6},
	url = {http://link.springer.com/10.1007/s00158-003-0368-6},
	issn = {1615-147X},
	descrip = {Survey of common multiobjective optimization algorithms and scalarization techniques in the context of engineering design optimization},
}

@article{martins2009pymdo,
	author = {Martins, Joaquim R. R. A. and Marriage, Christopher and Tedford, Nathan},
	title = {{pyMDO}: An Object-Oriented Framework for Multidisciplinary Design Optimization},
	year = {2009},
	month = {8},
	journal = {ACM Transactions on Mathematical Software},
	volume = {36},
	number = {4},
	numpages = {20},
	publisher = {ACM},
	doi = {10.1145/1555386.1555389},
	url = {https://dl.acm.org/doi/10.1145/1555386.1555389},
	issn = {0098-3500},
	descrip = {pyMDO: an open source numerical Python framework for modeling and solving multidisciplinary engineering design optimization problems},
}

@article{mills2021toward,
	author = {Mills, Richard Tran and Adams, Mark F. and Balay, Satish and Brown, Jed and Dener, Alp and Knepley, Matthew and Kruger, Scott E. and Morgan, Hannah and Munson, Todd and Rupp, Karl and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Junchao},
	title = {Toward performance-portable {PETSc} for {GPU}-based exascale systems},
	year = {2021},
	month = {12},
	journal = {Parallel Computing},
	volume = {108},
	numpages = {102831},
	publisher = {Elsevier BV},
	doi = {10.1016/j.parco.2021.102831},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016781912100079X},
	issn = {0167-8191},
	descrip = {Report on challenges and experiences gained in porting PETSc to GPUs for the exascale computing project},
}

@article{misitano2021desdeo,
	author = {Misitano, Giovanni and Saini, Bhupinder S. and Afsar, Bekir and Shavazipour, Babooshka and Miettinen, Kaisa},
	title = {{DESDEO}: The Modular and Open Source Framework for Interactive Multiobjective Optimization},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {148277--148295},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/ACCESS.2021.3123825},
	url = {https://ieeexplore.ieee.org/document/9591595/},
	issn = {2169-3536},
	descrip = {DESDEO an open source Python framework for implementing interactive multiobjective optimization solvers},
}

@article{moriwaki2018mordred,
	author = {Moriwaki, Hirotomo and Tia, Yu-Shi and Kawashita, Norihito and Takagi, Tatsuya},
	title = {Mordred: a molecular descriptor calculator},
	year = {2018},
	month = {12},
	journal = {Journal of Cheminformatics},
	volume = {10},
	number = {1},
	articleno = {4},
	numpages = {14},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1186/s13321-018-0258-y},
	url = {https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0258-y},
	issn = {1758-2946},
	descrip = {MORDRED: A 3D molecular descriptor calculator, which is widely used for embedding molecules into a continuous latent space (parameterized by their descriptors) which can be used to solve chemical property optimization problems. The MORDRED software is available open source in Python.},
}

@article{muller2017socemo,
	author = {M{\"u}ller, Juliane},
	title = {{SOCEMO}: {S}urrogate optimization of computationally expensive multiobjective problems},
	year = {2017},
	month = {11},
	journal = {INFORMS Journal on Computing},
	volume = {29},
	number = {4},
	pages = {581--596},
	publisher = {Institute for Operations Research and the Management Sciences (INFORMS)},
	doi = {10.1287/ijoc.2017.0749},
	url = {https://pubsonline.informs.org/doi/10.1287/ijoc.2017.0749},
	issn = {1091-9856},
	descrip = {SOCEMO: A response surface modeling (RSM) based algorithm for solving multiobjective optimization problems. Uses a Latin hypercube design-of-experiments, RBF surrogate modeling, multiple scalarizations, and solves the scalarized subproblem via evolutionary algorithms to produce a batch of evaluations in each iteration of the algorithm},
}

@techreport{munson2015tao,
	author = {Munson, Todd and Sarich, Jason and Wild, Stefan and Benson, Steven and McInnes, Lois Curfman},
	title = {{TAO} 3.5 Users Manual},
	year = {2015},
	number = {ANL/MCS-TM-322 version 3.5},
	institution = {Argonne National Laboratory},
	address = {Lemont, IL, USA},
	url = {https://www.mcs.anl.gov/petsc/petsc-3.5.4/docs/tao_manual.pdf},
	descrip = {This is the last TAO (toolkit for advanced optimization) reference before this open source numerical simulation optimization software when merged with PETSc, into a single PETSc + TAO release},
}

@book{myers2016response,
	author = {Myers, Raymond H. and Montgomery, Douglas C. and Anderson-Cook, Christine M.},
	title = {Response Surface Methodology: Process and Design Optimization Using Designed Experiments},
	year = {2016},
	edition = {4},
	publisher = {John Wiley \& Sons, Inc.},
	address = {Hoboken, NJ, USA},
	isbn = {9781118916032},
	descrip = {The classical textbook on response surface methodology and modeling practices. Contains useful information on the basic framework and applications of RSM. Also a useful reference for many of the options for specific techniques: Chapter 7 is a good reference for basic techniques in multiobjective RSM and Chapters 8-9 surveys the basic methods in design-of-experiments},
}

@article{neveu2023comparison,
	author = {Neveu, Nicole and Chang, Tyler H. and Franz, Paris and Hudson, Stephen and Larson, Jeffrey},
	title = {Comparison of multiobjective optimization methods for the {LCLS-II} photoinjector},
	year = {2023},
	month = {2},
	journal = {Computer Physics Communication},
	volume = {283},
	articleno = {108566},
	numpages = {10},
	publisher = {Elsevier BV},
	doi = {10.1016/j.cpc.2022.108566},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010465522002855},
	issn = {0010-4655},
	descrip = {An application of VTMOP for the multiobjective optimization (tuning) of the LCLS-II photoinjector (linear accelerator at SLAC). Had to use some hacks to get VTMOP to work, such as penalizing bad regions of the Pareto front, but ultimately performed better than NSGA-II},
}

@article{niederreiter1988lowdiscrepancy,
	author = {Niederreiter, Harald},
	title = {Low-discrepancy and low-dispersion sequences},
	year = {1988},
	month = {9},
	journal = {Journal of Number Theory},
	volume = {30},
	number = {1},
	pages = {51--70},
	publisher = {Elsevier BV},
	doi = {10.1016/0022-314X(88)90025-X},
	url = {https://doi.org/10.1016/0022-314X(88)90025-X},
	issn = {0022-314X},
	descrip = {The original publication where Sobol's sequences are generalized to the class now known as low-discrepancy sequenes},
}

@book{nocedal2006numerical,
	author = {Nocedal, Jorge and Wright, Stephen J.},
	title = {Numerical Optimization},
	year = {2006},
	booktitle = {Springer Series in Operations Research and Financial Engineering},
	series = {Springer Series in Operations Research and Financial Engineering},
	edition = {2},
	publisher = {Springer Verlag},
	address = {New York, NY, USA},
	doi = {10.1007/978-0-387-40065-5},
	url = {http://link.springer.com/10.1007/978-0-387-40065-5},
	isbn = {9780387303031},
	descrip = {The classic textbook by Nocedal on fundamental techniques in nonlinear programming, such as local modeling and trust-region methods},
}

@inproceedings{parsa2019pabo,
	author = {Parsa, Maryam and Ankit, Aayush and Ziabari, Amirkoushyar and Roy, Kaushik},
	title = {{PABO}: Pseudo Agent-Based Multi-Objective {B}ayesian Hyperparameter Optimization for Efficient Neural Accelerator Design},
	year = {2019},
	month = {11},
	booktitle = {Proc. 2019 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
	pages = {1--8},
	organization = {IEEE/ACM},
	location = {Westin Westminster, CO, USA},
	doi = {10.1109/ICCAD45719.2019.8942046},
	url = {https://ieeexplore.ieee.org/document/8942046/},
	descrip = {PABO - a multiobjective Bayesian optimization software package that is specialized for NAS -- basically an inner network is used as a surrogate and an outer network is used to predict which designs to evaluate next -- I have serious reservations about this kind of approach, and it doesn't seem to work that well},
}

@article{parsa2020bayesian,
	author = {Parsa, Maryam and Mitchell, John P. and Schuman, Catherine D. and Patton, Robert M. and Potok, Thomas E. and Roy, Kaushik},
	title = {Bayesian Multi-objective Hyperparameter Optimization for Accurate, Fast, and Efficient Neural Network Accelerator Design},
	year = {2020},
	month = {7},
	journal = {Frontiers in Neuroscience},
	volume = {14},
	numpages = {667},
	publisher = {Frontiers Media SA},
	doi = {10.3389/fnins.2020.00667},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2020.00667/full},
	issn = {1662-453X},
	descrip = {H-PABO multiobjective Bayesian optimization framework, specialized for NAS, and improvement on PABO},
}

@inproceedings{paszke2019pytorch,
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch\'{e}-Buc, F. d\textquotesingle and Fox, E. and Garnett, R.},
	title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
	year = {2019},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {32},
	pages = {1--12},
	organization = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
	descrip = {The official publicatino for pytorch a gold standard in open source software, providing automatic differentiation and numerical linear algebra in Python, targeted at implementing deep learning algorithms. Pytorch is pretty much a standard in not just open source software, but also machine learning software, and also numerical software},
}

@article{pedregosa2011scikitlearn,
	author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others, },
	title = {Scikit-learn: Machine learning in {P}ython},
	year = {2011},
	journal = {Journal of Machine Learning Research},
	volume = {12},
	pages = {2825--2830},
	url = {https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf},
	descrip = {The official publicatino for scikit-learn a gold standard in open source software, providing a clean interface to several standard implementations of numerical approximation, optimization, machine learning, and deep learning algorithms. Scikit-learn is pretty much a standard in not just open source software, but also machine learning software, and also numerical software},
}

@article{pickering2022discovering,
	author = {Pickering, Ethan and Guth, Stephen and Karniadakis, George Em and Sapsis, Themistoklis P},
	title = {Discovering and forecasting extreme events via active learning in neural operators},
	year = {2022},
	month = {12},
	journal = {Nature Computational Science},
	volume = {2},
	number = {12},
	pages = {823--833},
	publisher = {Nature Publishing Group US New York},
	doi = {10.1038/s43588-022-00376-0},
	url = {https://www.nature.com/articles/s43588-022-00376-0},
	issn = {2662-8457},
	descrip = {An active learning method for extreme event modeling. Specifically, the authors provide a novel acquisition function which targets extreme events},
}

@inproceedings{powell1994direct,
	author = {Powell, Michael J. D.},
	title = {A direct search optimization method that models the objective and constraint functions by linear interpolation},
	year = {1994},
	booktitle = {Gomez, S. and Hennart, J. P. (eds) Advances in Optimization and Numerical Analysis, vol 275},
	pages = {51--67},
	organization = {Springer},
	doi = {10.1007/978-94-015-8330-5_4},
	url = {http://link.springer.com/10.1007/978-94-015-8330-5_4},
	isbn = {9789048143580},
	descrip = {The COBYLA paper on Powell's constrainted optimization by linear approximation algorithm. COBYLA basically performs gradient descent on a constrainted blackbox optimization problem by fitting a linear model to the underlying function and following its gradient within a shrinking trust region. COBYLA is typically able to do this taking typically only one or two function evaluation per iteration since typically only one point is exiting the trust-region per iteration. (Occasionally, additional model improvement points must be sampled to maintain the interpolation set geometry). This makes COBYLA barely more expensive then true gradient descent. COBYQA has supplanted COBYLA since then (the Q standing for quadratic), but I personally prefer COBYLA still as a find the locally linear models to be more robust against noisy and nonsmooth data, still efficiently finding local minima even though COBYLA was not design for such problems. The original open source software was in impossibly complex old-style Fortran. A modern Fortran version has been provided in Pima by Zaikun Zhang, and a modern Python implementation is provided in PDFO by Ragonneau and Zhang.},
}

@article{pronzato2017minimax,
	author = {Pronzato, Luc},
	title = {Minimax and maximin space-filling designs: some properties and methods for construction},
	year = {2017},
	journal = {Journal de la Soci{\'e}t{\'e} Fran{\c{c}}aise de Statistique},
	volume = {158},
	number = {1},
	pages = {7--36},
	url = {http://www.numdam.org/item/JSFS_2017__158_1_7_0},
	descrip = {Review of minimax and maximin techniques and computational methods. Minimax is what we want, but it is hard to compute in high dimensions (would require optimizing a Delaunay triangulation, which is exponential complexity to compute). Maximin is easier to compute (and often used in many algorithms because of this). However, minimax gives better dispersion},
}

@inproceedings{raghunath2017global,
	author = {Raghunath, Chaitra and Chang, Tyler H. and Watson, Layne T. and Jrad, Mohamad and Kapania, Rakesh K. and Kolonay, Raymond M.},
	title = {Global deterministic and stochastic optimization in a service oriented architecture},
	year = {2017},
	booktitle = {Proc. 2017 Spring Simulation Conference (SpringSim 2017), the 25th High Performance Computing Symposium (HPC '17)},
	numpages = {7},
	organization = {SCS},
	location = {Virginia Beach, VA, USA},
	doi = {10.22360/springsim.2017.hpc.023},
	url = {http://dl.acm.org/citation.cfm?id=3108103},
	descrip = {Experiences, challenges, and techniques for integrating the blackbox optimization solvers VTDIRECT95 and QNSTOP into the parallel service architecture SORCER},
}

@misc{ragonneau2021pdfo,
	author = {Ragonneau, Tom M. and Zhang, Zaikun},
	title = {{PDFO}: Cross-Platform Interfaces for {P}owellâs Derivative-Free Optimization Solvers},
	year = {2021},
	booktitle = {GitHub repository},
	number = {1.2},
	publisher = {GitHub},
	url = {https://github.com/pdfo/pdfo},
	descrip = {PDFO: An open source modern Python implementation of Powell's derivative-free numerical optimization software suite, which is considered to be the standard (baseline) in derivative-free optimization solvers},
}

@article{regis2016multiobjective,
	author = {Regis, Rommel G.},
	title = {Multi-objective constrained black-box optimization using radial basis function surrogates},
	year = {2016},
	month = {9},
	journal = {Journal of Computational Science},
	volume = {16},
	pages = {140--155},
	publisher = {Elsevier BV},
	doi = {10.1016/j.jocs.2016.05.013},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1877750316300904},
	issn = {1877-7503},
	descrip = {Using RBF surrogates in the context of multiobjective optimization. I believe he ultimately solved the surrogate problems with NSGA-II or some other heuristic},
}

@article{roy2023quasimonte,
	author = {Roy, Pamphile T. and Owen, Art B. and Balandat, Maximilian and Haberland, Matt},
	title = {Quasi-Monte Carlo Methods in Python},
	year = {2023},
	month = {4},
	journal = {Journal of Open Source Software},
	volume = {8},
	number = {84},
	numpages = {5309},
	publisher = {The Open Journal},
	doi = {10.21105/joss.05309},
	url = {https://joss.theoj.org/papers/10.21105/joss.05309},
	issn = {2475-9066},
	descrip = {Official publication of the scipy.stats.qmc module, which is the newly released module for performing quasi-monte carlo sampling and design-of-experiments in scipy. Scipy is an open source numerical software package which is the standard for advanced numerical methods and scientific software packages in Python. Most of scipy are wrappers for much older Fortran or C++ code, that has been highly optimized.},
}

@inproceedings{ryu2009pareto,
	author = {Ryu, Jong-hyun and Kim, Sujin and Wan, Hong},
	title = {Pareto front approximation with adaptive weighted sum method in multiobjective simulation optimization},
	year = {2009},
	month = {12},
	booktitle = {Proc. 2009 Winter Simulation Conference (WSC '09)},
	pages = {623--633},
	organization = {IEEE},
	location = {Austin, TX, USA},
	doi = {10.1109/WSC.2009.5429562},
	url = {http://ieeexplore.ieee.org/document/5429562/},
	descrip = {The original publication of PAWS: An adaptive weighted sum and trust-regions method for solving biobjective (multiobjective) optimization problems. The key here is that the trust-regions help the weighted sum scalarization reach into nonconvex regions of the Pareto front, even though that would not normally be possible},
}

@article{ryu2014derivativefree,
	author = {Ryu, Jong-Hyun and Kim, Sujin},
	title = {A derivative-free trust-region method for biobjective optimization},
	year = {2014},
	month = {1},
	journal = {SIAM Journal on Optimization},
	volume = {24},
	number = {1},
	pages = {334--362},
	publisher = {SIAM},
	doi = {10.1137/120864738},
	url = {http://epubs.siam.org/doi/10.1137/120864738},
	issn = {1052-6234},
	descrip = {The latest version of PAWS: An adaptive weighted sum and trust-regions method for solving biobjective (multiobjective) optimization problems. The key here is that the trust-regions help the weighted sum scalarization reach into nonconvex regions of the Pareto front, even though that would not normally be possible},
}

@article{sapsis2022optimal,
	author = {Sapsis, Themistoklis P. and Blanchard, Antoine},
	title = {Optimal criteria and their asymptotic form for data selection in data-driven reduced-order modelling with {Gaussian} process regression},
	year = {2022},
	month = {8},
	journal = {Philosophical Transactions of the Royal Society A},
	volume = {380},
	number = {2229},
	numpages = {20210197},
	publisher = {The Royal Society},
	doi = {10.1098/rsta.2021.0197},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2021.0197},
	issn = {1364-503X},
	descrip = {Techniques and optimal sampling criteria for performing adaptive sampling to enable downstream Gaussian process regression modeling},
}

@article{saves2024smt,
	author = {Saves, Paul and Lafage, RÃ©mi and Bartoli, Nathalie and Diouane, Youssef and Bussemaker, Jasper and Lefebvre, Thierry and Hwang, John T. and Morlier, Joseph and Martins, Joaquim R.R.A.},
	title = {SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes},
	year = {2024},
	month = {2},
	journal = {Advances in Engineering Software},
	volume = {188},
	numpages = {103571},
	publisher = {Elsevier BV},
	doi = {10.1016/j.advengsoft.2023.103571},
	url = {https://www.sciencedirect.com/science/article/pii/S096599782300162X},
	issn = {0965-9978},
	descrip = {The SMT 2.0 paper, major improvements to the open source numerical software package (in Python) pySMT for solving multidisciplinary engineering design optimization (MDO) problems, while utilizing derivatives and providing numerical stability analysis for each surrogate model class. In SMT 2.0, support is added for hierarchical and mixed variables, and major improvements have been made to the structure, completeness, and features of the SMT library.},
}

@article{schweidtmann2018machine,
	author = {Schweidtmann, Artur M. and Clayton, Adam D. and Holmes, Nicholas and Bradford, Eric and Bourne, Richard A. and Lapkin, Alexei A.},
	title = {Machine learning meets continuous flow chemistry: Automated optimization towards the {Pareto} front of multiple objectives},
	year = {2018},
	month = {11},
	journal = {Chemical Engineering Journal},
	volume = {352},
	pages = {277--282},
	publisher = {Elsevier},
	doi = {10.1016/j.cej.2018.07.031},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1385894718312634},
	issn = {1385-8947},
	descrip = {Multiobjective molecule property optimization by optimizing processes in a continuous flow reactor (CFR) using the multiobjective evolutionary algorithm TS-EMO (thompson sampling evolutionary multiobjective optimization?)},
}

@article{shang2020survey,
	author = {Shang, Ke and Ishibuchi, Hisao and He, Linjun and Pang, Lie Meng},
	title = {A survey on the hypervolume indicator in evolutionary multiobjective optimization},
	year = {2020},
	month = {2},
	journal = {IEEE Transactions on Evolutionary Computation},
	volume = {25},
	number = {1},
	pages = {1--20},
	publisher = {IEEE},
	doi = {10.1109/TEVC.2020.3013290},
	url = {https://ieeexplore.ieee.org/document/9153850/},
	issn = {1089-778X},
	descrip = {A survey of hypervolume indicator usage in multiobjective evolutionary optimization, mainly in terms of algorithms that use hypervolume improvement and also as a performance indicator},
}

@article{shi2023numerical,
	author = {Shi, Hao-Jun Michael and Xuan, Melody Qiming and Oztoprak, Figen and and, Jorge Nocedal},
	title = {On the numerical performance of finite-difference-based methods for derivative-free optimization},
	year = {2023},
	month = {3},
	journal = {Optimization Methods and Software},
	volume = {38},
	number = {2},
	pages = {289--311},
	publisher = {Taylor \& Francis},
	doi = {10.1080/10556788.2022.2121832},
	url = {https://doi.org/10.1080/10556788.2022.2121832},
	issn = {1055-6788},
	descrip = {A recent paper on the numerical performance of finite-difference-based methods for DFO. Personally, I don't think this is a viable approach given the performance of model-based methods. However, one of their experiments corroborates my experience that you can just run COBYLA on noisy and nonsmooth blackbox optimization problems, and even though it was not designed for those problems, it still does extremely well and regularly finds local minima (at least up to the noise level) -- from Nocedal's lab},
}

@article{shields2021bayesian,
	author = {Shields, Benjamin J. and Stevens, Jason and Li, Jun and Parasram, Marvin and Damani, Farhan and Alvarado, Jesus I. M. and Janey, Jacob M. and Adams, Rryan P. and Doyle, Abigail G.},
	title = {Bayesian reaction optimization as a tool for chemical synthesis},
	year = {2021},
	month = {2},
	journal = {Nature},
	volume = {590},
	number = {7844},
	pages = {89--96},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1038/s41586-021-03213-y},
	url = {https://www.nature.com/articles/s41586-021-03213-y},
	issn = {0028-0836},
	git = {http://github.com/b-shields/edbo},
	descrip = {The EDBO software: open source Python software for performing multiobjective bayesian optimization for chemical synthesis and molecular discovery. Links a multiobjective optimization solver with the MORDRED software for getting molecular descriptors and optimizes for the desired properties},
}

@book{sobieszczanskisobieski2015multidisciplinary,
	author = {Sobieszczanski-Sobieski, Jaroslaw and Morris, Alan and Van Tooren, Michel},
	title = {Multidisciplinary Design Optimization Supported by Knowledge Based Engineering},
	year = {2015},
	publisher = {John Wiley \& Sons, Ltd.},
	address = {Chichester, UK},
	isbn = {978-1-118-49212-3},
	descrip = {One of the most popular textbooks in the field of multidisciplinary engineering design optimization. The introduction provides plenty of motivation for solving computational expensive multiobjective simulation / blackbox optimization problems},
}

@article{sobol1967distribution,
	author = {Sobol, I. M.},
	title = {Distribution of points in a cube and approximate evaluation of integrals},
	year = {1967},
	month = {1},
	journal = {\v{Z}urnal Vy\v{c}islitel\cprime no\u{\i} Matematiki i Matemati\v{c}esko\u{\i} Fiziki},
	volume = {7},
	number = {4},
	pages = {784--802},
	publisher = {Elsevier BV},
	doi = {10.1016/0041-5553(67)90144-9},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0041555367901449},
	issn = {0044-4669},
	descrip = {The original publication of the Sobol sequence algorithm for generating well-distributed points for in the context of good nodes for numerical integration. This is now referred to as a low-discrepancy sequence and is also used for design-of-experiments and quasi-random number generation},
}

@article{stall2019make,
	author = {Stall, Shelley and Yarmey, Lynn and Cutcher-Gershenfeld, Joel and Hanson, Brooks and Lehnert, Kerstin and Nosek, Brian and Parsons, Mark and Robinson, Erin and Wyborn, Lesley},
	title = {Make scientific data {FAIR}},
	year = {2019},
	month = {6},
	journal = {Nature},
	volume = {570},
	number = {7759},
	pages = {27--29},
	publisher = {Nature Publishing Group},
	doi = {10.1038/d41586-019-01720-7},
	url = {https://www.nature.com/articles/d41586-019-01720-7},
	issn = {0028-0836},
	descrip = {The FAIR principles of data management: Scientific data should be findable, accessible, interpretable, and reproducible},
}

@article{steuer1983interactive,
	author = {Steuer, Ralph E and Choo, Eng-Ung},
	title = {An interactive weighted Tchebycheff procedure for multiple objective programming},
	year = {1983},
	month = {10},
	journal = {Mathematical programming},
	volume = {26},
	number = {3},
	pages = {326--344},
	publisher = {Springer},
	doi = {10.1007/BF02591870},
	url = {http://link.springer.com/10.1007/BF02591870},
	issn = {0025-5610},
	descrip = {The original publication of the weighted Chebyshev scalarization scheme for multiobjective optimization},
}

@book{sv2005evolutionary,
	editor = {Abraham, Ajith and Jain, Lakhmi and Goldberg, Robert},
	title = {Evolutionary Multiobjective Optimization: Theoretical Advances and Applications},
	year = {2005},
	booktitle = {Advanced Information and Knowledge Processing},
	series = {Advanced Information and Knowledge Processing Series},
	publisher = {Springer Verlag},
	address = {London, UK},
	doi = {10.1007/1-84628-137-7},
	url = {http://link.springer.com/10.1007/1-84628-137-7},
	isbn = {1852337877},
	descrip = {The textbook on evolutionary multiobjective optimization (MOO), including common algorithms, evaluation methodologies, fundamental techniques, and test problems},
}

@article{tavares2022parallel,
	author = {Tavares, S. and Br\'as, C. P. and Cust\'odio, A. L. and Duarte, V. and Medeiros, P.},
	title = {Parallel Strategies for Direct Multisearch},
	year = {2022},
	month = {3},
	journal = {Numerical Algorithms},
	volume = {92},
	number = {3},
	pages = {1757--1788},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s11075-022-01364-1},
	url = {https://link.springer.com/10.1007/s11075-022-01364-1},
	issn = {1017-1398},
	descrip = {BoostDMS is numerical software library providing access to Custodio's direct search and pattern search software, including MultiGLODS and DMS, in Matlab with full parallel computing support},
}

@article{thomann2019trustregion,
	author = {Thomann, Jana and Eichfelder, Gabriele},
	title = {A Trust-Region Algorithm for Heterogeneous Multiobjective Optimization},
	year = {2019},
	month = {1},
	journal = {{SIAM} Journal on Optimization},
	volume = {29},
	number = {2},
	pages = {1017--1047},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/18m1173277},
	url = {https://epubs.siam.org/doi/10.1137/18M1173277},
	issn = {1052-6234},
	descrip = {A trust-region + RBF surrogate-based multiobjective optimization algorithm for solving heterogeneous multiobjective optimization problems (where one or more objectives is a computationally expensive blackbox, and one or more is not). The key is to just use the derivative of all the non blackbox objectives and use the model derivative for the blackbox terms. The algorithm itself follows something like Orbit},
}

@article{tian2017platemo,
	author = {Tian, Ye and Cheng, Ran and Zhang, Xingyi and Jin, Yaochu},
	title = {{PlatEMO}: A {MATLAB} Platform for Evolutionary Multi-Objective Optimization [Educational Forum]},
	year = {2017},
	month = {11},
	journal = {IEEE Computational Intelligence Magazine},
	volume = {12},
	number = {4},
	pages = {73--87},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/MCI.2017.2742868},
	url = {http://ieeexplore.ieee.org/document/8065138/},
	issn = {1556-603X},
	descrip = {An open source MATLAB platform for implementing and running wide-scale comparisons against other multiobjective evolutionary algorithms on standard multiobjective test problems},
}

@article{tuv sar2015visualization,
	author = {Tu{\v s}ar, Tea and Filipi{\v c}, Bogdan},
	title = {Visualization of {P}areto Front Approximations in Evolutionary Multiobjective Optimization: A Critical Review and the Prosection Method},
	year = {2015},
	month = {4},
	journal = {IEEE Transactions on Evolutionary Computation},
	volume = {19},
	number = {2},
	pages = {225--245},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/TEVC.2014.2313407},
	url = {https://ieeexplore.ieee.org/document/6777535/},
	issn = {1089-778X},
	descrip = {A survey of Pareto front visualization techniques in multiobjective optimization},
}

@article{urquhart2020surrogatebased,
	author = {Urquhart, Magnus and Ljungskog, Emil and Sebben, Simone},
	title = {Surrogate-based optimisation using adaptively scaled radial basis functions},
	year = {2020},
	month = {3},
	journal = {Applied Soft Computing},
	volume = {88},
	numpages = {106050},
	publisher = {Elsevier BV},
	doi = {10.1016/j.asoc.2019.106050},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1568494619308324},
	issn = {1568-4946},
	descrip = {A robust RBF surrogate-based model, with adaptive scaling of the basis function radii to maintain numerical stability and a custom LHS sampling technique},
}

@article{viana2016tutorial,
	author = {Viana, Felipe AC},
	title = {A tutorial on Latin hypercube design of experiments},
	year = {2016},
	month = {7},
	journal = {Quality and reliability engineering international},
	volume = {32},
	number = {5},
	pages = {1975--1985},
	publisher = {Wiley Online Library},
	doi = {10.1002/qre.1924},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/qre.1924},
	issn = {0748-8017},
	descrip = {A tutorial on how to compute Latin hypercube samples (LHS) and some basic properties and ongoing research related to design-of-experiments},
}

@article{virtanen2020scipy,
	author = {{Virtanen}, Pauli and {Gommers}, Ralf and {Oliphant}, Travis E. and {Haberland}, Matt and {Reddy}, Tyler and {Cournapeau}, David and {Burovski}, Evgeni and {Peterson}, Pearu and {Weckesser}, Warren and {Bright}, Jonathan and {van der Walt}, St{\'e}fan J. and {Brett}, Matthew and {Wilson}, Joshua and {Jarrod Millman}, K. and {Mayorov}, Nikolay and {Nelson}, Andrew R.~J. and {Jones}, Eric and {Kern}, Robert and {Larson}, Eric and {Carey}, CJ and {Polat}, {\.I}lhan and {Feng}, Yu and {Moore}, Eric W. and {VanderPlas}, Jake and {Laxalde}, Denis and {Perktold}, Josef and {Cimrman}, Robert and {Henriksen}, Ian and {Quintero}, E.~A. and {Harris}, Charles R and {Archibald}, Anne M. and {Ribeiro}, Ant{\^o}nio H. and {Pedregosa}, Fabian and {van Mulbregt}, Paul and {Contributors}, {SciPy 1.0}},
	title = {{SciPy} 1.0: {F}undamental Algorithms for Scientific Computing in {P}ython},
	year = {2020},
	month = {3},
	journal = {Nature Methods},
	volume = {17},
	number = {3},
	pages = {261--272},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1038/s41592-019-0686-2},
	url = {https://www.nature.com/articles/s41592-019-0686-2},
	issn = {1548-7091},
	descrip = {SciPy official publication: Scipy is an open source numerical software package which is the standard for advanced numerical methods and scientific software packages in Python. Most of scipy are wrappers for much older Fortran or C++ code, that has been highly optimized.},
}

@article{wang2022pyomo.doe,
	author = {Wang, Jialu and Dowling, Alexander W.},
	title = {Pyomo.DOE: An open-source package for model-based design of experiments in Python},
	year = {2022},
	month = {12},
	journal = {AIChE Journal},
	volume = {68},
	number = {12},
	articleno = {e17813},
	publisher = {Wiley},
	doi = {10.1002/aic.17813},
	url = {https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.17813},
	issn = {0001-1541},
	descrip = {Open source numerical Python software pyomo.DOE, implementing model-driven design-of-experiments generation in Pyomo},
}

@article{wang2023design,
	author = {Wang, Yueyao and Xu, Li and Hong, Yili and Pan, Rong and Chang, Tyler H. and Lux, Thomas C. H. and Bernard, Jon and Watson, Layne T. and Cameron, Kirk W.},
	title = {Design strategies and approximation methods for high-performance computing variability management},
	year = {2023},
	month = {1},
	journal = {Journal of Quality Technology},
	volume = {55},
	number = {1},
	pages = {88--103},
	publisher = {Taylor \& Francis},
	doi = {10.1080/00224065.2022.2035285},
	url = {https://www.tandfonline.com/doi/full/10.1080/00224065.2022.2035285},
	issn = {0022-4065},
	descrip = {Survey of design-of-experiments techniques and modifications for HPC system analysis, specifically related to linearly constrained and integer lattice design spaces},
}

@incollection{wierzbicki1999reference,
	author = {Wierzbicki, Andrzej P.},
	editor = {Gal, Tomas and Stewart, Theodor J. and Hanne, Thomas},
	title = {Reference Point Approaches},
	year = {1999},
	booktitle = {Multicriteria Decision Making: Advances in MCDM Models, Algorithms, Theory, and Applications},
	series = {International Series in Operations Research &amp; Management Science},
	pages = {237--275},
	publisher = {Springer US},
	address = {Boston, MA},
	doi = {10.1007/978-1-4615-5025-9_9},
	url = {http://link.springer.com/10.1007/978-1-4615-5025-9_9},
	isbn = {9781461372837},
	issn = {0884-8289},
	descrip = {The original publication of the reference point method for scalarizing multiobjective optimization problems (minimize the distance to a reference point)},
}

@article{wild2008orbit,
	author = {Wild, Stefan M. and Regis, Rommel G. and Shoemaker, Christine A.},
	title = {{ORBIT:} {O}ptimization by Radial Basis Function Interpolation in Trust-Regions},
	year = {2008},
	month = {1},
	journal = {SIAM Journal on Scientific Computing},
	volume = {30},
	number = {6},
	pages = {3197--3219},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/070691814},
	url = {http://epubs.siam.org/doi/10.1137/070691814},
	issn = {1064-8275},
	descrip = {ORBIT: the original algorithm for solving optimization problems via sequentially minimizing RBF interpolants with a linear tail inside a sequence of trust-regions. I can't remember if it's open source, but Stefan has a high quality numerical software in MATLAB},
}

@article{wild2011global,
	author = {Wild, Stefan M. and Shoemaker, Christine A.},
	title = {Global Convergence of Radial Basis Function Trust Region Derivative-Free Algorithms},
	year = {2011},
	month = {7},
	journal = {SIAM Journal on Optimization},
	volume = {21},
	number = {3},
	pages = {761--781},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/09074927X},
	url = {http://epubs.siam.org/doi/10.1137/09074927X},
	issn = {1052-6234},
	descrip = {Analysis of the convergence rate of RBF-based surrogates with linear tail (fully linear model) inside a sequence of trust regions. This is the theory used in ORBIT},
}

@incollection{wild2017solving,
	author = {Wild, Stefan M.},
	editor = {Terlaky, Tamas and Anjos, Miguel F. and Ahmed, Shabbir},
	title = {Solving Derivative-Free Nonlinear Least Squares Problems with {POUNDERS}},
	year = {2017},
	month = {4},
	booktitle = {Advances and Trends in Optimization with Engineering Applications},
	pages = {529--540},
	publisher = {SIAM},
	doi = {10.1137/1.9781611974683.ch40},
	url = {http://www.mcs.anl.gov/papers/P5120-0414.pdf},
	isbn = {978-1-611974-67-6},
	descrip = {The POUNDERS composite blackbox / simulation optimization algorithm, which is an open source numerical software package for exploiting the sum-of-squares structure in derivative-free least squares problems. Specifically, POUNDERS models the blackbox function / simulation's outputs using a fully linear model then uses the sum-of-squares structure to get a free Hessian approximation, and achieve second-order convergence for the price of first-order convergence. Although not included, open source numerical software implementations are now available in Python and Matlab through the PyOptUs GitHub group},
}

@article{wong1997sampling,
	author = {Wong, Tien-Tsin and Luk, Wai-Shing and Heng, Pheng-Ann},
	title = {Sampling with {H}ammersley and {H}alton points},
	year = {1997},
	journal = {Journal of graphics tools},
	volume = {2},
	number = {2},
	pages = {9--24},
	publisher = {Taylor \& Francis},
	descrip = {Hammersley's and Halton sequences -- other low-discrepancy sequences that are commonly used in design-of-experiments},
}

@inproceedings{wong2016hypervolumebased,
	author = {Wong, Cheryl Sze Yin and Al-Dujaili, Abdullah and Sundaram, Suresh},
	title = {Hypervolume-Based {DIRECT} for Multi-Objective Optimisation},
	year = {2016},
	month = {7},
	booktitle = {Proc. 2016 Genetic and Evolutionary Computation Conference Companion (GECCO '16)},
	pages = {1201--1208},
	organization = {ACM},
	location = {Denver, CO, USA},
	doi = {10.1145/2908961.2931702},
	url = {https://dl.acm.org/doi/10.1145/2908961.2931702},
	descrip = {A hypervolume-based approach to a multiobjective DIRECT algorithm for multiobjective blackbox / simulation optimization},
}

@article{xin2018interactive,
	author = {Xin, Bin and Chen, Lu and Chen, Jie and Ishibuchi, Hisao and Hirota, Kaoru and Liu, Bo},
	title = {Interactive Multiobjective Optimization: A Review of the State-of-the-Art},
	year = {2018},
	journal = {IEEE Access},
	volume = {6},
	pages = {41256--41279},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/ACCESS.2018.2856832},
	url = {https://ieeexplore.ieee.org/document/8412189/},
	issn = {2169-3536},
	descrip = {A survey of interactive techniques and software in multiobjective optimization including the known challenges limitations},
}

@article{yang2019multiobjective,
	author = {Yang, Kaifeng and Emmerich, Michael and Deutz, Andr{\'{e}} and B\"{a}ck, Thomas},
	title = {Multi-Objective {Bayesian} Global Optimization Using Expected Hypervolume Improvement Gradient},
	year = {2019},
	month = {2},
	journal = {Swarm and Evolutionary Computation},
	volume = {44},
	pages = {945--956},
	publisher = {Elsevier BV},
	doi = {10.1016/j.swevo.2018.10.007},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2210650217307861},
	issn = {2210-6502},
	descrip = {Multiobjective Bayesian optimization with hypervolume improvement-based acquisition},
}

@inproceedings{yang2019multipoint,
	author = {Yang, Kaifeng and Palar, Pramudita Satria and Emmerich, Michael and Shimoyama, Koji and B\"{a}ck, Thomas},
	title = {A multi-point mechanism of expected hypervolume improvement for parallel multi-objective {Bayesian} global optimization},
	year = {2019},
	month = {7},
	booktitle = {Proc. Genetic and Evolutionary Computation Conference (GECCO19)},
	organization = {ACM},
	location = {Prague Czech Republic},
	doi = {10.1145/3321707.3321784},
	url = {https://dl.acm.org/doi/10.1145/3321707.3321784},
	descrip = {Multiobjective Bayesian optimization with hypervolume improvement-based acquisition},
}

@article{yuan2023active,
	author = {Yuan, Xiaoze and Zhou, Yuwei and Peng, Qing and Yang, Yong and Li, Yongwang and Wen, Xiaodong},
	title = {Active learning to overcome exponential-wall problem for effective structure prediction of chemical-disordered materials},
	year = {2023},
	month = {1},
	journal = {Nature Computational Materials},
	volume = {9},
	number = {1},
	numpages = {12},
	publisher = {Nature Publishing Group UK London},
	doi = {10.1038/s41524-023-00967-z},
	url = {https://www.nature.com/articles/s41524-023-00967-z},
	issn = {2057-3960},
	descrip = {Solving DFT model calibrations for chemical design via active learning},
}

@phdthesis{yukish2004algorithms,
	author = {Yukish, Michael},
	title = {Algorithms to identify {P}areto points in multi-dimensional data sets},
	year = {2004},
	school = {The Pennsylvania State University, Dept. of Mechanical Engineering},
	url = {https://etda.libraries.psu.edu/catalog/6336},
	descrip = {PhD thesis on extracting high-dimensional (many objective) Pareto fronts including a thorough survey of such algorithms},
}

@article{zhang2010derivativefree,
	author = {Zhang, Hongchao and Conn, Andrew R. and Scheinberg, Katya},
	title = {A Derivative-Free Algorithm for Least-Squares Minimization},
	year = {2010},
	month = {1},
	journal = {SIAM Journal on Optimization},
	volume = {20},
	number = {6},
	pages = {3555--3576},
	publisher = {Society for Industrial & Applied Mathematics (SIAM)},
	doi = {10.1137/09075531X},
	url = {http://epubs.siam.org/doi/10.1137/09075531X},
	issn = {1052-6234},
	descrip = {An algorithm for solving composite sum-of-squares blackbox / simulation optimization problems by modeling the blackbox function / simulation's outputs using a fully linear model then using the sum-of-squares structure to get a free Hessian approximation},
}

@article{zhang2012local,
	author = {Zhang, Hongchao and Conn, Andrew R.},
	title = {On the Local Convergence of a Derivative-Free Algorithm for Least-Squares Minimization},
	year = {2012},
	month = {3},
	journal = {Computational Optimization and Applications},
	volume = {51},
	number = {2},
	pages = {481--507},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1007/s10589-010-9367-x},
	url = {http://link.springer.com/10.1007/s10589-010-9367-x},
	issn = {0926-6003},
	descrip = {Convergence analysis when solving composite sum-of-squares blackbox / simulation optimization problems by modeling the blackbox function / simulation's outputs using a fully linear model then using the sum-of-squares structure to get a free Hessian approximation. Basically, one can achieve second-order convergence for the price of first-order convergence},
}

@misc{zhang2023prima,
	author = {Zhang, Zaikun},
	title = {{PRIMA: Reference Implementation for Powell's Methods with Modernization and Amelioration}},
	year = {2023},
	howpublished = {github repository},
	doi = {10.5281/zenodo.8052654},
	url = {http://www.libprima.net},
	descrip = {Prima: open source reference implementation of all of Powell's numerical optimization solvers for blackbox / simulation optimization problems in modern Fortran. IMO, these should be considered the state-of-the-art and reference implementations for all blackbox optimization research},
}

@inproceedings{zhao2018multiobjective,
	author = {Zhao, Wei and Kapania, Rakesh K.},
	title = {Multiobjective Optimization of Composite Flying-wings with {SpaRibs} and Multiple Control Surfaces},
	year = {2018},
	month = {6},
	booktitle = {Proc. 2018 Multidisciplinary Analysis and Optimization Conference},
	numpages = {3424},
	organization = {AIAA},
	location = {Atlanta, GA, USA},
	doi = {10.2514/6.2018-3424},
	url = {https://arc.aiaa.org/doi/10.2514/6.2018-3424},
	descrip = {An application for multiobjective optimization in the context of aircraft wing design. We are optimizing one objective that is the lift/drag ratio, and another that describes the controllability. Problem is solved using multiobjective particle swarm},
}

@article{zhu1997algorithm,
	author = {Zhu, Ciyou and Byrd, Richard H. and Lu, Peihuang and Nocedal, Jorge},
	title = {Algorithm 778: {L-BFGS-B}: {F}ortran Subroutines for Large-Scale Bound-Constrained Optimization},
	year = {1997},
	month = {12},
	journal = {ACM Transactions on Mathematical Software},
	volume = {23},
	number = {4},
	pages = {550--560},
	publisher = {ACM},
	doi = {10.1145/279232.279236},
	url = {https://dl.acm.org/doi/10.1145/279232.279236},
	issn = {0098-3500},
	descrip = {The original publication for L-BFGS-B software, which solves bound-constrained optimization problems using a limited-memory BFGS. This is the standard implementation that is used in all L-BFGS-B codes to date, such as scipy, all machine learning codes, and most engineering codes and nonlinear systems solvers. The code is open source high-quality numerical software, written in old-style Fortran},
}

@article{zitzler2001spea2,
	author = {Zitzler, Eckart and Laumanns, Marco and Thiele, Lothar},
	title = {{SPEA2}: Improving the strength {Pareto} evolutionary algorithm},
	year = {2001},
	journal = {TIK-report},
	volume = {103},
	publisher = {Eidgen{\"o}ssische Technische Hochschule Z{\"u}rich (ETH Zurich), Institut f{\"u}r Technische},
	doi = {10.3929/ethz-a-004284029},
	git = {https://github.com/manuparra/spea2},
	descrip = {SPEA2 strength Pareto evolutionary algorithm -- an old evolutionary algorithm that was once a competitor to NSGA-II (and with significant overlap in co-authorship), but is now largely obsolete.},
}

