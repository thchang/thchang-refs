% The Dakota blackbox and derivative-free simulation optimization framework, a numerical software package (in C++) maintained by Sandia that offers support for AI/ML surrogate modeling, multifidelity modeling, uncertainty quantification (UQ), and distributed and parallel computing
@techreport{adams2022dakota,
	author = {Adams, Brian M. and Bohnhoff, William J. and Dalbey, Keith R. and Ebeida, Mohamed S. and Eddy, John P. and Eldred, Michael S. and Hooper, Russell W. and Hough, Patricia D. and Hu, Kenneth T. and Jakeman, John D. and Khalil, Mohammad and Maupin, Kathryn A. and Monschke, Jason A. and Ridgeway, Elliott M. and Rushdi, Ahmad A. and Seidl, D. Thomas and Stephens, J. Adam and Swiler, Laura P. and Tran, Anh and Winokur, Justin G.},
	title = {Dakota, A Multilevel Parallel Object-Oriented Framework for Design Optimization, Parameter Estimation, Uncertainty Quantification, and Sensitivity Analysis: Version 6.16 User's Manual},
	year = {2022},
	number = {SAND2022-6171 version 6.16},
	institution = {Sandia National Laboratory},
	address = {Albuquerque, NM, USA},
	url = {https://dakota.sandia.gov/sites/default/files/docs/6.16.0/Users-6.16.0.pdf},
	keywords = {design of experiments, DoE, model-based sampling},
}

% A Fortran 90 implementation of quasi-Newton stochastic optimization algorithms. This open source numerical software solves both determinisitc and stochastic blackbox optimization problems via a quasi-Newton trust-region method. It is a bit wasteful in terms of the number of function evaluations per iteration as it performs a fully Latin hypercube sampling of the trust region in each iteration, and does not explicitly re-use previous iterates to reduce iteration costs, like some of the more advanced model based methods. Still, it is extremely robust and a good choice in stochastic situations. Also includes a good Fortran implementation of Latin hypercube sampling and efficient sorting algorithms
@article{amos2020algorithm,
	author = {Amos, Brandon D. and Easterling, David R. and Watson, Layne T. and Thacker, William I. and Castle, Brent S. and Trosset, Michael W.},
	title = {Algorithm 1007: {QNSTOP}: {Q}uasi-{N}ewton algorithm for stochastic optimization},
	year = {2020},
	month = {6},
	journal = {ACM Transactions on Mathematical Software},
	volume = {46},
	number = {2},
	numpages = {17},
	publisher = {Association for Computing Machinery (ACM)},
	doi = {10.1145/3374219},
	url = {https://dl.acm.org/doi/10.1145/3374219},
	issn = {0098-3500},
	keywords = {design of experiments, DoE, Latin hypercube sampling, LHS},
}

% The original TOMS open source numerical software code implementing Sobol sequence (low discrepancy sequence) generation in Fortran 90. Apparently there is a bug or limitation to this code, fixed by Joe et al. 2003 in their TOMS Remark on 659, and subsequent publication of a new generator used in Scipy
@article{bratley1988algorithm,
	author = {Bratley, Paul and Fox, Bennett L.},
	title = {Algorithm 659: Implementing Sobol's Quasirandom Sequence Generator},
	year = {1988},
	month = {3},
	journal = {ACM Transactions on Mathematical Software},
	volume = {14},
	number = {1},
	numpages = {13},
	publisher = {Association for Computing Machinery},
	doi = {10.1145/42288.214372},
	url = {https://doi.org/10.1145/42288.214372},
	issn = {0098-3500},
	keywords = {design of experiments, DoE, low-discrepancy sequences, Sobol sequence},
}

% My PhD thesis, including multiobjective optimization techniques, algorithm, performance analysis, and software review; description of VTMOP, running parallel simulations, integrating with libE. Also scientific machine learning via Delaunay interpolation and algorithms and proofs for doing so. Several applications related to HPC performance modeling and autotuning.
@phdthesis{chang2020mathematical,
	author = {Chang, Tyler H.},
	title = {Mathematical Software for Multiobjective Optimization Problems},
	year = {2020},
	school = {Virginia Tech, Dept. of Computer Science},
	url = {https://vtechworks.lib.vt.edu/handle/10919/98915},
	keywords = {design of experiments, DoE},
}

% Publication of my second open source numerical software package: VTMOP a Fortran software for solving blackbox multiobjective optimization problems. Uses surrogate modeling (RSM), with an adaptive weighting scheme, within a trust region framework. The motivating application is a particle accelerator tuning problem at SLAC
@article{chang2022algorithm,
	author = {Chang, Tyler H. and Watson, Layne T. and Larson, Jeffrey and Neveu, Nicole and Thacker, William I. and Deshpande, Shubhangi and Lux, Thomas C. H.},
	title = {{Algorithm 1028}: {VTMOP}: Solver for Blackbox Multiobjective Optimization Problems},
	year = {2022},
	month = {9},
	journal = {{ACM} Transactions on Mathematical Software},
	volume = {48},
	number = {3},
	numpages = {36},
	publisher = {Association for Computing Machinery (ACM)},
	doi = {10.1145/3529258},
	url = {https://dl.acm.org/doi/10.1145/3529258},
	issn = {0098-3500},
	git = {https://github.com/Libensemble/libe-community-examples/tree/main/vtmop},
	keywords = {design of experiments, DoE, adaptive sampling},
}

% The ParMOO JOSS article -- ParMOO is my open source numerical software package and library ParMOO, written in Python, which can be used for implementing custom solvers for multiobjective simulation optimization problems, while supporting mixed variables, non linear constraints, and diverse and custom surrogte models, and composite structures where some components of the problem are blackbox, but the rest are algebraic. In later releases, ParMOO also supports interactive visualization of results via Plotly + Dash, parallel and distributed function evaluations via libEnsemble, and automatic gradient calculations and just-in-time compilation via jax
@article{chang2023parmoo,
	author = {Chang, Tyler H. and Wild, Stefan M.},
	title = {{ParMOO}: A {P}ython library for parallel multiobjective simulation optimization},
	year = {2023},
	month = {2},
	journal = {Journal of Open Source Software},
	volume = {8},
	number = {82},
	numpages = {4468},
	publisher = {The Open Journal},
	doi = {10.21105/joss.04468},
	url = {https://joss.theoj.org/papers/10.21105/joss.04468},
	issn = {2475-9066},
	keywords = {design of experiments, DoE},
}

% The ParMOO docs -- ParMOO is my open source numerical software package and library ParMOO, written in Python, which can be used for implementing custom solvers for multiobjective simulation optimization problems, while supporting mixed variables, non linear constraints, and diverse and custom surrogte models, and composite structures where some components of the problem are blackbox, but the rest are algebraic. In later releases, ParMOO also supports interactive visualization of results via Plotly + Dash, parallel and distributed function evaluations via libEnsemble, and automatic gradient calculations and just-in-time compilation via jax
@techreport{chang2024parmoo,
	author = {Chang, Tyler H. and Wild, Stefan M. and Dickinson, Hyrum},
	title = {{ParMOO}: {P}ython library for parallel multiobjective simulation optimization},
	year = {2024},
	number = {Version 0.4.1},
	institution = {Argonne National Laboratory},
	address = {Lemont, IL, USA},
	url = {https://parmoo.readthedocs.io/en/latest},
	keywords = {design of experiments, DoE},
}

% The ParMOO IJOC article describing the design of the ParMOO software, motivation, and providing examples of how ParMOO can be used to solve common scientific problems more efficiently with low effort -- ParMOO is my open source numerical software package and library ParMOO, written in Python, which can be used for implementing custom solvers for multiobjective simulation optimization problems, while supporting mixed variables, non linear constraints, and diverse and custom surrogte models, and composite structures where some components of the problem are blackbox, but the rest are algebraic. In later releases, ParMOO also supports interactive visualization of results via Plotly + Dash, parallel and distributed function evaluations via libEnsemble, and automatic gradient calculations and just-in-time compilation via jax
@article{chang2025designing,
	author = {Chang, Tyler H. and Wild, Stefan M.},
	title = {Designing a Framework for Solving Multiobjective Simulation Optimization Problems},
	year = {2025},
	month = {3},
	journal = {INFORMS Journal on Computing},
	publisher = {Institute for Operations Research and the Management Sciences (INFORMS)},
	doi = {10.1287/ijoc.2023.0250},
	url = {https://pubsonline.informs.org/doi/10.1287/ijoc.2023.0250},
	issn = {1091-9856},
	keywords = {design of experiments, DoE},
}

% This is the IJOC ParMOO repository DOI -- this is an archive of the software experiments for obtaining our test problems and reproducing our experimental results on those test problems with customized ParMOO solvers.
@misc{chang2025repository,
	author = {Chang, Tyler H. and Wild, Stefan M.},
	title = {Repository for ``Designing a Framework for Solving Multiobjective Simulation Optimization Problems''},
	year = {2025},
	month = {3},
	booktitle = {INFORMS Journal on Computing},
	publisher = {Institute for Operations Research and the Management Sciences (INFORMS)},
	doi = {10.1287/ijoc.2023.0250.cd},
	url = {https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0250},
	issn = {1091-9856},
	git = {https://github.com/INFORMSJoC/2023.0250},
    note = {Last accessed: May 1, 2025},
	keywords = {design of experiments, DoE},
}

% Publication of our work on multiobjective shape optimization of the RF-gun cavity for the Argonne wakefield accelerator using ParMOO with the POISSON/SUPERFISH simulation software
@inproceedings{chen2023integrated,
	author = {Chen, Gongxiaohui and Chang, Tyler H. and Power, John and Jing, Chungunag},
	title = {An Integrated Multi-Physics Optimization Framework for Particle Accelerator Design},
	year = {2023},
	booktitle = {Proc. 2023 Winter Simulation Conference (WSC 2023), Industrial Applications Track},
	numpages = {2},
	location = {Orlando, FL, USA},
	doi = {10.48550/arXiv.2311.09415},
	keywords = {design of experiments, DoE},
}

% pyOED an open source Python numerical software library for performing optimal experimental design, e.g, for sensor placement at Argonne
@article{chowdhary2024pyoed,
	author = {Chowdhary, Abhijit and Ahmed, Shady E. and Attia, Ahmed},
	title = {{PyOED}: An Extensible Suite for Data Assimilation and Model-Constrained Optimal Design of Experiments},
	year = {2024},
	month = {6},
	journal = {ACM Transactions on Mathematical Software},
	volume = {50},
	number = {2},
	articleno = {11},
	numpages = {22},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/3653071},
	url = {https://dl.acm.org/doi/10.1145/3653071},
	issn = {0098-3500},
	keywords = {design of experiments, DoE, model-based sampling},
}

% Applications of low-discrepancy sequences in Monte carlo simulation
@inproceedings{dalal2008low,
	author = {Dalal, Ishaan L. and Stefan, Deian and Harwayne-Gidansky, Jared},
	title = {Low discrepancy sequences for {M}onte {C}arlo simulations on reconfigurable platforms},
	year = {2008},
	month = {7},
	booktitle = {2008 International Conference on Application-Specific Systems, Architectures and Processors},
	volume = {},
	number = {},
	pages = {108--113},
	organization = {IEEE},
	location = {Leuven, Belgium},
	doi = {10.1109/ASAP.2008.4580163},
	url = {http://ieeexplore.ieee.org/document/4580163},
	keywords = {design of experiments, DoE, low-discrepancy sequences},
}

% Manisha's conference paper on SF-SFD -- the theory is far from ready, but the problem of concentration of measure in high-dimensions making robust sampling difficult and the ability to do something better than just random or latin hypercube sampling are clearly demonstrated
@inproceedings{garg2023sfsfd,
	author = {Garg, Manisha and Chang, Tyler H. and Raghavan, Krishnan},
	title = {{SF-SFD}: {S}tochastic optimization of {F}ourier coefficients for space-filling designs},
	year = {2023},
	month = {12},
	booktitle = {Proc. 2023 Winter Simulation Conference (WSC 2023)},
	pages = {3636--3646},
	organization = {IEEE},
	location = {Orlando, FL, USA},
	doi = {10.1109/WSC60868.2023.10408245},
	url = {https://ieeexplore.ieee.org/document/10408245/},
	keywords = {design of experiments, DoE, Latin hypercube sampling, LHS, measure theory},
}

% Theorems on the curse of dimensionality when it comes to drawing data points in high-dimensional spaces. The main theorem implies that the convex hull of N points in D dimensions has volume ~0 for D sufficiently large -- this occurs because of a concentration of measure type result
@article{gorban2017stochastic,
	author = {Gorban, Alexander N and Tyukin, Ivan Yu},
	title = {Stochastic separation theorems},
	year = {2017},
	month = {10},
	journal = {Neural Networks},
	volume = {94},
	pages = {255--259},
	publisher = {Elsevier},
	doi = {10.1016/j.neunet.2017.07.014},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608017301776},
	issn = {0893-6080},
	keywords = {design of experiments, DoE, measure theory},
}

% A numerical-quadrature based approximation to discrepancy. For high-dimensional ill-spaced points, the quadrature error can be huge, and although discrepancies should always be between 0 and 1, the approximation can approach (13/12)^d - 1, where d is the dimension of the problem. When points are randomly or quasi-randomly sampled, such large values of the approximation could be indicative of measure collapse. This is the technique used in scipy.stats.qmc.discrepancy(...)
@article{hickernell1998generalized,
	author = {Hickernell, Fred J.},
	title = {A generalized discrepancy and quadrature error bound},
	year = {1998},
	journal = {Mathematics of computation},
	volume = {67},
	number = {221},
	pages = {299--322},
	publisher = {American Mathematical Society (AMS)},
	doi = {10.1090/S0025-5718-98-00894-1},
	url = {https://www.ams.org/mcom/1998-67-221/S0025-5718-98-00894-1},
	issn = {0025-5718},
	keywords = {design of experiments, DoE, low-discrepancy sequences},
}

% A modification to the original Sobol sequence generator code
@article{joe2003remark,
	author = {Joe, Stephen and Kuo, Frances Y.},
	title = {Remark on Algorithm 659: Implementing Sobol's Quasirandom Sequence Generator},
	year = {2003},
	month = {3},
	journal = {ACM Transactions on Mathematical Software},
	volume = {29},
	number = {1},
	numpages = {9},
	publisher = {Association for Computing Machinery},
	doi = {10.1145/641876.641879},
	url = {https://dl.acm.org/doi/10.1145/641876.641879},
	issn = {0098-3500},
	keywords = {design of experiments, DoE, low-discrepancy sequences, Sobol sequence},
}

% The numerical software algorithm used in scipy algorithm for generating Sobol sequences (low discrepancy sequences)
@article{joe2008constructing,
	author = {Joe, Stephen and Kuo, Frances Y.},
	title = {Constructing Sobol sequences with better two-dimensional projections},
	year = {2008},
	month = {1},
	journal = {SIAM Journal on Scientific Computing},
	volume = {30},
	number = {5},
	pages = {2635--2654},
	publisher = {SIAM},
	doi = {10.1137/070709359},
	url = {http://epubs.siam.org/doi/10.1137/070709359},
	issn = {1064-8275},
	keywords = {design of experiments, DoE, low-discrepancy sequences, Sobol sequence},
}

% Original publication on maximin and minimax designs for design-of-experiments. I.e., minimize the maximum distance from any point in the bounding box to the nearest point in the design, and maximize the minimum distance between any pair of points in the design.
@article{johnson1990minimax,
	author = {Johnson, M.E. and Moore, L.M. and Ylvisaker, D.},
	title = {Minimax and maximin distance designs},
	year = {1990},
	month = {10},
	journal = {Journal of Statistical Planning and Inference},
	volume = {26},
	number = {2},
	pages = {131--148},
	publisher = {Elsevier BV},
	doi = {10.1016/0378-3758(90)90122-B},
	url = {https://linkinghub.elsevier.com/retrieve/pii/037837589090122B},
	issn = {0378-3758},
	keywords = {design of experiments, DoE},
}

% The textbook on discrepancy that Manisha used to learn about low discrepancy sequences and their motivation
@book{kuipers1974uniform,
	author = {Kuipers, L. and Niederreiter, H.},
	title = {Uniform distribution of sequences},
	year = {1974},
	series = {Pure and Applied Mathematics},
	pages = {xiv--390},
	publisher = {Wiley-Interscience [John Wiley \& Sons], New York-London-Sydney},
	keywords = {design of experiments, DoE, low-discrepancy sequences},
}

% Peter Lax's classic textbook on functional analysis and all the core theorems Banach spaces, Hilbert spaces, and approximation theory
@book{lax2002functional,
	author = {Lax, Peter D.},
	title = {Functional analysis},
	year = {2002},
	series = {Pure and Applied Mathematics (New York)},
	pages = {xx--580},
	publisher = {Wiley-Interscience [John Wiley \& Sons], New York},
	isbn = {0-471-55604-1},
    url = {https://books.google.com/books?hl=en&lr=&id=18VqDwAAQBAJ&oi=fnd&pg=PR17&ots=8FU4i_jAff&sig=Lh4GrUCrS_gt-HKqHSq4X7BaxMs#v=onepage&q&f=false},
	keywords = {design of experiments, DoE, measure theory},
}

% pyDOE a popular software repository for the common design-of-experiments in Python. This has been widely replaced by the new release of scipy which includes scipy.stats.qmc, which includes most of these techniques (used for monte carlo sampling, but still the same techniques)
@misc{lee2015pydoe,
	author = {Lee, Abraham D. and others, },
	title = {py{DOE}: The experimental design package for python},
	year = {2015},
	booktitle = {GitHub repository},
	number = {0.3.8},
	publisher = {GitHub},
	url = {https://github.com/tisimst/pyDOE},
	note = {Last accessed: Nov 2022},
	keywords = {design of experiments, DoE},
}

% Adaptive Kriging model-based sampling basically means using an interpolating Gaussian process's uncertainty information to select where to sample the next point during an adaptive sampling algorithm (for generating design-of-experiments or design space exploration).
@article{liu2017adaptive,
	author = {Liu, Haitao and Cai, Jianfei and Ong, Yew-Soon},
	title = {An adaptive sampling approach for Kriging metamodeling by maximizing expected prediction error},
	year = {2017},
	month = {11},
	journal = {Computers \& Chemical Engineering, Special Section - ESCAPE-26},
	volume = {106},
	pages = {171--182},
	publisher = {Elsevier BV},
	doi = {10.1016/j.compchemeng.2017.05.025},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S009813541730234X},
	issn = {0098-1354},
	keywords = {design of experiments, DoE, adaptive sampling, model-based sampling},
}

% Thomas' thorough survey paper on useful meshes and their properties for multivariate interpolation
@inproceedings{lux2018novel,
	author = {Lux, Thomas C. H. and Watson, Layne T. and Chang, Tyler H. and Bernard, Jon and Li, Bo and Yu, Xiadong and Xu, Li and Back, Godmar and Butt, Ali R. and Cameron, Kirk W. and Yao, Danfeng and Hong, Yili},
	title = {Novel meshes for multivariate interpolation and approximation},
	year = {2018},
	month = {3},
	booktitle = {Proc. 2018 ACM Southeast Conference (ACMSE '18)},
	articleno = {13},
	numpages = {7},
	organization = {Association of Computing Machinery},
	location = {Richmond, KY, USA},
	doi = {10.1145/3190645.3190687},
	url = {https://dl.acm.org/doi/10.1145/3190645.3190687},
	keywords = {design of experiments, DoE},
}

% SOCEMO: A response surface modeling (RSM) based algorithm for solving multiobjective optimization problems. Uses a Latin hypercube design-of-experiments, RBF surrogate modeling, multiple scalarizations, and solves the scalarized subproblem via evolutionary algorithms to produce a batch of evaluations in each iteration of the algorithm
@article{muller2017socemo,
	author = {M{\"u}ller, Juliane},
	title = {{SOCEMO}: {S}urrogate optimization of computationally expensive multiobjective problems},
	year = {2017},
	month = {11},
	journal = {INFORMS Journal on Computing},
	volume = {29},
	number = {4},
	pages = {581--596},
	publisher = {Institute for Operations Research and the Management Sciences (INFORMS)},
	doi = {10.1287/ijoc.2017.0749},
	url = {https://pubsonline.informs.org/doi/10.1287/ijoc.2017.0749},
	issn = {1091-9856},
	keywords = {design of experiments, DoE, Latin hypercube sampling, LHS},
}

% The classical textbook on response surface methodology and modeling practices. Contains useful information on the basic framework and applications of RSM. Also a useful reference for many of the options for specific techniques: Chapter 7 is a good reference for basic techniques in multiobjective RSM and Chapters 8-9 surveys the basic methods in design-of-experiments
@book{myers2016response,
	author = {Myers, Raymond H. and Montgomery, Douglas C. and Anderson-Cook, Christine M.},
	title = {Response Surface Methodology: Process and Design Optimization Using Designed Experiments},
	year = {2016},
	edition = {4},
	publisher = {John Wiley \& Sons, Inc.},
	address = {Hoboken, NJ, USA},
	isbn = {9781118916032},
    url = {https://books.google.com/books?hl=en&lr=&id=T-BbCwAAQBAJ&oi=fnd&pg=PR13&dq=Response+Surface+Methodology:+Process+and+Product+Optimization+Using+Designed+Experiments,+4th+Edition&ots=O3jdPna83T&sig=IimJlE46JBVkHOu7eik3RN9Z5GA#v=onepage&q=Response%20Surface%20Methodology%3A%20Process%20and%20Product%20Optimization%20Using%20Designed%20Experiments%2C%204th%20Edition&f=false},
	keywords = {design of experiments, DoE, model-based sampling},
}

% The original publication where Sobol's sequences are generalized to the class now known as low-discrepancy sequenes
@article{niederreiter1988lowdiscrepancy,
	author = {Niederreiter, Harald},
	title = {Low-discrepancy and low-dispersion sequences},
	year = {1988},
	month = {9},
	journal = {Journal of Number Theory},
	volume = {30},
	number = {1},
	pages = {51--70},
	publisher = {Elsevier BV},
	doi = {10.1016/0022-314X(88)90025-X},
	url = {https://doi.org/10.1016/0022-314X(88)90025-X},
	issn = {0022-314X},
	keywords = {design of experiments, DoE, low-discrepancy sequences, Sobol sequence},
}

% An active learning method for extreme event modeling. Specifically, the authors provide a novel acquisition function which targets extreme events
@article{pickering2022discovering,
	author = {Pickering, Ethan and Guth, Stephen and Karniadakis, George Em and Sapsis, Themistoklis P},
	title = {Discovering and forecasting extreme events via active learning in neural operators},
	year = {2022},
	month = {12},
	journal = {Nature Computational Science},
	volume = {2},
	number = {12},
	pages = {823--833},
	publisher = {Nature Publishing Group US New York},
	doi = {10.1038/s43588-022-00376-0},
	url = {https://www.nature.com/articles/s43588-022-00376-0},
	issn = {2662-8457},
	keywords = {design of experiments, DoE, model-based sampling},
}

% Review of minimax and maximin techniques and computational methods. Minimax is what we want, but it is hard to compute in high dimensions (would require optimizing a Delaunay triangulation, which is exponential complexity to compute). Maximin is easier to compute (and often used in many algorithms because of this). However, minimax gives better dispersion
@article{pronzato2017minimax,
	author = {Pronzato, Luc},
	title = {Minimax and maximin space-filling designs: some properties and methods for construction},
	year = {2017},
	journal = {Journal de la Soci{\'e}t{\'e} Fran{\c{c}}aise de Statistique},
	volume = {158},
	number = {1},
	pages = {7--36},
	url = {http://www.numdam.org/item/JSFS_2017__158_1_7_0},
	keywords = {design of experiments, DoE},
}

% Official publication of the scipy.stats.qmc module, which is the newly released module for performing quasi-monte carlo sampling and design-of-experiments in scipy. Scipy is an open source numerical software package which is the standard for advanced numerical methods and scientific software packages in Python. Most of scipy are wrappers for much older Fortran or C++ code, that has been highly optimized.
@article{roy2023quasimonte,
	author = {Roy, Pamphile T. and Owen, Art B. and Balandat, Maximilian and Haberland, Matt},
	title = {Quasi-Monte Carlo Methods in Python},
	year = {2023},
	month = {4},
	journal = {Journal of Open Source Software},
	volume = {8},
	number = {84},
	numpages = {5309},
	publisher = {The Open Journal},
	doi = {10.21105/joss.05309},
	url = {https://joss.theoj.org/papers/10.21105/joss.05309},
	issn = {2475-9066},
	keywords = {design of experiments, DoE},
}

% Techniques and optimal sampling criteria for performing adaptive sampling to enable downstream Gaussian process regression modeling
@article{sapsis2022optimal,
	author = {Sapsis, Themistoklis P. and Blanchard, Antoine},
	title = {Optimal criteria and their asymptotic form for data selection in data-driven reduced-order modelling with {Gaussian} process regression},
	year = {2022},
	month = {8},
	journal = {Philosophical Transactions of the Royal Society A},
	volume = {380},
	number = {2229},
	numpages = {20210197},
	publisher = {The Royal Society},
	doi = {10.1098/rsta.2021.0197},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2021.0197},
	issn = {1364-503X},
	keywords = {design of experiments, DoE, adaptive sampling, model-based sampling},
}

% The SMT 2.0 paper, major improvements to the open source numerical software package (in Python) pySMT for solving multidisciplinary engineering design optimization (MDO) problems, while utilizing derivatives and providing numerical stability analysis for each surrogate model class. In SMT 2.0, support is added for hierarchical and mixed variables, and major improvements have been made to the structure, completeness, and features of the SMT library.
@article{saves2024smt,
	author = {Saves, Paul and Lafage, RÃ©mi and Bartoli, Nathalie and Diouane, Youssef and Bussemaker, Jasper and Lefebvre, Thierry and Hwang, John T. and Morlier, Joseph and Martins, Joaquim R.R.A.},
	title = {SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes},
	year = {2024},
	month = {2},
	journal = {Advances in Engineering Software},
	volume = {188},
	numpages = {103571},
	publisher = {Elsevier BV},
	doi = {10.1016/j.advengsoft.2023.103571},
	url = {https://www.sciencedirect.com/science/article/pii/S096599782300162X},
	issn = {0965-9978},
	keywords = {design of experiments, DoE, model-based sampling},
}

% One of the most popular textbooks in the field of multidisciplinary engineering design optimization. The introduction provides plenty of motivation for solving computational expensive multiobjective simulation / blackbox optimization problems
@book{sobieszczanskisobieski2015multidisciplinary,
	author = {Sobieszczanski-Sobieski, Jaroslaw and Morris, Alan and Van Tooren, Michel},
	title = {Multidisciplinary Design Optimization Supported by Knowledge Based Engineering},
	year = {2015},
	publisher = {John Wiley \& Sons, Ltd.},
	address = {Chichester, UK},
	isbn = {978-1-118-49212-3},
	keywords = {design of experiments, DoE},
}

% The original publication of the Sobol sequence algorithm for generating well-distributed points for in the context of good nodes for numerical integration. This is now referred to as a low-discrepancy sequence and is also used for design-of-experiments and quasi-random number generation
@article{sobol1967distribution,
	author = {Sobol, I. M.},
	title = {Distribution of points in a cube and approximate evaluation of integrals},
	year = {1967},
	month = {1},
	journal = {\v{Z}urnal Vy\v{c}islitel\cprime no\u{\i} Matematiki i Matemati\v{c}esko\u{\i} Fiziki},
	volume = {7},
	number = {4},
	pages = {784--802},
	publisher = {Elsevier BV},
	doi = {10.1016/0041-5553(67)90144-9},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0041555367901449},
	issn = {0044-4669},
	keywords = {design of experiments, DoE, low-discrepancy sequences, Sobol sequence},
}

% The textbook from which I learned measure theory: covering measure theory and topology bases, common measure and metric spaces, Banach and Hilbert spaces, compactness, strong and weak topologies for a linear operator, L^p spaces, Fourier transforms, the Hausdorff dimension, and most basic theorems (Hahn-Banach, Caratheodory, Baire Category theorem, etc.)
@book{tao2011epsilon,
	author = {Tao, Terence},
	title = {An Epsilon of Room: Pages from year three of a mathematical blog},
	year = {2011},
	month = {3},
	volume = {2},
	publisher = {American Mathematical Society},
	doi = {10.1090/mbk/077},
	url = {http://www.ams.org/mbk/077},
	isbn = {9780821852804},
	keywords = {design of experiments, DoE, measure theory},
}

% A tutorial on how to compute Latin hypercube samples (LHS) and some basic properties and ongoing research related to design-of-experiments
@article{viana2016tutorial,
	author = {Viana, Felipe AC},
	title = {A tutorial on Latin hypercube design of experiments},
	year = {2016},
	month = {7},
	journal = {Quality and reliability engineering international},
	volume = {32},
	number = {5},
	pages = {1975--1985},
	publisher = {Wiley Online Library},
	doi = {10.1002/qre.1924},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/qre.1924},
	issn = {0748-8017},
	keywords = {design of experiments, DoE, Latin hypercube sampling, LHS},
}

% SciPy official publication: Scipy is an open source numerical software package which is the standard for advanced numerical methods and scientific software packages in Python. Most of scipy are wrappers for much older Fortran or C++ code, that has been highly optimized.
@article{virtanen2020scipy,
	author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, St{\'e}fan J. and Brett, Matthew and Wilson, Joshua and Jarrod Millman, K. and Mayorov, Nikolay and Nelson, Andrew R.~J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, CJ and Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E.~A. and Harris, Charles R and Archibald, Anne M. and Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and van Mulbregt, Paul and Contributors, SciPy 1.0},
	title = {{SciPy} 1.0: {F}undamental Algorithms for Scientific Computing in {P}ython},
	year = {2020},
	month = {3},
	journal = {Nature Methods},
	volume = {17},
	number = {3},
	pages = {261--272},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1038/s41592-019-0686-2},
	url = {https://www.nature.com/articles/s41592-019-0686-2},
	issn = {1548-7091},
	keywords = {design of experiments, DoE},
}

% Open source numerical Python software pyomo.DOE, implementing model-driven design-of-experiments generation in Pyomo
@article{wang2022pyomodoe,
	author = {Wang, Jialu and Dowling, Alexander W.},
	title = {Pyomo.DOE: An open-source package for model-based design of experiments in Python},
	year = {2022},
	month = {12},
	journal = {AIChE Journal},
	volume = {68},
	number = {12},
	articleno = {e17813},
	publisher = {Wiley},
	doi = {10.1002/aic.17813},
	url = {https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.17813},
	issn = {0001-1541},
	keywords = {design of experiments, DoE, model-based sampling},
}

% Survey of design-of-experiments techniques and modifications for HPC system analysis, specifically related to linearly constrained and integer lattice design spaces
@article{wang2023design,
	author = {Wang, Yueyao and Xu, Li and Hong, Yili and Pan, Rong and Chang, Tyler H. and Lux, Thomas C. H. and Bernard, Jon and Watson, Layne T. and Cameron, Kirk W.},
	title = {Design strategies and approximation methods for high-performance computing variability management},
	year = {2023},
	month = {1},
	journal = {Journal of Quality Technology},
	volume = {55},
	number = {1},
	pages = {88--103},
	publisher = {Taylor \& Francis},
	doi = {10.1080/00224065.2022.2035285},
	url = {https://www.tandfonline.com/doi/full/10.1080/00224065.2022.2035285},
	issn = {0022-4065},
	keywords = {design of experiments, DoE, Latin hypercube sampling, LHS},
}

% Hammersley's and Halton sequences -- other low-discrepancy sequences that are commonly used in design-of-experiments
@article{wong1997sampling,
	author = {Wong, Tien-Tsin and Luk, Wai-Shing and Heng, Pheng-Ann},
	title = {Sampling with {H}ammersley and {H}alton points},
	year = {1997},
	month = {1},
	journal = {Journal of graphics tools},
	volume = {2},
	number = {2},
	pages = {9--24},
	publisher = {Taylor \& Francis},
	doi = {10.1080/10867651.1997.10487471},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10867651.1997.10487471},
	issn = {1086-7651},
	keywords = {design of experiments, DoE, low-discrepancy sequences},
}

