% A review article on representation learning and unifying the ideas of representation learning, density estimation, and manifold learning under a single geometric umbrella. The authors show broadly how representation learning has been the key to the performance of neural networks across many fields, often allowing us to break the curse of dimensionality. Additionally, they discuss the general requirements (priors) about a problem / function for representation learning to be an effective approach.
@article{bengio2013representation,
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	title = {Representation Learning: A Review and New Perspectives},
	year = {2013},
	month = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume = {35},
	number = {8},
	pages = {1798--1828},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/TPAMI.2013.50},
	url = {http://ieeexplore.ieee.org/document/6472238/},
	issn = {0162-8828},
	keywords = {AI, artificial intelligence, machine learning, ML, representation learning, neural networks},
}

% The famous textbook on convex optimization (from which I learned most concepts) covering concepts such as basic convexity definitions and theorems, basic algorithms and optimality conditions, handling constraints, Lagrangian duality, multiobjective optimization basics, gradient descent and newton's method, sequential quadratic programming, linear programming, and a few applications and modeling basics
@book{boyd2004convex,
	author = {Boyd, Stephen P and Vandenberghe, Lieven},
	title = {Convex optimization},
	year = {2004},
	publisher = {Cambridge university press},
	keywords = {AI, artificial intelligence, machine learning, ML, optimization},
}

% The recommended citation for the jax software project -- one of my personal favorite open source numerical software in Python. Performs autograd (or algorithmic differentiation) in either forward or reverse mode, is strongly typed, can act as a drop-in replacement for numpy, and can be just-in-time (jit) compiled for massive speedups
@misc{bradbury2018jax,
	author = {Bradbury, J. and others, },
	title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
	year = {2018},
	number = {0.3.13},
	url = {http://github.com/google/jax},
	note = {Last accessed: Jul 2024},
	keywords = {AI, artificial intelligence, machine learning, ML, autograd, algorithmic differentiation, backpropagation, open source},
}

% The largest repository of open source AI, machine learning, and control benchmark problems, maintained by OpenAI. This was the primary benchmark problem environment for all reinforcement learning researchers not affiliated with another company with their own private environments (such as Meta and Google). Still available at github.com/openai/gym
@techreport{brockman2016openai,
	author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	title = {OpenAI Gym},
	year = {2016},
	institution = {arXiv:1606.01540},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, benchmarking, open source},
}

% The new classic textbook on geometric deep learning -- this book (by the creator of the field) covers how all of representation learning can be broken down into exploiting symmetries, stabilities, and invariances in data, through the lens of group theory. For example, a convolutional layer exploits a symmetry between equivalent groups of images; and a max pooling layer exploits a scale invariance in image size/resolution; and when we talk about feature encodings, we are often looking for mappings that maintain stability (i.e., similar feature vectors remain close together after encoding).
@book{bronstein2021geometric,
	author = {Bronstein, Michael M. and Bruna, Joan and Cohen, Taco and Veličković, Petar},
	title = {Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges},
	year = {2021},
	publisher = {arXiv cs.LG},
	doi = {10.48550/arXiv.2104.13478},
	keywords = {AI, artificial intelligence, machine learning, ML, representation learning, neural networks},
}

% The publication for the XGBoost numerical software. XGBoost can be used to efficiently compute optimized gradient boosted decision trees on massive datasets via a fully-distributed algorithm that can be configured to run on Hadoop, SGE, and MPI. It can also be run on NVIDIA GPUs using CUDA. The software is fully open-source and written in highly optimized C++, though everyone uses it through its Python interface. The download is available at github.com/dmlc/xgboost. Most data science competition winners use XGBoost for tabular data
@inproceedings{chen2016xgboost,
	author = {Chen, Tianqi and Guestrin, Carlos},
	title = {{XGBoost}: A Scalable Tree Boosting System},
	year = {2016},
	month = {8},
	booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '16)},
	pages = {785--794},
	organization = {ACM},
	location = {San Francisco, California, USA},
	doi = {10.1145/2939672.2939785},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
	keywords = {AI, artificial intelligence, machine learning, ML, decision trees, open source},
}

% HumanEval: OpenAI's publicly available test set of function headers and docstrings + unit tests for evaluating the performance of generative AI models and LLMs that generate Python code from function docstings. They also train a code generation model from GitHub data and evaluate its performance on their test set with mixed results. The challenge appears to be having the LLM understand long multi-step docstrings and binding the results of operations to variables (and remembering those variables in the future!). Other popular benchmarks for code generation involve mostly just having the AI answer questions on Codebench and Codefore. The HumanEval benchmark is available with a Python interface at: github.com/openai/human-eval
@techreport{chen2021evaluating,
	author = {Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others, },
	title = {Evaluating large language models trained on code},
	year = {2021},
	institution = {arXiv preprint arXiv:2107.03374},
	doi = {10.48550/arXiv.2107.03374},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, benchmarking, open source},
}

% Official reference for the LLM Chatbot Arena website where humans go to ask questions and rank their preference for various chatbots, generating a leaderboard for the "best" current chatbot. This is still considered the most reliable way to rank LLM performance on real problems. The website is https://chat.lmsys.org/
@inproceedings{chiang2024chatbot,
	author = {Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhu, Banghua and Zhang, Hao and Jordan, Michael and Gonzalez, Joseph E. and Stoica, Ion},
	title = {{Chatbot Arena}: An Open Platform for Evaluating {LLM}s by Human Preference},
	year = {2024},
	booktitle = {Forty-first International Conference on Machine Learning (ICML)},
	url = {https://openreview.net/forum?id=3MW8GKNyzI},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs},
}

% The Keras docs -- great and highly impactful open source Python software, needs no introduction. A simplified interface for quickly building neural networks and other deep learning models with various backends frameworks such as Tensorflow, jax, and Pytorch.
@misc{chollet2015keras,
	author = {Chollet, Fran\c{c}ois and others, },
	title = {Keras},
	year = {2015},
	howpublished = {\url{https://keras.io}},
	note = {Last accessed: Nov 2023},
	keywords = {AI, artificial intelligence, machine learning, ML, open source, neural networks},
}

% Paper on how the HPC Frontier at ORNL was configured to train trillion-parameter large language models (LLMs). There is a really nice discussion of the model architectures and sizes, and the memory requirements of each. There is also a nice discussion of parallel pipelines and model vs data sharding. Then they discuss their code bases and software stacks. Finally, they perform a hyperparameter optimization with DeepHyper to determine optimal block sizes and pipeline overlapping configurations.
@inproceedings{dash2024optimizing,
	author = {Dash, Sajal and Lyngaas, Isaac R and Yin, Junqi and Wang, Xiao and Egele, Romain and Ellis, J. Austin and Maiterth, Matthias and Cong, Guojing and Wang, Feiyi and Balaprakash, Prasanna},
	title = {Optimizing Distributed Training on Frontier for Large Language Models},
	year = {2024},
	month = {5},
	booktitle = {ISC High Performance 2024 Research Paper Proceedings (39th International Conference)},
	pages = {1--11},
	organization = {IEEE},
	location = {Hamburg, Germany},
	doi = {10.23919/ISC.2024.10528939},
	url = {https://ieeexplore.ieee.org/document/10528939/},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, transformers, optimization},
}

% Interesting paper on why it is generally OK to use local optimizers when solving non convex optimization problems in high-dimensional spaces. In general, in high-dimensional spaces, almost every critical point will be a saddle point with high probability. Therefore, first-order methods tend to perform very well on these problems as they converge quickly but are not attracted to saddle points and therefore tend to find the global optimum in the limit. The analysis of the probability that a critical point will be a saddle point is based on a spectral analysis of the hessian at each critical point other than the global minimum/maximum -- all of the eigenvalues must be positive or negative for the critical point to be a local minima / maxima, and the probability of this occurring decays as the number of eigenvalues grows with the dimension of the Hessian. The authors also experimentally validate these claims by extracting critical points from the loss landscapes of single layer MLPs trained on down-sampled versions of MNIST and CIFAR-10.
@inproceedings{dauphin2014identifying,
	author = {Dauphin, Yann N. and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. and Weinberger, K.Q.},
	title = {Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
	year = {2014},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {27},
	organization = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/04192426585542c54b96ba14445be996-Paper.pdf},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, optimization},
}

% One of the largest most difficult image classification benchmark problems from the 2010s, which drove a lot of advancement. Was a bit too difficult for the average researcher to solve since it required a lot of training resources to get good performance, but drove advancement in developing and training large (deep) neural networks with many layers and millions of parameters
@inproceedings{deng2009imagenet,
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	title = {{ImageNet}: A large-scale hierarchical image database},
	year = {2009},
	month = {6},
	booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
	volume = {},
	number = {},
	pages = {248--255},
	organization = {IEEE},
	location = {Miami, FL},
	doi = {10.1109/CVPR.2009.5206848},
	url = {https://ieeexplore.ieee.org/document/5206848/},
	keywords = {AI, artificial intelligence, machine learning, ML, benchmarking, neural networks},
}

% BERT was one of the first transformer-based neural network architectures for solving language-related tasks, such as language translations, at Google. This was also by far the largest model of its time. BERT paved the way for modern large language models, probably moreso than the Attention is all you need paper
@inproceedings{devlin2019bert,
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	year = {2019},
	booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	pages = {4171--4186},
	organization = {Association for Computational Linguistics},
	location = {Minneapolis, Minnesota},
	doi = {10.18653/v1/N19-1423},
	url = {https://aclanthology.org/N19-1423/},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, transformers, neural networks},
}

% A repository of baseline models for reinforcement learning algorithms. OpenAI encourages researchers to compare their models against these baselines. All of the provided RL models are open source and available for download in Python from: github.com/openai/baselines
@misc{dhariwal2017openai,
	author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
	title = {{OpenAI} Baselines},
	year = {2017},
	howpublished = {GitHub repository},
	publisher = {GitHub},
	url = {https://github.com/openai/baselines},
	note = {Last accessed: Apr 2025},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, open source, neural networks},
}

% Latest AlpacaEval paper introducing length control to the evaluation pipeline, which prevents models from being able to game the evaluation system by producing longer outputs. AlpacaEval is a standard English-language LLM evaluation benchmark, which ranks and evaluates how well a LLM is capable of following instructions and completing basic tasks using the Alpaca model (another LLM) to judge performance instead of a human judge. This particular benchmark has a 98% correlation with the LLM Chatbot Arena without requiring human participants and using minimal OpenAI credits to run. Open source Python interface at: github.com/tatsu-lab/alpaca_eval
@techreport{dubois2024lengthcontrolled,
	author = {Dubois, Yann and Galambosi, Bal{\'a}zs and Liang, Percy and Hashimoto, Tatsunori B},
	title = {Length-Controlled {AlpacaEval}: A Simple Way to Debias Automatic Evaluators},
	year = {2024},
	institution = {arXiv preprint arXiv:2404.04475},
	doi = {10.48550/arXiv.2404.04475},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, benchmarking},
}

% The original paper for AdaGrad (adaptive subgradient method) which replaced the subgradient method with an adaptive estimate for the gradient, where each component of the gradient is rescaled by an adaptive estimate for the standard deviation in that direction based on previous iterates. This adaptive estimate for standard deviation in each axis-aligned direction serves as a diagonal approximation to the Hessian matrix, giving second-order like properties to the method and greatly improving the practical convergence. AdaGrad was very popular and considered the state-of-the-art optimization algorithm for training neural networks upon its initial release, but was quickly replaced by Adam, which added a Nesterov momentum esque smoothing to this adaptive gradient estimation in order to further improve convergence rates on nonsmooth, highly stochastic, and ill-conditioned problems
@article{duchi2011adaptive,
	author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
	year = {2011},
	journal = {Journal of Machine Learning Research},
	volume = {12},
	number = {61},
	pages = {2121--2159},
	url = {http://jmlr.org/papers/v12/duchi11a.html},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, optimization},
}

% The culmination of a line of work from Google DeepMind on discovering better matrix factorization algorithms using reinforcement learning. They defined a tensor game for trying to solve matrix multiplication at a fixed size in fewer moves, then trained a RL agent to play the game using monte carlo tree search and training a neural network to predict a manageable subset of states and expected state outcomes since the number of states was too numerous for true MCTS. They were able to match the performance of Strassen's algorithm on 5x5 matrices (this is how recursive block-based recursive multiplication is done) and exceed performance on other sizes and rings (such as modular arithmetic rings)
@article{fawzi2022discovering,
	author = {Fawzi, Alhussein and Balog, Matej and Huang, Aja and Hubert, Thomas and Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and R. Ruiz, Francisco J and Schrittwieser, Julian and Swirszcz, Grzegorz and others, },
	title = {Discovering faster matrix multiplication algorithms with reinforcement learning},
	year = {2022},
	month = {10},
	journal = {Nature},
	volume = {610},
	number = {7930},
	pages = {47--53},
	publisher = {Nature Publishing Group UK London},
	doi = {10.1038/s41586-022-05172-4},
	url = {https://www.nature.com/articles/s41586-022-05172-4},
	issn = {0028-0836},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, neural networks},
}

% The first paper where the ReLU activation function was used as the activation function in neural network models. This would later become the standard for many years (and still is for regressor models)
@article{fukushima1975cognitron,
	author = {Fukushima, Kunihiko},
	title = {Cognitron: A self-organizing multilayered neural network},
	year = {1975},
	journal = {Biological cybernetics},
	volume = {20},
	number = {3},
	pages = {121--136},
	publisher = {Springer},
	doi = {10.1007/bf00342633},
	url = {http://link.springer.com/10.1007/BF00342633},
	issn = {0340-1200},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks},
}

% Paper showing that using the process reward model (PRM) during fine-tuning can easily lead models to over-optimize for quick rewards, leading to worse overall ability to reach the correct solution. This doesn't mean that process can't work, we just need a mechanism to encourage better long-term planning
@inproceedings{gao2023scaling,
	author = {Gao, Leo and Schulman, John and Hilton, Jacob},
	editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
	title = {Scaling Laws for Reward Model Overoptimization},
	year = {2023},
	booktitle = {Proceedings of the 40th International Conference on Machine Learning},
	series = {Proceedings of Machine Learning Research},
	volume = {202},
	pages = {10835--10866},
	organization = {PMLR},
	url = {https://proceedings.mlr.press/v202/gao23h.html},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, overfitting},
}

% The original paper on the bias-variance tradeoff curve. Now widely debunked (in my opinion) the theory that machine learning and neural networks had to tradeoff between training accuracy and overfitting (which would lead to the idea of so-called "generalization error") and had to be combatted by limiting model size or regularization rules ruled AI theory for many, many years. One key insight in this paper that was perhaps ahead of its time, is that the important part of machine learning is the representation learning, in which sense training neural networks with backpropagation for regression problems is somewhat not special
@article{geman1992neural,
	author = {Geman, Stuart and Bienenstock, Elie and Doursat, Ren\'e},
	title = {Neural networks and the bias/variance dilemma},
	year = {1992},
	month = {jan},
	journal = {Neural Computation},
	volume = {4},
	number = {1},
	pages = {1--58},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
	doi = {10.1162/neco.1992.4.1.1},
	url = {https://direct.mit.edu/neco/article/4/1/1-58/5624},
	issn = {0899-7667},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, representation learning, regularization, overfitting},
}

% Online paper with interactive visualizations explaining what Nesterov's momentum is and how it works intuitively by smoothing out optimization sample paths and preventing oscillations in the optimizer that occur do to poor problem conditioning. Then, they show how the problem conditioning appears as an often ignored constant in the convergence rate of gradient descent. All this is to show intuitively and mathematically that gradient descent with Nesterov's momentum will convergence faster in practice for ill-conditioned problems
@article{goh2017why,
	author = {Goh, Gabriel},
	title = {Why Momentum Really Works},
	year = {2017},
	month = {4},
	journal = {Distill},
	volume = {2},
	number = {4},
	publisher = {Distill Working Group},
	doi = {10.23915/distill.00006},
	url = {http://distill.pub/2017/momentum},
	issn = {2476-0757},
	keywords = {AI, artificial intelligence, machine learning, ML, optimization},
}

% Theorems on the curse of dimensionality when it comes to drawing data points in high-dimensional spaces. The main theorem implies that the convex hull of N points in D dimensions has volume ~0 for D sufficiently large -- this occurs because of a concentration of measure type result
@article{gorban2017stochastic,
	author = {Gorban, Alexander N and Tyukin, Ivan Yu},
	title = {Stochastic separation theorems},
	year = {2017},
	month = {10},
	journal = {Neural Networks},
	volume = {94},
	pages = {255--259},
	publisher = {Elsevier},
	doi = {10.1016/j.neunet.2017.07.014},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608017301776},
	issn = {0893-6080},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks},
}

% The LLaMA 3 model publication. In addition to the information from LLaMA 1 tech report, they add information on training and pipeline parallelism. The latest max model size is a 405B parameter (dense) model, which competes with GPT-4 from OpenAI. The model architectures and instructions to download the weights (form HuggingFace) are obtained from github.com/meta-llama/llama TODO: read this report carefully, especially the training details, I have only skimmed
@techreport{grattafiori2024llama,
	author = {Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others, },
	title = {The {LLaMA} 3 herd of models},
	year = {2024},
	institution = {arXiv preprint arXiv:2407.21783},
	url = {https://arxiv.org/abs/2407.21783},
	keywords = {AI, artificial intelligence, machine learning, ML, open source},
}

% First published work using Geoff Hinton's unpublished optimization algorithm RMSProp (root mean squared propogation, an adjustment to AdaGrad using an adaptive learning rate in each dimension). The author uses RMSProp to train a recurrent neural network (RNN) with long short-term memory (LSTM) in order to generate handwritten digits
@techreport{graves2014generating,
	author = {Graves, Alex},
	title = {Generating Sequences With Recurrent Neural Networks},
	year = {2014},
	institution = {arXiv cs.NE preprint},
	url = {https://arxiv.org/abs/1308.0850},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, optimization},
}

% DeepSeek-R1 tech report: DeepSeek-R1 is DeepSeek's first state-of-the-art reasoning model. DeepSeek-R1-Zero was fine-tuned from DeepSeek-V3, by allowing chain-of-thought reasoning and using training objectives without cold start consisting of mostly checkable rules and formatting. I.e., it is possible to penalize any computer code that doesn't compile, any images that spill out of a bounding box, and any thought chains that are not enclosed within <think></think> blocks. This model has good performance but mixes languages and doesn't always generate human readable output. Next, they trained DeepSeek-R1 using some carefully crafted cold-start examples to enforce reasoning and logic and output language consistency, using mostly coding, math, logic, and science problem sets and language mixing penalties. These penalties are critically applied inside as well as without the CoT blocks. The authors trained both R1 and R1-Zero via reinforcement learning with group relative policy optimization (GRPO). They claim the model naturally learned to use long chains of thoughts and internal discussions unprompted, but that's debatable since this kind of discussion is actually common in internet data. The resulting model performs well on standard AI model benchmarks. They also show that information from their large MoE models can be distilled into smaller dense models with better results than just fine-tuning those dense models on the same data
@techreport{guo2025deepseekr1,
	author = {Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others, },
	title = {{DeepSeek-R1}: Incentivizing reasoning capability in {LLM}s via reinforcement learning},
	year = {2025},
	institution = {arXiv preprint arXiv:2501.12948},
	doi = {10.48550/arXiv.2501.12948},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, LLMs, benchmarking, open source},
}

% Original publication of the Boltzman machine, an early type of AI model that made predictions by modeling the Ising spin-glass model with public input units (set by the user with the independent variables during inference) and hidden internal units that are correlated to eachother and the public units through learned Ising model weights and biases. Each unit has a binary {0, 1} state. The energy of the system is the output (prediction). The weights and biases are learned through simulated annealing, and in this way, the model is not unlike quantum annealing. The model learns a distribution of potential inference values for each input combination. Thus, it is a form of distribution learning. These were a commonly used alternative to neural networks for a time, and often cited as explainable alternatives. The binary state variables would later be replaced by sigmoidal activation functions (for smoothness)
@inproceedings{hinton1983optimal,
	author = {Hinton, Geoffrey E and Sejnowski, Terrence J},
	title = {Optimal perceptual inference},
	year = {1983},
	booktitle = {Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
	volume = {448},
	pages = {448--453},
	organization = {Citeseer},
	url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b89e9f0cef5ace08946a7c07bf7284854c418445},
	keywords = {AI, artificial intelligence, machine learning, ML, Boltzmann machine, neural networks},
}

% Original publication on using long-short term memory within a recurrent neural network framework to address the issue of vanishing gradients during training. The idea is to truncate gradients for certain blocks (short-term memory units) and chain these blocks to generate skip connections for long term memory. These would be the state-of-the-art in natural language processing and other sequential prediction tasks until BERT replaces them with transformer models.
@article{hochreiter1997long,
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	title = {Long Short-Term Memory},
	year = {1997},
	month = {11},
	journal = {Neural Computation},
	volume = {9},
	number = {8},
	pages = {1735--1780},
	publisher = {MIT Press},
	doi = {10.1162/neco.1997.9.8.1735},
	url = {https://direct.mit.edu/neco/article/9/8/1735-1780/6109},
	issn = {0899-7667},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, RNNs},
}

% An article on Google GlassBox research: Google's research division dedicated to interpretable machine learning
@article{hof2015google,
	author = {Hof, Robert D.},
	title = {Google Tries to Make Machine Learning a Little More Human},
	year = {2015},
	month = {nov},
	journal = {MIT Technology Review},
	url = {https://www.technologyreview.com/2015/11/05/165175/google-tries-to-make-machine-learning-a-little-more-human},
	note = {Last accessed: June 20, 2022},
	keywords = {AI, artificial intelligence, machine learning, ML},
}

% An analysis of how adversarial examples for neural network and other AI models are typically indicative of the model using highly predictive but brittle features to make predictions -- i.e., features that are highly predictive but nevertheless not robust enough to use for actually making predictions
@inproceedings{ilyas2019adversarial,
	author = {Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch\'{e}-Buc, F. d\textquotesingle and Fox, E. and Garnett, R.},
	title = {Adversarial Examples Are Not Bugs, They Are Features},
	year = {2019},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {32},
	pages = {125--136},
	organization = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, overfitting},
}

% LiveCodeBench is a LLM code generation evaluation benchmark. It continuously collects new problems from CodeBench and annotates them with their release dates, so that LLMs can be evaluated on just problems from specific timeframes. This allows researchers to prevent contamination of the test set with data from the training set. An open source Python interface is available at: github.com/LiveCodeBench/LiveCodeBench Submissions to the leaderboard are made via pull request to github.com/LiveCodeBench/submissions
@techreport{jain2024livecodebench,
	author = {Jain, Naman and Han, King and Gu, Alex and Li, Wen-Ding and Yan, Fanjia and Zhang, Tianjun and Wang, Sida and Solar-Lezama, Armando and Sen, Koushik and Stoica, Ion},
	title = {{LiveCodeBench}: Holistic and Contamination Free Evaluation of Large Language Models for Code},
	year = {2024},
	institution = {arXiv preprint arXiv:2403.07974},
	doi = {10.48550/arXiv.2403.07974},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, benchmarking, open source},
}

% Original tech report where recurent neural networks were originally applied at scale to a language processing (next word prediction) application
@techreport{jordan1986serial,
	author = {Jordan, Michael I.},
	title = {Serial order: a parallel distributed processing approach},
	year = {1986},
	institution = {Institute for Cognitive Science, University of California},
	address = {San Diego, La Jolla, CA, USA},
	url = {https://www.osti.gov/biblio/6910294},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, RNNs, neural networks},
}

% The original paper defining variational autoencoders, a standard practice in performing dimension reduction and training models that encode continuous latent spaces. The idea being to train and optimize an encoder neural network model whose posterior is a continuous latent space to generate samples in the latent space distribution based on inputs from the original dataset without "losing information", then jointly train a decoder model that samples the latent distribution to produce the original observations. The idea being to randomly sample new data points that look like the original data. When trained jointly, these models can also be used as embedder/extractor or compression/decompression pairs.
@inproceedings{kingma2014autoencoding,
	author = {Kingma, Diederik P and Welling, Max},
	title = {Auto-encoding variational {B}ayes},
	year = {2014},
	booktitle = {2nd International Conference on Learning Representations (ICLR 2014)},
	url = {https://arxiv.org/abs/1312.6114},
	keywords = {AI, artificial intelligence, machine learning, ML, autoencoders, representation learning, neural networks},
}

% The original paper on Adam: an adaptive gradient and moment estimator that uses second order moments to approximate curvature (i.e., Hessian information) in order to accelerate the convergence of AdaGrad. In particular, this means applying Nesterov's momentum to both the gradient and curvature estimations. From 2015-2024 this was the state-of-the-art algorithm for optimization of neural network weights during training, and was what was typically meant when people talked about stochastic gradient descent.
@inproceedings{kingma2015adam,
	author = {Kingma, Diedrik and Ba, Jimmy},
	title = {Adam: A method for stochastic optimization},
	year = {2015},
	booktitle = {3rd International Conference on Learning Representations (ICLR 2015)},
	numpages = {11},
	location = {San Diego, CA, USA},
	url = {https://arxiv.org/abs/1412.6980},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, optimization},
}

% The official techreport for the CIFAR-10 dataset -- one of the next most popular neural network and image classification benchmark problems for machine learning and AI research in the 2010s. Just a little harder than MNIST due to having lower quality images and more (imbalanced) classes
@techreport{krizhevsky2009learning,
	author = {Krizhevsky, Alex and Hinton, Geoffrey and others, },
	title = {Learning multiple layers of features from tiny images},
	year = {2009},
	institution = {Toronto, ON, Canada},
	keywords = {AI, artificial intelligence, machine learning, ML, benchmarking, neural networks},
}

% The official publication for AlexNet -- one of the first truly massive overparameterized convolutional neural networks, which threw away a lot of the conventional wisdom around overfitting and achieved state-of-the-art performance and fine generalization errors on the ImageNet benchmark problem. This could be considered the beginning of "deep" learning in the sense of adding many many layers
@inproceedings{krizhevsky2012imagenet,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C.J. and Bottou, L. and Weinberger, K.Q.},
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	year = {2012},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {25},
	organization = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
	keywords = {AI, artificial intelligence, machine learning, ML, benchmarking, neural networks, CNNs, regularization, overfitting},
}

% Stochastic approximation algorithm (i.e., stochastic gradient descent) and how to analyze its radius of convergence for a fixed step-size -- you can decay its step size at a square-summable but not summable rate to guarantee convergence in the limit
@article{lai2003stochastic,
	author = {Lai, Tze Leung},
	title = {Stochastic approximation},
	year = {2003},
	journal = {The annals of Statistics},
	volume = {31},
	number = {2},
	pages = {391--406},
	publisher = {Institute of Mathematical Statistics},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks},
}

% LeCun et al. show that convolutional nets can outperform all other methods on handwritten digit classification and other perception problems
@article{lecun1989backpropagation,
	author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
	title = {Backpropagation Applied to Handwritten Zip Code Recognition},
	year = {1989},
	month = {12},
	journal = {Neural Computation},
	volume = {1},
	number = {4},
	pages = {541--551},
	publisher = {MIT Press},
	doi = {10.1162/neco.1989.1.4.541},
	url = {https://direct.mit.edu/neco/article/1/4/541-551/5515},
	issn = {0899-7667},
	keywords = {AI, artificial intelligence, machine learning, ML, CNNs, neural networks},
}

% LeCun's original paper on convolutional neural network architecture -- the first example of a problem where neural networks trained with backpropagation actually outperformed other models, and one of the early examples of the magic of representation learning and how exploiting problem structure is essential to making machine learning work. This remained the state-of-the art in image classification and image processing for over 20 years until the event of transformers, and whether transformers are better for image problems remains debatable
@article{lecun1995convolutional,
	author = {LeCun, Yann and Bengio, Yoshua and others, },
	title = {Convolutional networks for images, speech, and time series},
	year = {1995},
	journal = {The handbook of brain theory and neural networks},
	volume = {3361},
	number = {10},
	numpages = {1995},
	publisher = {Citeseer},
	keywords = {AI, artificial intelligence, machine learning, ML, representation learning, autograd, algorithmic differentiation, backpropagation, CNNs, neural networks},
}

% LeCun et al. show that convolutional nets can outperform all other methods on handwriting classification for efficient document processing
@article{lecun1998gradientbased,
	author = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	title = {Gradient-based learning applied to document recognition},
	year = {1998},
	journal = {Proceedings of the IEEE},
	volume = {86},
	number = {11},
	pages = {2278--2324},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	doi = {10.1109/5.726791},
	url = {http://ieeexplore.ieee.org/document/726791/},
	issn = {0018-9219},
	keywords = {AI, artificial intelligence, machine learning, ML, CNNs, neural networks},
}

% Original publication on "chain of thought" (CoT) reasoning in LLMs, based on the observation that when prompted to solve complex logic problems in multiple small steps (with no fine tuning), language models achieve better performance than when directly prompted for the solution. This discovery is important, as it would lead to the release of numerous "reasoning models," which generate long CoT discussions within a <think> ... </think> (or similar) block. The authors claim that these chains of thoughts mimic a human reasoning process, but acknowledge that this may not actually be indicative of any emergent reasoning behavior in the network (which I believe is the correct take). It seems natural to me that the model is better able to succeed on simple logic problems, and is also able to use the previous state (i.e.,the solution to the previous small problem) to make another small logical step. That process actually is a form of reasoning, but when prompted or fine-tuned to encourage this behavior, it becomes unclear whether we can call that true reasoning.
@inproceedings{wei2022,
author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
title = {Chain-of-thought prompting elicits reasoning in large language models},
year = {2022},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {1800},
numpages = {14},
location = {New Orleans, LA, USA},
url={https://openreview.net/forum?id=_VjQlMeSB_J},
keywords = {AI, artificial intelligence, machine learning, ML, LLMs},
}

% DeepSeek-V3 technical report: DeepSeek-V3 is the first open source model to obtain performance on par with closed source models. The architecture is transformer based with multi-headed latent attention applied to a mixture of experts model. The first layer is an embedding layer that is shared by all models and trained on the data (as opposed to using word2vec). Next, the architecture passes through alternating multi-headed latent attention and feed-forward (i.e., MLP) layers. The latent attention blocks are shared between all experts. Each expert then has its own multi-layer perceptron consisting of feed-forward layers with sigmoidal activation functions. Each individual expert model is run sequential and used to generate a sequence of multiple output tokens (as opposed to just the next word). All experts are run in parallel. The predictions from each expert are ultimately combined in an output layer and hit with a softmax to generate the logits for the next word prediction(s). During training, the objective is the CrossEntropy loss for each prediction depth. The authors use model sharding and pipeline paralleism during training. They break apart and overlap forward and backward pass computations to create 2 overlapping pipelines, which they use to hide latency. The model is trained in FP8 and mixed precision. The weight checkpoints are publicly available at: https://github.com/deepseek-ai/DeepSeek-V3 TODO: read this report carefully
@techreport{liu2024deepseekv3,
	author = {Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others, },
	title = {{DeepSeek-V3} technical report},
	year = {2024},
	institution = {arXiv preprint arXiv:2412.19437},
	doi = {10.48550/arXiv.2412.19437},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, open source},
}

% Our paper proposing test functions for convex optimization problems with very specific properties, in order to gauge the effectiveness and robustness of various techniques subject to various forms of degeneracy
@inproceedings{lux2020analytic,
	author = {Lux, Thomas C. H. and Chang, Tyler H.},
	title = {Analytic test functions for generalizable evaluation of convex optimization techniques},
	year = {2020},
	month = {3},
	booktitle = {Proc. IEEE SoutheastCon 2020},
	numpages = {8},
	organization = {Institute of Electrical and Electronics Engineers},
	location = {Raleigh, NC, USA},
	doi = {10.1109/SoutheastCon44009.2020.9368254},
	url = {https://ieeexplore.ieee.org/document/9368254/},
	keywords = {AI, artificial intelligence, machine learning, ML, benchmarking, open source, optimization},
}

% Original word2vec publication: embedding words into a continuous vector space in a "dense" way, meaning that the embedding is somewhat minimal and no extra dimensions are added and word relationships are preserved (as in semantic regularization). The authors show that a relatively small and simple model with semantic regularization is sufficient to train such an embedding in less than a day, and the resulting word2vec embedding layer is fast and cheap to evaluate. The word2vec embedding would go on to be the basis for most early transformer models. Modern LLMs train their own embedding as the embedding layers of the network, but use the same techniques as word2vec. The open source software is available for download from Google: https://code.google.com/archive/p/word2vec
@inproceedings{mikolov2013efficient,
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	title = {Efficient estimation of word representations in vector space},
	year = {2013},
	booktitle = {1st International Conference on Learning Representations (ICLR 2013)},
	location = {Scottsdale, AZ, USA},
	url = {https://openreview.net/forum?id=idpCdOWtqXd60&noteld=C8Vn84fq},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, representation learning, open source, neural networks, regularization},
}

% Introduces the idea of semantic regularization for generating word embeddings. This is a massive improvement over bag of word embeddings, where each word gets a dimension and sentences / documents are embedded as vectors listing the number of occurrences for each word. Instead, for this work, words are compressed into a continuous latent space using a RNN-based compression model. In the compression, the embedding is regularized by relationships between words. For example, embedding(king):embedding(queen) ~ embedding(man):embedding(woman) and embedding(clothes):embedding(shirt) ~ embedding(dishes):embedding(bowl). These relationships are enforced using the cosin similarity score of their embeddings. The authors also collected a massive dataset of english words and the corresponding relationships, and successfully trained the first word to vector embedding that (mostly) preserves these relationships, meaning that all vector operations remain meaningful
@inproceedings{mikolov2013linguistic,
	author = {Mikolov, Tom{\'a}{\v{s}} and Yih, Wen-tau and Zweig, Geoffrey},
	title = {Linguistic regularities in continuous space word representations},
	year = {2013},
	booktitle = {Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: Human language technologies},
	pages = {746--751},
	keywords = {AI, artificial intelligence, machine learning, ML, representation learning, neural networks, regularization},
}

% Paper where ReLU functions were first used to replace sigmoidal activations in a restricted Boltzmann machine with much success. After this, ReLU became the standard activation function in all neural network regressive models
@inproceedings{nair2010rectified,
	author = {Nair, Vinod and Hinton, Geoffrey E.},
	title = {Rectified linear units improve restricted {B}oltzmann machines},
	year = {2010},
	booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
	series = {ICML'10},
	pages = {807--814},
	organization = {Omnipress},
	location = {Haifa, Israel},
	isbn = {9781605589077},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, Boltzmann machine},
}

% Original publication on Nesterov's momentum. I haven't read it (it is hard to find a copy and likely in Russian) but this is the preferred citation. The equation for Nesterov momentum in gradient descent is instead of using the update: x' = x - a*g(x), use x' = x - a*g(y) - b*v where y = x - b*v and v = b*v + a*g(x) -- in this equation, b*v is the momentum term which smooths out poor conditioning in the problem by encouraging the algorithm to continue in the direction it was headed instead of oscillating. Nexterov proves that this term also leads to better convergence rates. For best results, b is usually chosen to be a large value such as 0.9 or 0.99
@inproceedings{nesterov1983method,
	author = {Nesterov, Yurii},
	title = {A method for solving the convex programming problem with convergence rate O (1/k2)},
	year = {1983},
	booktitle = {Dokl akad nauk Sssr},
	volume = {269},
	numpages = {543},
	keywords = {AI, artificial intelligence, machine learning, ML, optimization},
}

% Not an original paper, as L1 and L2 regularization have been around since the beginning of machine learning and applied math, and are generally not attributed to anyone in particular, but a nice review paper on the usage and effects of L1 and L2 regularization in machine learning and neural network training with back propagation. Regularization was considered an essential part of neural network training (and still is in scientific machine learning) for many many years.
@inproceedings{ng2004feature,
	author = {Ng, Andrew Y.},
	title = {Feature selection, L1 vs. L2 regularization, and rotational invariance},
	year = {2004},
	booktitle = {Proceedings of the Twenty-First International Conference on Machine Learning},
	series = {ICML '04},
	numpages = {78},
	organization = {Association for Computing Machinery},
	location = {Banff, Alberta, Canada},
	doi = {10.1145/1015330.1015435},
	url = {https://doi.org/10.1145/1015330.1015435},
	isbn = {1581138385},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, regularization, overfitting},
}

% Original definition of RBF networks, an early form of neural networks that focused on the usage of combining RBF basis functions. These networks are not used much anymore, although occasionally still come up in the context of scientific machine learning theory and proofs
@article{park1991universal,
	author = {Park, Jooyoung and Sandberg, Irwin W},
	title = {Universal approximation using radial-basis-function networks},
	year = {1991},
	month = {6},
	journal = {Neural computation},
	volume = {3},
	number = {2},
	pages = {246--257},
	publisher = {MIT Press},
	doi = {10.1162/neco.1991.3.2.246},
	url = {https://direct.mit.edu/neco/article/3/2/246-257/5580},
	issn = {0899-7667},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, RBFs},
}

% The official publication for pytorch a gold standard in open source software, providing automatic differentiation and numerical linear algebra in Python, targeted at implementing deep learning algorithms. Pytorch is pretty much a standard in not just open source software, but also machine learning software, and also numerical software
@inproceedings{paszke2019pytorch,
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch\'{e}-Buc, F. d\textquotesingle and Fox, E. and Garnett, R.},
	title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
	year = {2019},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {32},
	pages = {1--12},
	organization = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
	keywords = {AI, artificial intelligence, machine learning, ML, autograd, algorithmic differentiation, backpropagation, open source, neural networks},
}

% The official publication for scikit-learn a gold standard in open source software, providing a clean interface to several standard implementations of numerical approximation, optimization, machine learning, and deep learning algorithms. Scikit-learn is pretty much a standard in not just open source software, but also machine learning software, and also numerical software
@article{pedregosa2011scikitlearn,
	author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others, },
	title = {Scikit-learn: Machine learning in {P}ython},
	year = {2011},
	journal = {Journal of Machine Learning Research},
	volume = {12},
	pages = {2825--2830},
	url = {https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf},
	keywords = {AI, artificial intelligence, machine learning, ML, open source, decision trees, neural networks},
}

% One of the original papers proposing that overfitting, the bias variance tradeoff curve, and generalization error are all misunderstood and misused ideas. The authors present a true holdout set of lost and never-before-seen ImageNet and CIFAR-10 data, and show that massive interpolatory models (models trained to zero error) generalize just as well as the well-regularized models on this new data (better because their training error was lower and total error = training error + generalization error). Ben would go on to claim that (1) you want to interpolate a lot of data that we claim we don't want to overfit (such as image data). (2) Models that interpolate don't generalize poorly in practice and large overparameterized models always perform better in practice. And (3) Hyperparameter tuning is basically a form of training on the test set in order to find the best model that interpolates the training data. This paper was an eye-opener for me personally, and lead me to firmly believe in interpolation for high-dimensional data
@inproceedings{recht2019imagenet,
	author = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
	editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	title = {Do {I}mage{N}et Classifiers Generalize to {I}mage{N}et?},
	year = {2019},
	month = {09--15 Jun},
	booktitle = {Proceedings of the 36th International Conference on Machine Learning},
	series = {Proceedings of Machine Learning Research},
	volume = {97},
	pages = {5389--5400},
	organization = {PMLR},
	url = {https://proceedings.mlr.press/v97/recht19a.html},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, regularization, overfitting},
}

% Rosenblatt's original paper proposing the multi-layer perceptron with an input layer, output layer, and a single hidden layer: this is the foundation for all AI and neural network research. It is proposed as a simulation model for biologists and psychologists to study brain function. It would not be useful as a tool for regression, classification, or prediction for many years until the advent of representation learning. He originally used a step (discontinuous) activation function since it was well-known from functional analysis and approximation theory that the span of these functions is dense in L2 space. The sigmoidal activation would later be introduced as a continuous smoothing of the step function (so that back propogation would have gradients to train on), but there is no clear reference for who first proposed this
@article{rosenblatt1958perceptron,
	author = {Rosenblatt, Frank},
	title = {The perceptron: a probabilistic model for information storage and organization in the brain.},
	year = {1958},
	journal = {Psychological review},
	volume = {65},
	number = {6},
	numpages = {386},
	publisher = {American Psychological Association},
	doi = {10.1037/h0042519},
	url = {https://doi.apa.org/doi/10.1037/h0042519},
	issn = {1939-1471},
	keywords = {AI, artificial intelligence, machine learning, ML, representation learning, autograd, algorithmic differentiation, backpropagation, neural networks},
}

% Original tech report introducing recurrent neural networks (RNNs), which use a recursively defined state variable to track the context of sequential data observations so far, plus the value of the current output to predict the next output. The authors derive how the gradients can be backpropogated through this entire chain for efficient training. This idea had been around since the 60s, but this is the first paper explicitly proposing such recurrent layers in a representation learning context. The authors propose these recurrent layers as a means of representation learning for sequence data (such as next-word prediction in language models). RNNs would go on to become the state-of-the-art in language models and natural language processing for almost 30 years until they were replaced by transformers with the advent of BERT in 2017. Although the idea of encoding state information is a valid solution, RNNs notoriously suffered from a vanishing gradient issue where tokens further back in the sequence had little effect on the current prediction.
@techreport{rumelhart1985learning,
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	title = {Learning internal representations by error propagation},
	year = {1985},
	month = {9},
	number = {ICS 8504},
	institution = {Institute for Cognitive Science, University of California},
	address = {San Diego, CA, USA},
	doi = {10.21236/ada164453},
	url = {https://www.cs.toronto.edu/~hinton/absps/pdp8.pdf},
	keywords = {AI, artificial intelligence, machine learning, ML, representation learning, backpropagation, RNNs, neural networks},
}

% Original paper on back-propagation for training neural networks. Equivalent to reverse-mode algorithmic differentiation or more simply applying the chain rule recursively.
@article{rumelhart1986learning,
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	title = {Learning representations by back-propagating errors},
	year = {1986},
	month = {10},
	journal = {Nature},
	volume = {323},
	number = {6088},
	pages = {533--536},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1038/323533a0},
	url = {https://www.nature.com/articles/323533a0},
	issn = {0028-0836},
	keywords = {AI, artificial intelligence, machine learning, ML, autograd, algorithmic differentiation, backpropagation, neural networks},
}

% Proximal policy optimization (PPO) is the state-of-the-art policy gradient optimization method for reinforcement learning. Proximal gradient methods computes the update by directly optimizing the parameters for a given batch of observations in order to maximize the intermediate value function. PPO limits the step size in each iteration and enforces a penalization to discourage models from drifting too far from the original "base" model.
@techreport{schulman2017proximal,
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	title = {Proximal Policy Optimization Algorithms},
	year = {2017},
	institution = {arXiv cs.LG},
	url = {https://arxiv.org/abs/1707.06347},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, neural networks, optimization},
}

% DeepSeekMath: Describes how DeepSeek's mathematical specialist model was trained TODO: read this report carefully
@techreport{shao2024deepseekmath,
	author = {Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others, },
	title = {{DeepSeekMath}: Pushing the limits of mathematical reasoning in open language models},
	year = {2024},
	institution = {arXiv preprint arXiv:2402.03300},
	doi = {10.48550/arXiv.2402.03300},
	keywords = {AI, artificial intelligence, machine learning, ML, open source},
}

% A survey on how deep learning models (such as transformer models and neural networks/multilayer perceptrons) still do not perform well (are not the state of the art) when it comes to tabular data, which remains the most important application for most businesses. Gradient boosted trees remain the most reliable predictors for these applications
@article{shwartzziv2022tabular,
	author = {Shwartz-Ziv, Ravid and Armon, Amitai},
	title = {Tabular data: Deep learning is not all you need},
	year = {2022},
	month = {5},
	journal = {Information Fusion},
	volume = {81},
	pages = {84--90},
	publisher = {Elsevier},
	doi = {10.1016/j.inffus.2021.11.011},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253521002360},
	issn = {1566-2535},
	keywords = {AI, artificial intelligence, machine learning, ML, decision trees, neural networks},
}

% Google DeepMind's AlphaGo was the first reinforcement learning agent to beat pro players (exceed the maximum human skill) in Go, which is a much more complex game than chess and required modeling an enumerable amount of game states and move possibilities. This required combining monte carlo tree search (MCTS) with neural networks to filter down to a reasonable number of potential states. This is credited as the first RL model to use MCTS, which is now a standard in RL
@article{silver2016mastering,
	author = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others, },
	title = {Mastering the game of Go with deep neural networks and tree search},
	year = {2016},
	month = {1},
	journal = {nature},
	volume = {529},
	number = {7587},
	pages = {484--489},
	publisher = {Nature Publishing Group},
	doi = {10.1038/nature16961},
	url = {https://www.nature.com/articles/nature16961},
	issn = {0028-0836},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, neural networks},
}

% Original publication on diffusion models. The paper introduces a framework inspired by non-equilibrium thermodynamics where a forward diffusion process gradually destroys structure in the data distribution, transforming it into a simple distribution like Gaussian noise. A reverse diffusion process is then learned to reconstruct the original data distribution, serving as a generative mode. Data can be generated by training the distribution through diffusion, then applying the reverse diffusion operator to sample (or "generate") new data. This is the basis for most image and video generation models
@inproceedings{sohldickstein2015deep,
	author = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
	editor = {Bach, Francis and Blei, David},
	title = {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
	year = {2015},
	booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
	series = {Proceedings of Machine Learning Research},
	volume = {37},
	pages = {2256--2265},
	organization = {PMLR},
	location = {Lille, France},
	url = {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
	keywords = {AI, artificial intelligence, machine learning, ML, diffusion models},
}

% The original dropout paper, this was standard practice in training deep neural networks, especially massive convolutional nets and RNNs for image and language processing for a long time, prior to the invention of transformers -- the idea being that you zero out the effects (and updates to) a small percentage of the nodes in each layer in each iteration, in order to (1) make training cheaper, (2) prevent overfitting since over reliance on any individual node(s) makes the predictions brittle, and (3) redistribute weights to earlier layers and avoid vanishing gradients
@article{srivastava2014dropout,
	author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	title = {Dropout: a simple way to prevent neural networks from overfitting},
	year = {2014},
	journal = {The Journal of Machine Learning research},
	volume = {15},
	number = {1},
	pages = {1929--1958},
	publisher = {JMLR. org},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks},
}

% The original Google Gemini tech report. The model is closed, so this is not that useful, but they discuss the architecture. There is an interesting contribution to architecture, where they utilize heterogeneous encoders from text, speech, video, and images into the same latent space, then feed these encoded tokens (in sequence) to a transformer-based decoder-only model, then pass its output to either an image or text decoder to generate the next token. TODO: read this report carefully, especially the architecture details.
@techreport{team2023gemini,
	author = {Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others, },
	title = {Gemini: a family of highly capable multimodal models},
	year = {2023},
	institution = {arXiv preprint arXiv:2312.11805},
	doi = {10.48550/arXiv.2312.11805},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, transformers, representation learning},
}

% Meta's original LLaMA tech report, introducing the first "herd" of LLaMA models, which were the first open source (really just open weight) models, which one can download and host locally. The original models were 7B and 65B parameters, and trained on only publicly available data. They list their data sources, model architectures (i.e., embedding layers, number of transformer / attention heads, number of layers, number of feed-forward network dimensions, learning rates, number of input tokens, activation function, and optimizer. They trained the models in PyTorchs. Then they share performance on common benchmarks. The model architectures and instructions to download the weights (form HuggingFace) are obtained from github.com/meta-llama/llama TODO: read this report carefully
@techreport{touvron2023llama,
	author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others, },
	title = {{LLaMA}: Open and efficient foundation language models},
	year = {2023},
	institution = {arXiv preprint arXiv:2302.13971},
	doi = {10.48550/arXiv.2302.13971},
	keywords = {AI, artificial intelligence, machine learning, ML, benchmarking, LLMs, transformers, open source},
}

% The LLaMA 2 model publication. In addition to the information from LLaMA 1 tech report, they are now discussing fine-tuning and RLHF and chat safety features. The latest models range from 7B to 70B total parameters. The model architectures and instructions to download the weights (form HuggingFace) are obtained from github.com/meta-llama/llama TODO: read this report carefully
@techreport{touvron2023llama2,
	author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others, },
	title = {{LLaMA}~2: Open foundation and fine-tuned chat models},
	year = {2023},
	institution = {arXiv preprint arXiv:2307.09288},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, LLMs, open source},
}

% The landmark paper showing that transformers alone are capable of capturing all structure needed for language conversion, i.e., recurence relations and the sequential structure of time-series predictions can be encoded into which tokens to "pay attention to" during next word (or any next item) predictions. This paper is often cited as the inspiration for large language models (LLMs), which rely heavily on the transformer architecture, which became a standard after this
@inproceedings{vaswani2017attention,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	title = {Attention is all you need},
	year = {2017},
	booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems (NeurIPs '17)},
	pages = {1--11},
	organization = {Curran Associates, Inc.},
	location = {Long Beach, California, USA},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, transformers, neural networks},
}

% Google DeepMind's AlphaStar II was the first reinforcement learning agent that could beat pro players in video games, which is a signficantly more complex environment than a board game environment with a finite state and set of possible actions
@article{vinyals2019grandmaster,
	author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, R{\'e}mi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and W{\"u}nsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
	title = {Grandmaster level in {StarCraft II} using multi-agent reinforcement learning},
	year = {2019},
	month = {11},
	journal = {Nature},
	volume = {575},
	number = {7782},
	pages = {350--354},
	publisher = {Springer Science and Business Media LLC},
	doi = {10.1038/s41586-019-1724-z},
	url = {https://doi.org/10.1038/s41586-019-1724-z},
	isbn = {1476-4687},
	issn = {0028-0836},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, neural networks},
}

% Math-Shepherd paper describing how the Math-Shepherd model was trained via RLHF to evaluate each step in a LLM's logical process. The resulting model can be used to validate other LLM's mathematical and reasoning skills. TODO: read this report carefully
@inproceedings{wang2024mathshepherd,
	author = {Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
	title = {Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations},
	year = {2024},
	booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)},
	volume = {1},
	pages = {9426--9439},
	organization = {Association for Computational Linguistics},
	location = {Bangkok, Thailand},
	doi = {10.18653/v1/2024.acl-long.510},
	url = {https://aclanthology.org/2024.acl-long.510},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, LLMs},
}

% The MMLU-Pro benchmark. The current go to benchmark for multitask understanding and reasoning in large language models (LLMs). Focuses on logical reasoning capabilities. The benchmark interface is available in Python from github.com/TIGER-AI-Lab/MMLU-Pro
@inproceedings{wang2024mmlupro,
	author = {Wang, Yubo and Ma, Xueguang and Zhang, Ge and Ni, Yuansheng and Chandra, Abhranil and Guo, Shiguang and Ren, Weiming and Arulraj, Aaran and He, Xuan and Jiang, Ziyan and Li, Tianle and Ku, Max and Wang, Kai and Zhuang, Alex and Fan, Rongqi and Yue, Xiang and Chen, Wenhu},
	editor = {Globerson, A. and Mackey, L. and Belgrave, D. and Fan, A. and Paquet, U. and Tomczak, J. and Zhang, C.},
	title = {{MMLU-Pro}: A More Robust and Challenging Multi-Task Language Understanding Benchmark},
	year = {2024},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {37},
	pages = {95266--95290},
	organization = {Curran Associates, Inc.},
	location = {Miami, Florida, USA},
	doi = {10.18653/v1/2024.genbench-1.5},
	url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/ad236edc564f3e3156e1b2feafb99a24-Paper-Datasets_and_Benchmarks_Track.pdf},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, benchmarking},
}

% The authors take a 137B parameter foundational LLM and fine tune if for about 60 types of instruction-based tasks (they refer to this as "instruction tuning"). Then they evaluate the model on task types not in the training list, and it performs adequately. They claim this shows that LLMs are zero-shot learners. I think this may be a stretch as the tasks likely have a lot of overlapping similarities. However, the idea that LLMs can complete semi-related but new tasks (not in the training data) is obviously true to anyone who has used one.
@inproceedings{wei2022chainofthought,
	author = {Wei, Jason and Bosma, Maarten and Zhao, Vincent and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M. and Le, Quoc V and Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
	title = {Chain-of-thought prompting elicits reasoning in large language models},
	year = {2022},
	booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
	articleno = {1800},
	numpages = {14},
	organization = {Curran Associates Inc.},
	location = {New Orleans, LA, USA},
	url = {https://openreview.net/forum?id=_VjQlMeSB_J},
	isbn = {9781713871088},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs},
}

% A summary paper for an influential line of work in the field of scientific machine learning. Some standard techniques for computing error bounds for neural networks using traditional techniques from numerical analysis and approximation theory, and introducing a universal approximation theorem for neural networks. I.e., showing the existence of a two-layer multilayer perceptron or similar neural network that can approximate any Sobolev function to arbitrary required accuracy. Equivalently, we could say that such neural networks are dense in this Sobolev space
@article{weinan2020machine,
	author = {Weinan, E},
	title = {Machine learning and computational mathematics},
	year = {2020},
	month = {1},
	journal = {Communications in Computational Physics},
	volume = {28},
	number = {5},
	pages = {1639--1670},
	publisher = {Global Science Press},
	doi = {10.4208/cicp.OA-2020-0185},
	url = {https://global-sci.com/article/79736/machine-learning-and-computational-mathematics},
	issn = {1991-7120},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks},
}

% The MNIST dataset presents the first and most popular benchmark problem for image classification via neural networks and other AI and machine learning methods
@misc{yann1998mnist,
	author = {Yann, LeCun},
	title = {The {MNIST} database of handwritten digits},
	year = {1998},
	url = {yann.lecun.com/exdb/mnist},
	note = {Last accessed: Apr 2025},
	keywords = {AI, artificial intelligence, machine learning, ML, benchmarking, neural networks},
}

% An experiment showing that when training labels are replaced with random values (pure noise), most neural network classifier methods can still be trained to zero training error. (I.e., obviously overfitting). However, regularization techniques don't prevent them from doing so. The authors conclude that regularization isn't doing what we think it's doing and may not actually be related to generalization error
@inproceedings{zhang2017understanding,
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	title = {Understanding deep learning requires rethinking generalization},
	year = {2017},
	booktitle = {International Conference on Learning Representations},
	url = {https://openreview.net/forum?id=Sy8gdB9xx},
	keywords = {AI, artificial intelligence, machine learning, ML, neural networks, regularization, overfitting},
}

% Publication of Google Research IF-Eval benchmark, testing whether a LLM is capable of following very particular instructions (including formatting instructions) such as "answer in at least 400 words" or "mention AI at least 3 times". The open source Python benchmark code is available at: github.com/google-research/google-research/tree/master/instruction_following_eval
@techreport{zhou2023instructionfollowing,
	author = {Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
	title = {Instruction-Following Evaluation for Large Language Models},
	year = {2023},
	institution = {arXiv cs.CL preprint arxXiv:2211.07911},
	url = {https://arxiv.org/abs/2311.07911},
	keywords = {AI, artificial intelligence, machine learning, ML, LLMs, benchmarking, open source},
}

% The original publication from OpenAI for reinforcement learning with human feedback (RLHF), a method for fine-tuning large language models (LLMs) and other neural network type models using human provided labels (i.e., "cold data") to better align model outputs with desired behavior. This is now one of the standard approaches to fine-tuning foundational models. The authors propose collecting cold start data encompassing human preferences, taking a pre-trained model, and further training the weights on the cold start data using proximal policy optimization (PPO). Since this predates large language models, this examples are with convolutional neural networks (CNNs). There is publicly available code for reproducing their results here: github.com/openai/lm-human-preferences
@techreport{ziegler2019finetuning,
	author = {Ziegler, Daniel M. and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B. and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
	title = {Fine-Tuning Language Models from Human Preferences},
	year = {2019},
	institution = {arXiv preprint arXiv:1909.08593},
	url = {https://arxiv.org/abs/1909.08593},
	keywords = {AI, artificial intelligence, machine learning, ML, reinforcement learning, RL, LLMs, neural networks, optimization},
}

